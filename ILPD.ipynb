{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
    "#https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "#Page No. 63\n",
    "#Research Paper 10th and 12th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><a href=\"#zero\">Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph1\">PCA Plot</a></li>\n",
    "        <li><a href=\"#first\">Classification</a></li>\n",
    "        <li><a href=\"#pca1\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper1\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#under\">Undersampling the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph2\">PCA Plot</a></li>\n",
    "        <li><a href=\"#second\">Classification</a></li>\n",
    "        <li><a href=\"#pca2\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper2\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#under\">Oversampling the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph3\">PCA Plot</a></li>\n",
    "        <li><a href=\"#third\">Classification</a></li>\n",
    "        <li><a href=\"#pca3\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper3\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#rus\">Randomundersampling the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph4\">PCA Plot</a></li>\n",
    "        <li><a href=\"#fourth\">Classification</a></li>\n",
    "        <li><a href=\"#pca4\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper4\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#ros\">Randomoversampling the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph5\">PCA Plot</a></li>\n",
    "        <li><a href=\"#fifth\">Classification</a></li>\n",
    "        <li><a href=\"#pca5\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper5\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#tomek\">Tomeklinking the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph6\">PCA Plot</a></li>\n",
    "        <li><a href=\"#sixth\">Classification</a></li>\n",
    "        <li><a href=\"#pca6\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper6\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#cc\">Cluster Centroid the Original Dataset-</li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph7\">PCA Plot</a></li>\n",
    "        <li><a href=\"#seventh\">Classification</a></li>\n",
    "        <li><a href=\"#pca7\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper7\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#smote\">SMOTE the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph8\">PCA Plot</a></li>\n",
    "        <li><a href=\"#eigth\">Classification</a></li>\n",
    "        <li><a href=\"#pca8\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper8\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#enn\">ENN the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph9\">PCA Plot</a></li>\n",
    "        <li><a href=\"#ninth\">Classification</a></li>\n",
    "        <li><a href=\"#pca9\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper9\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#smoteenn\">SMOTEENN the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph10\">PCA Plot</a></li>\n",
    "        <li><a href=\"#tenth\">Classification</a></li>\n",
    "        <li><a href=\"#pca10\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper10\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "    <li><a href=\"#smotetomek\">SMOTETomek the Original Dataset-</a></li>\n",
    "    <ol>\n",
    "        <li><a href=\"#graph11\">PCA Plot</a></li>        \n",
    "        <li><a href=\"#eleventh\">Classification</a></li>\n",
    "        <li><a href=\"#pca11\">Classification on PCA Dataset</a></li>\n",
    "        <li><a href=\"#hyper11\">Hyperparameter Tuning</a></li>\n",
    "        <li>Result Comparison</li>\n",
    "    </ol>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  albumin  \\\n",
      "0   65  Female            0.7               0.1           187       16   \n",
      "1   62    Male           10.9               5.5           699       64   \n",
      "2   62    Male            7.3               4.1           490       60   \n",
      "3   58    Male            1.0               0.4           182       14   \n",
      "4   72    Male            3.9               2.0           195       27   \n",
      "\n",
      "   ag_ratio  sgpt  sgot  alkphos  is_patient  \n",
      "0        18   6.8   3.3     0.90           1  \n",
      "1       100   7.5   3.2     0.74           1  \n",
      "2        68   7.0   3.3     0.89           1  \n",
      "3        20   6.8   3.4     1.00           1  \n",
      "4        59   7.3   2.4     0.40           1  \n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "data = pd.read_csv('Indian Liver Patient Dataset (ILPD).csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 0\n",
      "gender              0\n",
      "tot_bilirubin       0\n",
      "direct_bilirubin    0\n",
      "tot_proteins        0\n",
      "albumin             0\n",
      "ag_ratio            0\n",
      "sgpt                0\n",
      "sgot                0\n",
      "alkphos             4\n",
      "is_patient          0\n",
      "dtype: int64\n",
      "age                 0\n",
      "gender              0\n",
      "tot_bilirubin       0\n",
      "direct_bilirubin    0\n",
      "tot_proteins        0\n",
      "albumin             0\n",
      "ag_ratio            0\n",
      "sgpt                0\n",
      "sgot                0\n",
      "alkphos             4\n",
      "is_patient          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for Null or NaN values\n",
    "print(data.isnull().sum())\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               583 non-null    int64  \n",
      " 1   gender            583 non-null    object \n",
      " 2   tot_bilirubin     583 non-null    float64\n",
      " 3   direct_bilirubin  583 non-null    float64\n",
      " 4   tot_proteins      583 non-null    int64  \n",
      " 5   albumin           583 non-null    int64  \n",
      " 6   ag_ratio          583 non-null    int64  \n",
      " 7   sgpt              583 non-null    float64\n",
      " 8   sgot              583 non-null    float64\n",
      " 9   alkphos           579 non-null    float64\n",
      " 10  is_patient        583 non-null    int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Info of the dataset\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age  tot_bilirubin  direct_bilirubin  tot_proteins      albumin  \\\n",
      "count  583.000000     583.000000        583.000000    583.000000   583.000000   \n",
      "mean    44.746141       3.298799          1.486106    290.576329    80.713551   \n",
      "std     16.189833       6.209522          2.808498    242.937989   182.620356   \n",
      "min      4.000000       0.400000          0.100000     63.000000    10.000000   \n",
      "25%     33.000000       0.800000          0.200000    175.500000    23.000000   \n",
      "50%     45.000000       1.000000          0.300000    208.000000    35.000000   \n",
      "75%     58.000000       2.600000          1.300000    298.000000    60.500000   \n",
      "max     90.000000      75.000000         19.700000   2110.000000  2000.000000   \n",
      "\n",
      "          ag_ratio        sgpt        sgot     alkphos  is_patient  \n",
      "count   583.000000  583.000000  583.000000  579.000000  583.000000  \n",
      "mean    109.910806    6.483190    3.141852    0.947064    1.286449  \n",
      "std     288.918529    1.085451    0.795519    0.319592    0.452490  \n",
      "min      10.000000    2.700000    0.900000    0.300000    1.000000  \n",
      "25%      25.000000    5.800000    2.600000    0.700000    1.000000  \n",
      "50%      42.000000    6.600000    3.100000    0.930000    1.000000  \n",
      "75%      87.000000    7.200000    3.800000    1.100000    2.000000  \n",
      "max    4929.000000    9.600000    5.500000    2.800000    2.000000  \n"
     ]
    }
   ],
   "source": [
    "#standard statistic measures\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 0\n",
      "gender              0\n",
      "tot_bilirubin       0\n",
      "direct_bilirubin    0\n",
      "tot_proteins        0\n",
      "albumin             0\n",
      "ag_ratio            0\n",
      "sgpt                0\n",
      "sgot                0\n",
      "alkphos             0\n",
      "is_patient          0\n",
      "dtype: int64\n",
      "age                 0\n",
      "gender              0\n",
      "tot_bilirubin       0\n",
      "direct_bilirubin    0\n",
      "tot_proteins        0\n",
      "albumin             0\n",
      "ag_ratio            0\n",
      "sgpt                0\n",
      "sgot                0\n",
      "alkphos             0\n",
      "is_patient          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Removing the Null or NaN values.\n",
    "data1 = data\n",
    "data1 = data1.fillna(data1.mean())\n",
    "print(data1.isna().sum())\n",
    "print(data1.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above that now there is no NaN or Null values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       age  tot_bilirubin  direct_bilirubin  tot_proteins  \\\n",
      "age               1.000000       0.011763          0.007529      0.080425   \n",
      "tot_bilirubin     0.011763       1.000000          0.874618      0.206669   \n",
      "direct_bilirubin  0.007529       0.874618          1.000000      0.234939   \n",
      "tot_proteins      0.080425       0.206669          0.234939      1.000000   \n",
      "albumin           0.086883       0.214065          0.233894      0.125680   \n",
      "ag_ratio          0.019910       0.237831          0.257544      0.167196   \n",
      "sgpt              0.187461       0.008099          0.000139      0.028514   \n",
      "sgot              0.265924       0.222250          0.228531      0.165453   \n",
      "alkphos           0.216089       0.206159          0.200004      0.233960   \n",
      "is_patient        0.137351       0.220208          0.246046      0.184866   \n",
      "\n",
      "                   albumin  ag_ratio      sgpt      sgot   alkphos  is_patient  \n",
      "age               0.086883  0.019910  0.187461  0.265924  0.216089    0.137351  \n",
      "tot_bilirubin     0.214065  0.237831  0.008099  0.222250  0.206159    0.220208  \n",
      "direct_bilirubin  0.233894  0.257544  0.000139  0.228531  0.200004    0.246046  \n",
      "tot_proteins      0.125680  0.167196  0.028514  0.165453  0.233960    0.184866  \n",
      "albumin           1.000000  0.791966  0.042518  0.029742  0.002374    0.163416  \n",
      "ag_ratio          0.791966  1.000000  0.025645  0.085290  0.070024    0.151934  \n",
      "sgpt              0.042518  0.025645  1.000000  0.784053  0.233904    0.035008  \n",
      "sgot              0.029742  0.085290  0.784053  1.000000  0.686322    0.161388  \n",
      "alkphos           0.002374  0.070024  0.233904  0.686322  1.000000    0.162319  \n",
      "is_patient        0.163416  0.151934  0.035008  0.161388  0.162319    1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd83c498c90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking for Correlation as to reduce dimensionality\n",
    "print(data1.corr().abs())\n",
    "sns.heatmap(data1.corr().abs(), annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above the highest correlation between different columns is 0.87(\"tot_bilirubin\",\"direct_bilirubin\"), which means they are 87% similar and 13% different. So, it is not appropriate to remove any of the coulmns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  albumin  \\\n",
      "0   65       1            0.7               0.1           187       16   \n",
      "1   62       0           10.9               5.5           699       64   \n",
      "2   62       0            7.3               4.1           490       60   \n",
      "3   58       0            1.0               0.4           182       14   \n",
      "4   72       0            3.9               2.0           195       27   \n",
      "\n",
      "   ag_ratio  sgpt  sgot  alkphos  is_patient  \n",
      "0        18   6.8   3.3     0.90           1  \n",
      "1       100   7.5   3.2     0.74           1  \n",
      "2        68   7.0   3.3     0.89           1  \n",
      "3        20   6.8   3.4     1.00           1  \n",
      "4        59   7.3   2.4     0.40           1  \n"
     ]
    }
   ],
   "source": [
    "#LabelEncoding for gender \n",
    "data1[\"gender\"] = data1[\"gender\"].map({\"Male\":0, \"Female\":1})\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               583 non-null    int64  \n",
      " 1   gender            583 non-null    int64  \n",
      " 2   tot_bilirubin     583 non-null    float64\n",
      " 3   direct_bilirubin  583 non-null    float64\n",
      " 4   tot_proteins      583 non-null    int64  \n",
      " 5   albumin           583 non-null    int64  \n",
      " 6   ag_ratio          583 non-null    int64  \n",
      " 7   sgpt              583 non-null    float64\n",
      " 8   sgot              583 non-null    float64\n",
      " 9   alkphos           583 non-null    float64\n",
      " 10  is_patient        583 non-null    int64  \n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 50.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"zero\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n",
      "583\n",
      "408\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the dataset so that the data scales properly on the algorithms. \n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = data1.drop('is_patient', axis=1)\n",
    "y = data1[[\"is_patient\"]]\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=99)\n",
    "data_training = pd.concat([X_train, y_train], axis=1)\n",
    "data_test = pd.concat([X_test, y_test], axis=1)\n",
    "df = data_training.values\n",
    "df_test = data_test.values\n",
    "data_training = min_max_scaler.fit_transform(df)\n",
    "data_testing = min_max_scaler.transform(df_test)\n",
    "\n",
    "data_norm = pd.DataFrame(data_training, columns=data1.columns)\n",
    "X_train = data_norm.drop(\"is_patient\", axis=1)\n",
    "y_train = data_norm[[\"is_patient\"]]\n",
    "\n",
    "data_normed = pd.DataFrame(data_testing, columns = data1.columns)\n",
    "X_test = data_normed.drop(\"is_patient\", axis=1)\n",
    "y_test = data_normed[[\"is_patient\"]]\n",
    "\n",
    "X = pd.concat([X_train, X_test], axis=0)\n",
    "y = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "print(len(data_norm))\n",
    "print(len(data_normed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'gender', 'tot_bilirubin', 'direct_bilirubin', 'tot_proteins',\n",
      "       'albumin', 'ag_ratio', 'sgpt', 'sgot', 'alkphos'],\n",
      "      dtype='object')\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "[6 9 1 1 2 3 5 8 4 7]\n",
      "Index(['tot_bilirubin', 'direct_bilirubin'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection \n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=2, verbose=1)\n",
    "print(X_train.columns)\n",
    "rfe.fit(X_train, y_train)\n",
    "print(rfe.ranking_)\n",
    "print(X_train.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Features     Score\n",
      "2     tot_bilirubin  6.898676\n",
      "3  direct_bilirubin  6.847099\n",
      "1            gender  2.643982\n",
      "5           albumin  2.517531\n",
      "6          ag_ratio  2.286247\n",
      "4      tot_proteins  2.161537\n",
      "8              sgot  0.759569\n",
      "9           alkphos  0.571888\n",
      "0               age  0.343602\n",
      "7              sgpt  0.066495\n"
     ]
    }
   ],
   "source": [
    "#Univariate Selection \n",
    "#apply SelectKBest class to extract top 5 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_train.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']\n",
    "print(featureScores.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11012629 0.0276339  0.11220069 0.0996144  0.11707356 0.11864939\n",
      " 0.12015717 0.09901281 0.09797589 0.09755591]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Feature Importance\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train,y_train.values.ravel())\n",
    "print(model.feature_importances_)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    416\n",
      "1.0    167\n",
      "Name: is_patient, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 float64\n",
      "gender              float64\n",
      "tot_bilirubin       float64\n",
      "direct_bilirubin    float64\n",
      "tot_proteins        float64\n",
      "albumin             float64\n",
      "ag_ratio            float64\n",
      "sgpt                float64\n",
      "sgot                float64\n",
      "alkphos             float64\n",
      "is_patient          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_norm.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective of Under and Over Sampling :\n",
    "            1) High Precision on Majority Class(0.0). High Precision indicates an example labeled as positive is                  indeed positive (small number of FP).\n",
    "            2) High Recall of Minority Class(1.0). High Recall indicates the class is correctly recognized (small                number of FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  gender  tot_bilirubin  direct_bilirubin  tot_proteins   albumin  \\\n",
      "0  0.000000     0.0       0.016447          0.005495      0.139228  0.010050   \n",
      "1  0.567901     0.0       0.023026          0.010989      0.054714  0.005025   \n",
      "2  0.271605     1.0       0.006579          0.005495      0.038593  0.001005   \n",
      "3  0.358025     0.0       0.013158          0.005495      0.065950  0.008040   \n",
      "4  0.851852     0.0       0.049342          0.032967      0.824133  0.046231   \n",
      "\n",
      "   ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "0  0.008174  0.768116  0.673913     0.28         1.0  \n",
      "1  0.003065  0.637681  0.782609     0.56         1.0  \n",
      "2  0.007493  0.434783  0.326087     0.18         0.0  \n",
      "3  0.004428  0.768116  0.673913     0.28         1.0  \n",
      "4  0.044619  0.405797  0.239130     0.08         0.0  \n"
     ]
    }
   ],
   "source": [
    "print(data_norm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52020536 0.69548154]\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "y_temp = y_train\n",
    "y_temp[\"PC1\"] = X_pca[:,0]\n",
    "y_temp[\"PC2\"] = X_pca[:,1]\n",
    "sns.scatterplot(data=y_temp, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp[\"is_patient\"].value_counts())\n",
    "# print(len(y), len(X_pca))\n",
    "#print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_patient       PC1       PC2\n",
      "0         1.0 -0.203093 -0.476366\n",
      "1         1.0 -0.225383 -0.340140\n",
      "2         0.0  0.750240  0.113175\n",
      "3         1.0 -0.219966 -0.335130\n",
      "4         0.0 -0.287818  0.492670\n",
      "   is_patient\n",
      "0         1.0\n",
      "1         1.0\n",
      "2         0.0\n",
      "3         1.0\n",
      "4         0.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head())\n",
    "y_train = y_train.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clfFitPredict(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = clf.predict(X_test)\n",
    "    confusionMatrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aurocPredict(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "    print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y_test, y_pred):\n",
    "    co = confusion_matrix(y_test, y_pred)\n",
    "    print('\\nConfusion Matrix: \\n'+str(co))\n",
    "    \n",
    "    total=co[0,0]+co[1,1]+co[0,1]+co[1,0]\n",
    "    accuracy=(co[0,0]+co[1,1])/total\n",
    "    print('\\nAccuracy : '+ str(accuracy))\n",
    "\n",
    "    sensitivity = co[0,0]/(co[0,0]+co[0,1])\n",
    "    print('Sensitivity : '+ str(sensitivity ))\n",
    "    \n",
    "    precision = co[0,0]/(co[0,0]+co[1,0])\n",
    "    print('Precision: ' + str(precision))\n",
    "\n",
    "    specificity = co[1,1]/(co[1,0]+co[1,1])\n",
    "    print('Specificity : ' + str(specificity))\n",
    "    \n",
    "    fscore = 2*precision*sensitivity/(precision+sensitivity)\n",
    "    print('F-Score : ' + str(fscore))\n",
    "    \n",
    "    print(\"\\n\",classification_report(y_test, y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(confusion_matrix):\n",
    "    co = confusion_matrix\n",
    "    print('\\nConfusion Matrix By taking mean of all individual confusion matrix folds: \\n'+str(co))\n",
    "    \n",
    "    total=co[0,0]+co[1,1]+co[0,1]+co[1,0]\n",
    "    accuracy=(co[0,0]+co[1,1])/total\n",
    "    print('\\nAccuracy : '+ str(accuracy))\n",
    "\n",
    "    sensitivity = co[0,0]/(co[0,0]+co[0,1])\n",
    "    print('Sensitivity : '+ str(sensitivity ))\n",
    "    \n",
    "    precision = co[0,0]/(co[0,0]+co[1,0])\n",
    "    print('Precision: ' + str(precision))\n",
    "\n",
    "    specificity = co[1,1]/(co[1,0]+co[1,1])\n",
    "    print('Specificity : ' + str(specificity))\n",
    "    \n",
    "    fscore = 2*precision*sensitivity/(precision+sensitivity)\n",
    "    print('F-Score : ' + str(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(clf, X, y, folds):\n",
    "    #https://stackoverflow.com/questions/41458834/how-is-scikit-learn-cross-val-predict-accuracy-score-calculated\n",
    "    scoreclf = cross_val_score(clf, X, y.values.ravel(), cv=folds)\n",
    "    print(scoreclf,\"\\n\")\n",
    "    print(np.mean(scoreclf))\n",
    "    \n",
    "#     list_of_confmatrix = []\n",
    "#     kf = KFold(n_splits = folds)\n",
    "#     kf.get_n_splits(X)\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#         X_train_kf, X_test_kf = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train_kf, y_test_kf = y.iloc[train_index], y.iloc[test_index]\n",
    "#         clf.fit(X_train_kf, y_train_kf.values.ravel())\n",
    "#         confmatrix = confusion_matrix(y_test_kf, clf.predict(X_test_kf))\n",
    "#         list_of_confmatrix.append(confmatrix)\n",
    "    \n",
    "#     mean_of_confmatrix = np.mean(list_of_confmatrix, axis=0)\n",
    "#     params(mean_of_confmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['is_patient'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(y_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9230769230769231\n",
      "Specificity : 0.92\n",
      "F-Score : 0.5423728813559322\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.38      0.54       125\n",
      "         1.0       0.37      0.92      0.53        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.65      0.65      0.54       175\n",
      "weighted avg       0.77      0.54      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Original dataset:\n",
      "[0.60273973 0.54109589 0.52739726 0.55172414] \n",
      "\n",
      "0.5557392536608408\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Original dataset\n",
    "print(\"Naive Bayes on Original dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Original datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Original dataset:\")\n",
    "crossValidation(GaussianNB(), X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 48   2]]\n",
      "\n",
      "Accuracy : 0.7257142857142858\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7225433526011561\n",
      "Specificity : 0.04\n",
      "F-Score : 0.8389261744966443\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.84       125\n",
      "         1.0       1.00      0.04      0.08        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.86      0.52      0.46       175\n",
      "weighted avg       0.80      0.73      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Original dataset:\n",
      "[0.73287671 0.70547945 0.69178082 0.73103448] \n",
      "\n",
      "0.7152928672649976\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2 SVM Classifier On the Original Dataset\n",
    "print(\"SVM Classifier on Original dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of SVM Classifier on Original dataset:\")\n",
    "crossValidation(LinearSVC(), X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regressor Classifier on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regressor Classifier on Original dataset:\n",
      "[0.71917808 0.70547945 0.7260274  0.71724138] \n",
      "\n",
      "0.7169815777042986\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3 Logistic Regressor Classifier On the Original Dataset \n",
    "print(\"Logistic Regressor Classifier on Original dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regressor Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of Logistic Regressor Classifier on Original dataset:\")\n",
    "crossValidation(LogisticRegression(), X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " KNN Classifier on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[116   9]\n",
      " [ 44   6]]\n",
      "\n",
      "Accuracy : 0.6971428571428572\n",
      "Sensitivity : 0.928\n",
      "Precision: 0.725\n",
      "Specificity : 0.12\n",
      "F-Score : 0.8140350877192983\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.93      0.81       125\n",
      "         1.0       0.40      0.12      0.18        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.56      0.52      0.50       175\n",
      "weighted avg       0.63      0.70      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of  KNN Classifier  on Original dataset:\n",
      "[0.71232877 0.65068493 0.70547945 0.71034483] \n",
      "\n",
      "0.6947094945677845\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4 KNN Classifier On the Original Dataset \n",
    "print(\" KNN Classifier on Original dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of  KNN Classifier  on Original dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "RandomForest Classifier on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[121   4]\n",
      " [ 43   7]]\n",
      "\n",
      "Accuracy : 0.7314285714285714\n",
      "Sensitivity : 0.968\n",
      "Precision: 0.7378048780487805\n",
      "Specificity : 0.14\n",
      "F-Score : 0.8373702422145328\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84       125\n",
      "         1.0       0.64      0.14      0.23        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.69      0.55      0.53       175\n",
      "weighted avg       0.71      0.73      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of  RandomForest Classifier on Original dataset:\n",
      "[0.68493151 0.70547945 0.71232877 0.71724138] \n",
      "\n",
      "0.7049952763344355\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5 RandomForest Classifier On the Original Dataset \n",
    "print(\"RandomForest Classifier on Original dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on RandomForest Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of  RandomForest Classifier on Original dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 48   2]]\n",
      "\n",
      "Accuracy : 0.7257142857142858\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7225433526011561\n",
      "Specificity : 0.04\n",
      "F-Score : 0.8389261744966443\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.84       125\n",
      "         1.0       1.00      0.04      0.08        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.86      0.52      0.46       175\n",
      "weighted avg       0.80      0.73      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Original dataset:\n",
      "[0.7260274  0.70547945 0.71232877 0.73103448] \n",
      "\n",
      "0.7187175247992443\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Original Dataset\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "print(\"Voting Classifier on Original dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of Voting Classifier on Original dataset:\")\n",
    "crossValidation(vclf, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoost Classifier on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[124   1]\n",
      " [ 47   3]]\n",
      "\n",
      "Accuracy : 0.7257142857142858\n",
      "Sensitivity : 0.992\n",
      "Precision: 0.7251461988304093\n",
      "Specificity : 0.06\n",
      "F-Score : 0.8378378378378378\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.99      0.84       125\n",
      "         1.0       0.75      0.06      0.11        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.74      0.53      0.47       175\n",
      "weighted avg       0.73      0.73      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Original dataset:\n",
      "[0.71232877 0.73287671 0.7260274  0.71724138] \n",
      "\n",
      "0.7221185640056684\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVM as base estimator on Original dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Original dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71232877 0.71232877 0.71232877 0.71724138] \n",
      "\n",
      "0.7135569201700519\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#AdaBoostClassifier With Decision Tree Classifier as base estimator \n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoost Classifier on Original dataset:\")\n",
    "clfFitPredict(adb_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Original dataset:\")\n",
    "crossValidation(adb_clf, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc = AdaBoostClassifier(base_estimator=svc_adb, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVM as base estimator on Original dataset:\")\n",
    "clfFitPredict(adb_clf_svc, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Orginial datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Original dataset:\")\n",
    "crossValidation(adb_clf_svc, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on Original dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[112  13]\n",
      " [ 29  21]]\n",
      "\n",
      "Accuracy : 0.76\n",
      "Sensitivity : 0.896\n",
      "Precision: 0.7943262411347518\n",
      "Specificity : 0.42\n",
      "F-Score : 0.8421052631578948\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84       125\n",
      "         1.0       0.62      0.42      0.50        50\n",
      "\n",
      "    accuracy                           0.76       175\n",
      "   macro avg       0.71      0.66      0.67       175\n",
      "weighted avg       0.74      0.76      0.74       175\n",
      " \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Original dataset:\n",
      "[0.7260274  0.70547945 0.69863014 0.74482759] \n",
      "\n",
      "0.7187411431270667\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#GradientBoostingClassifier On Original Dataset\n",
    "\n",
    "gbc = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on Original dataset :\")\n",
    "clfFitPredict(gbc, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Orginial datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Original dataset:\")\n",
    "crossValidation(gbc, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "XGBClassifier on Original dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Original dataset:\n",
      "[0.71232877 0.71232877 0.71232877 0.71724138] \n",
      "\n",
      "0.7135569201700519\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#XGBClassifier on the Original Dataset\n",
    "\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"XGBClassifier on Original dataset :\")\n",
    "clfFitPredict(xgb_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Orginial datset\n",
    "print(\"\\nCross Validation of XGBClassifier on Original dataset:\")\n",
    "crossValidation(xgb_clf, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on Original dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[111  14]\n",
      " [ 37  13]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.888\n",
      "Precision: 0.75\n",
      "Specificity : 0.26\n",
      "F-Score : 0.8131868131868133\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.89      0.81       125\n",
      "         1.0       0.48      0.26      0.34        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.62      0.57      0.58       175\n",
      "weighted avg       0.67      0.71      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on Original dataset :\n",
      "[0.67123288 0.67808219 0.70547945 0.67586207] \n",
      "\n",
      "0.6826641473783657\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[111  14]\n",
      " [ 37  13]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.888\n",
      "Precision: 0.75\n",
      "Specificity : 0.26\n",
      "F-Score : 0.8131868131868133\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.89      0.81       125\n",
      "         1.0       0.48      0.26      0.34        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.62      0.57      0.58       175\n",
      "weighted avg       0.67      0.71      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On Original Dataset\n",
      "[0.67123288 0.67808219 0.70547945 0.67586207] \n",
      "\n",
      "0.6826641473783657\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[124   1]\n",
      " [ 48   2]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.992\n",
      "Precision: 0.7209302325581395\n",
      "Specificity : 0.04\n",
      "F-Score : 0.835016835016835\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.99      0.84       125\n",
      "         1.0       0.67      0.04      0.08        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.69      0.52      0.46       175\n",
      "weighted avg       0.71      0.72      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On Original Dataset\n",
      "[0.71917808 0.67123288 0.67123288 0.71034483] \n",
      "\n",
      "0.6929971658006613\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 40  10]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7202797202797203\n",
      "Specificity : 0.2\n",
      "F-Score : 0.7686567164179103\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.82      0.77       125\n",
      "         1.0       0.31      0.20      0.24        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.52      0.51      0.51       175\n",
      "weighted avg       0.60      0.65      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On Original Dataset\n",
      "[0.69178082 0.64383562 0.64383562 0.68275862] \n",
      "\n",
      "0.665552668871044\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On Original Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71232877 0.71232877 0.71232877 0.71724138] \n",
      "\n",
      "0.7135569201700519\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[114  11]\n",
      " [ 39  11]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 0.912\n",
      "Precision: 0.7450980392156863\n",
      "Specificity : 0.22\n",
      "F-Score : 0.8201438848920864\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.91      0.82       125\n",
      "         1.0       0.50      0.22      0.31        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.62      0.57      0.56       175\n",
      "weighted avg       0.68      0.71      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On Original Dataset\n",
      "[0.68493151 0.69863014 0.71917808 0.70344828] \n",
      "\n",
      "0.7015470004723665\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On Original Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71917808 0.70547945 0.7260274  0.71724138] \n",
      "\n",
      "0.7169815777042986\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the Original Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on Original dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on Original dataset :\")\n",
    "crossValidation(clf_bagging, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On Original Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train, X_test, y_train, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On Original Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X, y, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on Original dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[107  18]\n",
      " [ 34  16]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.856\n",
      "Precision: 0.7588652482269503\n",
      "Specificity : 0.32\n",
      "F-Score : 0.8045112781954887\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.86      0.80       125\n",
      "         1.0       0.47      0.32      0.38        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.61      0.59      0.59       175\n",
      "weighted avg       0.68      0.70      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on Original dataset :\n",
      "[0.71232877 0.71232877 0.54109589 0.5862069 ] \n",
      "\n",
      "0.6379900803023146\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The Original Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on Original dataset :\")\n",
    "clfFitPredict(clf_percept, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on Orginial datset\n",
    "print(\"\\nCross Validation of Perceptron on Original dataset :\")\n",
    "crossValidation(clf_percept, X, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    125\n",
      "1.0     50\n",
      "Name: is_patient, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "408/408 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.6152\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 0s 232us/step - loss: 0.6765 - accuracy: 0.7132\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 0s 264us/step - loss: 0.6434 - accuracy: 0.7132\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 0s 298us/step - loss: 0.5988 - accuracy: 0.7132\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 0s 255us/step - loss: 0.5828 - accuracy: 0.7132\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 0s 230us/step - loss: 0.5704 - accuracy: 0.7132\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 0s 283us/step - loss: 0.5593 - accuracy: 0.7132\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 0s 223us/step - loss: 0.5477 - accuracy: 0.7132\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 0s 224us/step - loss: 0.5385 - accuracy: 0.7132\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 0s 283us/step - loss: 0.5344 - accuracy: 0.7108\n",
      "408/408 [==============================] - 0s 174us/step\n",
      "\n",
      "Model on Training Data - [0.5272871098097633, 0.7107843160629272]\n",
      "175/175 [==============================] - 0s 59us/step\n",
      "\n",
      "Model on Testing Data - [0.5215767061710358, 0.7142857313156128]\n"
     ]
    }
   ],
   "source": [
    "#Neural Networks\n",
    "model=Sequential()\n",
    "model.add(Dense(16,input_shape=(10,))) \n",
    "model.add(Dense(8,activation='relu')) \n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=10)\n",
    "#print(history.history['loss'])\n",
    "preds = model.predict(X_test)\n",
    "#print(preds)\n",
    "print(\"\\nModel on Training Data -\", model.evaluate(X_train, y_train))\n",
    "print(\"\\nModel on Testing Data -\", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52020536 0.69548154 0.80807882 0.89162226 0.93410336 0.9663823\n",
      " 0.99381232 0.99730793 0.99913325 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With PCA Training dataset\n",
    "\n",
    "pca_1 = PCA()\n",
    "X_pca_1 = pca_1.fit_transform(X_train)\n",
    "print(pca_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca1 = PCA(n_components=6)\n",
    "X_pca_train1 = pd.DataFrame(pca1.fit_transform(X_train))\n",
    "X_pca_test1 = pd.DataFrame(pca1.transform(X_test))\n",
    "\n",
    "X_pca1 = pd.concat([X_pca_train1, X_pca_test1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[78 47]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.624\n",
      "Precision: 0.8297872340425532\n",
      "Specificity : 0.68\n",
      "F-Score : 0.7123287671232877\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.62      0.71       125\n",
      "         1.0       0.42      0.68      0.52        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.62      0.65      0.62       175\n",
      "weighted avg       0.71      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on PCA Training dataset:\n",
      "[0.54109589 0.65068493 0.60958904 0.62068966] \n",
      "\n",
      "0.6055148795465282\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on PCA Training dataset:\n",
      "[0.71232877 0.70547945 0.69863014 0.71724138] \n",
      "\n",
      "0.7084199338686822\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on PCA Training dataset::\n",
      "[0.71917808 0.70547945 0.73287671 0.71724138] \n",
      "\n",
      "0.7186939064714218\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[117   8]\n",
      " [ 45   5]]\n",
      "\n",
      "Accuracy : 0.6971428571428572\n",
      "Sensitivity : 0.936\n",
      "Precision: 0.7222222222222222\n",
      "Specificity : 0.1\n",
      "F-Score : 0.8153310104529617\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.94      0.82       125\n",
      "         1.0       0.38      0.10      0.16        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.55      0.52      0.49       175\n",
      "weighted avg       0.63      0.70      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on PCA Training dataset:\n",
      "[0.69178082 0.6369863  0.71917808 0.71724138] \n",
      "\n",
      "0.6912966461974492\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[121   4]\n",
      " [ 47   3]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.968\n",
      "Precision: 0.7202380952380952\n",
      "Specificity : 0.06\n",
      "F-Score : 0.8259385665529009\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.83       125\n",
      "         1.0       0.43      0.06      0.11        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.57      0.51      0.47       175\n",
      "weighted avg       0.64      0.71      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on PCA Training dataset:\n",
      "[0.69863014 0.70547945 0.69178082 0.71724138] \n",
      "\n",
      "0.7032829475673122\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on PCA Training dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71917808 0.70547945 0.71917808 0.71724138] \n",
      "\n",
      "0.7152692489371753\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "AdaBoostClassifier with Decision Tree Classifier as base estimator\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on PCA Training dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71232877 0.71232877 0.69863014 0.71724138] \n",
      "\n",
      "0.7101322626358054\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier With SVC as base estimator on PCA Training Dataset \n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVC as base estimator on PCA Training dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71232877 0.71232877 0.71232877 0.71724138] \n",
      "\n",
      "0.7135569201700519\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[110  15]\n",
      " [ 39  11]]\n",
      "\n",
      "Accuracy : 0.6914285714285714\n",
      "Sensitivity : 0.88\n",
      "Precision: 0.738255033557047\n",
      "Specificity : 0.22\n",
      "F-Score : 0.8029197080291972\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.88      0.80       125\n",
      "         1.0       0.42      0.22      0.29        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.58      0.55      0.55       175\n",
      "weighted avg       0.65      0.69      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on PCA Training dataset:\n",
      "[0.70547945 0.70547945 0.67808219 0.68275862] \n",
      "\n",
      "0.6929499291450165\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on PCA Training dataset:\n",
      "[0.71232877 0.71232877 0.71232877 0.71724138] \n",
      "\n",
      "0.7135569201700519\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on Original dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[105  20]\n",
      " [ 36  14]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.84\n",
      "Precision: 0.7446808510638298\n",
      "Specificity : 0.28\n",
      "F-Score : 0.7894736842105262\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.84      0.79       125\n",
      "         1.0       0.41      0.28      0.33        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.58      0.56      0.56       175\n",
      "weighted avg       0.65      0.68      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on Original dataset :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71232877 0.65753425 0.71232877 0.73793103] \n",
      "\n",
      "0.7050307038261691\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[105  20]\n",
      " [ 36  14]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.84\n",
      "Precision: 0.7446808510638298\n",
      "Specificity : 0.28\n",
      "F-Score : 0.7894736842105262\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.84      0.79       125\n",
      "         1.0       0.41      0.28      0.33        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.58      0.56      0.56       175\n",
      "weighted avg       0.65      0.68      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On Original Dataset\n",
      "[0.71232877 0.65753425 0.71232877 0.73793103] \n",
      "\n",
      "0.7050307038261691\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[109  16]\n",
      " [ 40  10]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.872\n",
      "Precision: 0.7315436241610739\n",
      "Specificity : 0.2\n",
      "F-Score : 0.7956204379562044\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.87      0.80       125\n",
      "         1.0       0.38      0.20      0.26        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.56      0.54      0.53       175\n",
      "weighted avg       0.63      0.68      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On Original Dataset\n",
      "[0.71232877 0.71232877 0.68493151 0.71724138] \n",
      "\n",
      "0.7067076051015588\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[105  20]\n",
      " [ 43   7]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.84\n",
      "Precision: 0.7094594594594594\n",
      "Specificity : 0.14\n",
      "F-Score : 0.769230769230769\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.84      0.77       125\n",
      "         1.0       0.26      0.14      0.18        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.48      0.49      0.48       175\n",
      "weighted avg       0.58      0.64      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On Original Dataset\n",
      "[0.67808219 0.65068493 0.61643836 0.68275862] \n",
      "\n",
      "0.6569910250354275\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On Original Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70547945 0.71232877 0.71232877 0.71034483] \n",
      "\n",
      "0.7101204534718941\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[117   8]\n",
      " [ 40  10]]\n",
      "\n",
      "Accuracy : 0.7257142857142858\n",
      "Sensitivity : 0.936\n",
      "Precision: 0.7452229299363057\n",
      "Specificity : 0.2\n",
      "F-Score : 0.8297872340425532\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.94      0.83       125\n",
      "         1.0       0.56      0.20      0.29        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.65      0.57      0.56       175\n",
      "weighted avg       0.69      0.73      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On Original Dataset\n",
      "[0.69178082 0.69863014 0.7260274  0.71034483] \n",
      "\n",
      "0.7066957959376476\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On Original Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On Original Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7260274  0.70547945 0.73287671 0.71724138] \n",
      "\n",
      "0.7204062352385452\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on Original dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[123   2]\n",
      " [ 45   5]]\n",
      "\n",
      "Accuracy : 0.7314285714285714\n",
      "Sensitivity : 0.984\n",
      "Precision: 0.7321428571428571\n",
      "Specificity : 0.1\n",
      "F-Score : 0.8395904436860068\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.98      0.84       125\n",
      "         1.0       0.71      0.10      0.18        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.72      0.54      0.51       175\n",
      "weighted avg       0.73      0.73      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on Original dataset :\n",
      "[0.5890411  0.59589041 0.56164384 0.71724138] \n",
      "\n",
      "0.6159541804440246\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On PCA Training dataset\n",
    "print(\"Naive Bayes on PCA Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on PCA Training dataset:\n",
    "print(\"\\nCross Validation of Naive Bayes on PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On PCA Training dataset:\n",
    "print(\"SVM Classifier on PCA Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on PCA Training dataset:\n",
    "print(\"\\nCross Validation of SVM Classifier on PCA Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On PCA Training dataset:\n",
    "print(\"Logistic Regression Classifier on PCA Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on PCA Training dataset:\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on PCA Training dataset::\")\n",
    "crossValidation(LogisticRegression(), X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On PCA Training dataset\n",
    "print(\"KNN Classifier on PCA Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on PCA Training dataset:\n",
    "print(\"\\nCross Validation of KNN Classifier on PCA Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On PCA Training dataset:\n",
    "print(\"Random Forest Classifier on PCA Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on PCA Training dataset:\n",
    "print(\"\\nCross Validation of Random Forest Classifier on PCA Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for PCA Training dataset:\n",
    "print(\"Voting Classifier on PCA Training dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on PCA Training dataset:\n",
    "print(\"\\nCross Validation of Voting Classifier on PCA Training dataset:\")\n",
    "crossValidation(vclf, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With DecisionTree as base estimator on PCA Training Dataset \n",
    "print(\"AdaBoostClassifier with Decision Tree Classifier as base estimator\")\n",
    "clfFitPredict(adb_clf, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier with DecisionTree as base estimator on PCA Training Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on PCA Training dataset:\")\n",
    "crossValidation(adb_clf, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC on PCA Training Dataset \n",
    "print(\"\\nAdaBoostClassifier With SVC as base estimator on PCA Training Dataset \")\n",
    "clfFitPredict(adb_clf_svc, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier with SVC on PCA Training dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVC as base estimator on PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On PCA Training Dataset\n",
    "print(\"\\nGradientBoostingClassifier on PCA Training Dataset\")\n",
    "clfFitPredict(gbc, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on PCA Training dataset:\")\n",
    "crossValidation(gbc, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on PCA Training Dataset\n",
    "print(\"\\nXGBClassifier on PCA Training Dataset\")\n",
    "clfFitPredict(xgb_clf, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on PCA Training Dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on PCA Training dataset:\")\n",
    "crossValidation(xgb_clf, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#11 Bagging Classifier on PCA Training Dataset  \n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on Original dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on Orginial datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on Original dataset :\")\n",
    "crossValidation(clf_bagging, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On Original Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "    \n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On Original Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca1, y, 4)\n",
    "    \n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#12 Perceptron on Original PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on Original dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train1, X_pca_test1, y_train, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on Orginial datset\n",
    "print(\"\\nCross Validation of Perceptron on Original dataset :\")\n",
    "crossValidation(clf_percept, X_pca1, y, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "408/408 [==============================] - 0s 886us/step - loss: 0.7217 - accuracy: 0.3431\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 0s 218us/step - loss: 0.6886 - accuracy: 0.6324\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 0s 252us/step - loss: 0.6784 - accuracy: 0.7034\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 0s 289us/step - loss: 0.6716 - accuracy: 0.7132\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 0s 245us/step - loss: 0.6656 - accuracy: 0.7132\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 0s 235us/step - loss: 0.6604 - accuracy: 0.7132\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 0s 300us/step - loss: 0.6553 - accuracy: 0.7132\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 0s 248us/step - loss: 0.6505 - accuracy: 0.7132\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 0s 253us/step - loss: 0.6463 - accuracy: 0.7132\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 0s 257us/step - loss: 0.6422 - accuracy: 0.7132\n",
      "408/408 [==============================] - 0s 126us/step\n",
      "\n",
      "Model on Training Data - 0.7132353186607361\n",
      "175/175 [==============================] - 0s 75us/step\n",
      "\n",
      "Model on Testing Data - 0.7142857313156128\n"
     ]
    }
   ],
   "source": [
    "#Neural Networks On Original turned PCA dataset\n",
    "model=Sequential()\n",
    "model.add(Dense(16,input_shape=(6,))) \n",
    "model.add(Dense(8,activation='relu')) \n",
    "model.add(Dense(4,activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#X_pca_train1, X_pca_test1, y_train, y_test\n",
    "history = model.fit(X_pca_train1, y_train, batch_size=10, epochs=10)\n",
    "#print(history.history['loss'])\n",
    "preds = model.predict(X_pca_test1)\n",
    "#print(preds)\n",
    "print(\"\\nModel on Training Data -\", model.evaluate(X_pca_train1, y_train)[1])\n",
    "print(\"\\nModel on Testing Data -\", model.evaluate(X_pca_test1, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = {'C':[0.1, 1, 10, 50, 100, 500, 1000, 1500], \n",
    "              'gamma': [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 'scale', 'auto'], \n",
    "              'kernel': ['rbf', 'linear', 'poly', 'rbf', 'sigmoid']\n",
    "             }\n",
    "\n",
    "param_grid_logreg = {'penalty':['l1', 'l2', 'elasticnet'],\n",
    "              'C':[0.1, 1, 10, 50, 100, 500, 1000, 1500], \n",
    "              'solver':['liblinear', 'lbfgs', 'saga','newton-cg']\n",
    "             }\n",
    "\n",
    "\n",
    "param_grid_rf = {'n_estimators':[16, 32, 64, 100, 300, 500, 800, 1000, 1250, 1500], \n",
    "              'max_features':['auto', 'sqrt'],\n",
    "              'max_depth':np.linspace(1, 32, 32),\n",
    "              'min_samples_split': np.linspace(0.1, 1.0, 10),\n",
    "              'min_samples_leaf': np.linspace(0.1, 0.5, 5),\n",
    "              'bootstrap': [True, False]\n",
    "             }\n",
    "param_grid_knn = {'leaf_size':list(range(1,50)),\n",
    "              'n_neighbors':list(range(1,30)),\n",
    "              'p':[1, 2, 3, 4, 5], \n",
    "              'weights':['uniform', 'distance'],\n",
    "              'algorithm':['auto', 'ball_tree','kd_tree','brute']\n",
    "             }\n",
    "\n",
    "param_grid_gbc  = {'learning_rate':[1, 0.5, 0.25, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "               'n_estimators':[32, 64, 100, 300, 500, 750, 1000, 1250, 1500],\n",
    "               'max_depth' : np.linspace(1, 32, 32, endpoint=True),\n",
    "               'min_samples_split' : np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "               'min_samples_leaf' : np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "              }\n",
    "\n",
    "param_grid_adc = {'n_estimators': [16, 32, 64, 100, 300, 500, 800, 1000, 1250, 1500],\n",
    "              'learning_rate':[1, 0.5, 0.25, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "              'algorithm':['SAMME', 'SAMME.R']\n",
    "             }\n",
    "\n",
    "param_grid_adc_svc = {'n_estimators': [16, 32, 64, 100, 300, 500, 800, 1000, 1250, 1500],\n",
    "              'learning_rate':[1, 0.5, 0.25, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "              'algorithm':['SAMME', 'SAMME.R']\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC.pkl']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC\n",
    "#https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "random_svc = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_svc.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(random_svc, \"RSCV_SVC.pkl\")\n",
    "# print(\"\\nBest Parameters :\",random.best_params_)\n",
    "# print(\"\\nBest Score :\", random.best_score_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, random.predict(X_test)))\n",
    "# print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV result for SVC on Original Dataset -\n",
      "\n",
      "Best Parameters : {'kernel': 'rbf', 'gamma': 0.0001, 'C': 50}\n",
      "\n",
      "Best Score : 0.7132926829268291\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RSCV_SVC_loaded = joblib.load(\"RSCV_SVC.pkl\")\n",
    "print(\"\\nRandomizedSearchCV result for SVC on Original Dataset -\")\n",
    "print(\"\\nBest Parameters :\",RSCV_SVC_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_SVC_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_loaded.predict(X_test)))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_pca.pkl']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_svc_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_svc_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(random_svc_pca, \"RSCV_SVC_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results on SVC with PCA Original Dataset - \n",
      "\n",
      "Best Parameters : {'kernel': 'rbf', 'gamma': 0.0001, 'C': 50}\n",
      "\n",
      "Best Score : 0.7132926829268291\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results on SVC with PCA Original Dataset - \")\n",
    "RSCV_SVC_pca_loaded = joblib.load(\"RSCV_SVC_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_SVC_pca_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_SVC_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_pca_loaded.predict(X_pca_test1)))\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR.pkl']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression \n",
    "\n",
    "#https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "random_logreg = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,\n",
    "                            scoring='accuracy', \n",
    "                            refit=True,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1,\n",
    "                            n_iter=100,\n",
    "                            random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(random_logreg, \"RSCV_LR.pkl\")\n",
    "# print(\"\\nBest Parameters :\",random_logreg.best_params_) \n",
    "# print(\"\\nBest Score :\",random.best_score_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, random_logreg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results for Logisitic Regression On Original Dataset -\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l1', 'C': 50}\n",
      "\n",
      "Best Score : 0.7182317073170732\n",
      "\n",
      "Accuracy Score : 0.7371428571428571\n"
     ]
    }
   ],
   "source": [
    "RSCV_LR_loaded = joblib.load(\"RSCV_LR.pkl\")\n",
    "print(\"\\nRandomizedSearchCV results for Logisitic Regression On Original Dataset -\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca.pkl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logreg_pca = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(random_logreg_pca, \"RSCV_LR_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results on LR with PCA Original Dataset - \n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 1}\n",
      "\n",
      "Best Score : 0.715731707317073\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results on LR with PCA Original Dataset - \")\n",
    "RSCV_LR_pca_loaded = joblib.load(\"RSCV_LR_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_pca_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_loaded.predict(X_pca_test1)))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF.pkl']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest \n",
    "#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "#https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6\n",
    "\n",
    "random_rf = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False, \n",
    "                               cv=10,\n",
    "                               scoring='accuracy', \n",
    "                               refit=True,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=0\n",
    "                              )\n",
    "random_rf.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(random_rf, \"RSCV_RF.pkl\")\n",
    "# print(\"\\nBest Parameter :\",random_rf.best_params_)\n",
    "# print(\"\\nBest Score :\", random_rf.best_score_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, random_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results for Random Forest on Original Dataset -\n",
      "\n",
      "Best Parameter : {'n_estimators': 64, 'min_samples_split': 0.4, 'min_samples_leaf': 0.30000000000000004, 'max_features': 'sqrt', 'max_depth': 3.0, 'bootstrap': True}\n",
      "\n",
      "Best Score : 0.7132926829268291\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "RSCV_RF_loaded = joblib.load(\"RSCV_RF.pkl\")\n",
    "print(\"\\nRandomizedSearchCV results for Random Forest on Original Dataset -\")\n",
    "print(\"\\nBest Parameter :\",RSCV_RF_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   28.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca.pkl']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rf_pca = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_rf_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(random_rf_pca, \"RSCV_RF_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results on RF with PCA Original Dataset - \n",
      "\n",
      "Best Parameters : {'n_estimators': 64, 'min_samples_split': 0.4, 'min_samples_leaf': 0.30000000000000004, 'max_features': 'sqrt', 'max_depth': 3.0, 'bootstrap': True}\n",
      "\n",
      "Best Score : 0.7132926829268291\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results on RF with PCA Original Dataset - \")\n",
    "RSCV_RF_pca_loaded = joblib.load(\"RSCV_RF_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_RF_pca_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_loaded.predict(X_pca_test1)))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_knn.pkl']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning in KNN \n",
    "#https://medium.com/@mohtedibf/in-depth-parameter-tuning-for-knn-4c0de485baf6\n",
    "#https://medium.com/datadriveninvestor/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f\n",
    "#https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn\n",
    "\n",
    "clf_knn = RandomizedSearchCV( estimator = KNeighborsClassifier(), \n",
    "                    param_distributions = param_grid_knn,\n",
    "                    cv=10,\n",
    "                    verbose=False,\n",
    "                    scoring='accuracy', \n",
    "                    refit=True,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=0\n",
    "                  )\n",
    "clf_knn.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(clf_knn, \"RSCV_knn.pkl\")\n",
    "# print(\"\\nBest Params :\",clf_knn.best_params_) \n",
    "# print(\"\\nBest Score :\",clf_knn.best_score_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, clf_knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results for KNN on Original Dataset -\n",
      "\n",
      "Best Params : {'weights': 'uniform', 'p': 4, 'n_neighbors': 22, 'leaf_size': 34, 'algorithm': 'brute'}\n",
      "\n",
      "Best Score : 0.7060365853658536\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "RSCV_knn_loaded = joblib.load('RSCV_knn.pkl') \n",
    "print(\"\\nRandomizedSearchCV results for KNN on Original Dataset -\")\n",
    "print(\"\\nBest Params :\", RSCV_knn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_knn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_knn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_KNN_pca.pkl']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_knn_pca = RandomizedSearchCV(estimator = KNeighborsClassifier(), \n",
    "                            param_distributions = param_grid_knn, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_knn_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(random_knn_pca, \"RSCV_KNN_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results on KNN with PCA Original Dataset - \n",
      "\n",
      "Best Parameters : {'weights': 'uniform', 'p': 4, 'n_neighbors': 22, 'leaf_size': 34, 'algorithm': 'brute'}\n",
      "\n",
      "Best Score : 0.6915243902439026\n",
      "\n",
      "Accuracy Score : 0.7257142857142858\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results on KNN with PCA Original Dataset - \")\n",
    "RSCV_KNN_pca_loaded = joblib.load(\"RSCV_KNN_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_KNN_pca_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_KNN_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_KNN_pca_loaded.predict(X_pca_test1)))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC.pkl']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier\n",
    "#https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "#https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae\n",
    "#https://www.datacareer.de/blog/parameter-tuning-in-gradient-boosting-gbm/\n",
    "\n",
    "clf_gbc = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy',\n",
    "                             refit=True, \n",
    "                             n_jobs=-1,\n",
    "                             verbose=False,\n",
    "                             random_state=0\n",
    "                            )\n",
    "clf_gbc.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(clf_gbc,'RSCV_GBC.pkl')\n",
    "# print(\"\\nBest Score :\",clf_gbc.best_score_)\n",
    "# print(\"\\nBest Parameters :\",clf_gbc.best_params_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, clf_gbc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV result for GradientBoostingClassifier with Original Dataset -\n",
      "\n",
      "Best Score : 0.7132926829268291\n",
      "\n",
      "Best Parameters : {'n_estimators': 1250, 'min_samples_split': 0.1, 'min_samples_leaf': 0.5, 'max_depth': 1.0, 'learning_rate': 0.1}\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV result for GradientBoostingClassifier with Original Dataset -\")\n",
    "RSCV_GBC_loaded = joblib.load('RSCV_GBC.pkl')\n",
    "print(\"\\nBest Score :\", RSCV_GBC_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca.pkl']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier on PCA Original Dataset\n",
    "clf_gbc_pca = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy',\n",
    "                             refit=True, \n",
    "                             n_jobs=-1,\n",
    "                             verbose=False,\n",
    "                             random_state=0\n",
    "                            )\n",
    "clf_gbc_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(clf_gbc,'RSCV_GBC_pca.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GradientBoostingClassifier on PCA Original Dataset\n",
      "\n",
      "Best Score : 0.7132926829268291\n",
      "\n",
      "Best Parameters : {'n_estimators': 1250, 'min_samples_split': 0.1, 'min_samples_leaf': 0.5, 'max_depth': 1.0, 'learning_rate': 0.1}\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GradientBoostingClassifier on PCA Original Dataset\")\n",
    "RSCV_GBC_pca_loaded = joblib.load(\"RSCV_GBC_pca.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC.pkl']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier \n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "#https://www.kaggle.com/jmohitj/adaboostclassifier-and-gradientboostingclassifier\n",
    "#https://www.programcreek.com/python/example/91146/sklearn.model_selection.RandomizedSearchCV\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(random_adaboost, \"RSCV_ADC.pkl\")\n",
    "# print(\"\\nBest Score -\",random_adaboost.best_score_)\n",
    "# print(\"\\nBest Parameters -\",random_adaboost.best_params_)\n",
    "# print(\"\\n Accuracy Score -\", accuracy_score(y_test, random_adaboost.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results for AdaBoostClassifier with Decision Tree as base estimator on Original Dataset -\n",
      "\n",
      "Best Score - 0.7132926829268291\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results for AdaBoostClassifier with Decision Tree as base estimator on Original Dataset -\")\n",
    "RSCV_ADC_loaded = joblib.load(\"RSCV_ADC.pkl\")\n",
    "print(\"\\nBest Score -\",RSCV_ADC_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_pca.pkl']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA Original Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(random_adaboost_pca, \"RSCV_ADC_pca.pkl\")\n",
    "# print(\"\\nBest Score -\",random_adaboost.best_score_)\n",
    "# print(\"\\nBest Parameters -\",random_adaboost.best_params_)\n",
    "# print(\"\\n Accuracy Score -\", accuracy_score(y_test, random_adaboost.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for AdaBoostClassifier on PCA Original Dataset -\n",
      "\n",
      "Best Score - 0.7132926829268292\n",
      "\n",
      "Best Parameters - {'n_estimators': 32, 'learning_rate': 0.25, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for AdaBoostClassifier on PCA Original Dataset -\")\n",
    "RSCV_ADC_pca_loaded = joblib.load(\"RSCV_ADC_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_pca_loaded.predict(X_pca_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC.pkl']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "\n",
    "random_adaboost_svc.fit(X_train, y_train.values.ravel())\n",
    "joblib.dump(random_adaboost_svc, \"RSCV_ADC_SVC.pkl\")\n",
    "# print(\"\\nBest Score :\",random_adaboost_svc.best_params_)\n",
    "# print(\"\\nBest Parameter :\",random_adaboost_svc.best_score_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, random_adaboost_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results for AdaBoostClassifier with SVC as base estimator on Original Dataset - \n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.7132926829268291\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results for AdaBoostClassifier with SVC as base estimator on Original Dataset - \")\n",
    "RSCV_ADC_SVC_loaded = joblib.load(\"RSCV_ADC_SVC.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_SVC_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_SVC_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_pca.pkl']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "\n",
    "random_adaboost_svc_pca.fit(X_pca_train1, y_train.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca, \"RSCV_ADC_SVC_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV results for AdaBoostClassifier with SVC as base estimator on PCA Original Dataset - \n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.7132926829268291\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV results for AdaBoostClassifier with SVC as base estimator on PCA Original Dataset - \")\n",
    "RSCV_ADC_SVC_pca_loaded = joblib.load(\"RSCV_ADC_SVC_pca.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_SVC_pca_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_SVC_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_pca_loaded.predict(X_pca_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning for XGBClassifier \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_norm[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"under\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Undersampling\n",
      "\n",
      "1.0    117\n",
      "0.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Oversampling\n",
      "\n",
      "1.0    291\n",
      "0.0    291\n",
      "Name: is_patient, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_0, count_1 = data_norm[\"is_patient\"].value_counts()\n",
    "\n",
    "data_class_0 = data_norm[data_norm[\"is_patient\"]==0]\n",
    "data_class_1 = data_norm[data_norm[\"is_patient\"]==1]\n",
    "\n",
    "data_class_0_under  = data_class_0.sample(count_1, random_state=1)\n",
    "data_through_undersample = pd.concat([data_class_0_under, data_class_1], axis=0)\n",
    "print(\"\\nUndersampling\\n\")\n",
    "print(data_through_undersample[\"is_patient\"].value_counts())\n",
    "\n",
    "data_class_1_over  = data_class_1.sample(count_0, replace=True, random_state=1)\n",
    "data_through_oversample = pd.concat([data_class_0, data_class_1_over], axis=0)\n",
    "print(\"\\nOversampling\\n\")\n",
    "print(data_through_oversample[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 234 entries, 183 to 407\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               234 non-null    float64\n",
      " 1   gender            234 non-null    float64\n",
      " 2   tot_bilirubin     234 non-null    float64\n",
      " 3   direct_bilirubin  234 non-null    float64\n",
      " 4   tot_proteins      234 non-null    float64\n",
      " 5   albumin           234 non-null    float64\n",
      " 6   ag_ratio          234 non-null    float64\n",
      " 7   sgpt              234 non-null    float64\n",
      " 8   sgot              234 non-null    float64\n",
      " 9   alkphos           234 non-null    float64\n",
      " 10  is_patient        234 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 21.9 KB\n",
      "None\n",
      "\n",
      "           age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  \\\n",
      "183  0.172840     0.0       0.013158          0.005495      0.080606   \n",
      "377  0.543210     0.0       0.009868          0.000000      0.765511   \n",
      "376  0.333333     1.0       0.013158          0.005495      0.074255   \n",
      "83   0.271605     1.0       0.009868          0.005495      0.039570   \n",
      "155  0.271605     1.0       0.016447          0.005495      0.044455   \n",
      "\n",
      "      albumin  ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "183  0.022613  0.014986  0.608696  0.673913     0.40         0.0  \n",
      "377  0.032161  0.047343  0.376812  0.239130     0.12         0.0  \n",
      "376  0.002513  0.003747  0.710145  0.673913     0.32         0.0  \n",
      "83   0.013065  0.007834  0.797101  0.739130     0.32         0.0  \n",
      "155  0.003015  0.000681  0.623188  0.565217     0.28         0.0  \n",
      "\n",
      "           age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  \\\n",
      "399  0.814815     1.0       0.009868          0.005495      0.085002   \n",
      "401  0.753086     1.0       0.019737          0.010989      0.067904   \n",
      "403  0.629630     0.0       0.023026          0.010989      0.074255   \n",
      "404  0.456790     1.0       0.016447          0.005495      0.067416   \n",
      "407  0.172840     1.0       0.013158          0.005495      0.066439   \n",
      "\n",
      "      albumin  ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "399  0.004020  0.006131  0.449275  0.347826    0.180         1.0  \n",
      "401  0.008040  0.001022  0.376812  0.369565    0.240         1.0  \n",
      "403  0.005528  0.001703  0.507246  0.434783    0.200         1.0  \n",
      "404  0.010553  0.004768  0.710145  0.630435    0.280         1.0  \n",
      "407  0.012060  0.007153  0.550725  0.565217    0.344         1.0  \n"
     ]
    }
   ],
   "source": [
    "print(data_through_undersample.info())\n",
    "print(\"\\n\",data_through_undersample.head())\n",
    "print(\"\\n\",data_through_undersample.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 582 entries, 2 to 49\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   age               582 non-null    float64\n",
      " 1   gender            582 non-null    float64\n",
      " 2   tot_bilirubin     582 non-null    float64\n",
      " 3   direct_bilirubin  582 non-null    float64\n",
      " 4   tot_proteins      582 non-null    float64\n",
      " 5   albumin           582 non-null    float64\n",
      " 6   ag_ratio          582 non-null    float64\n",
      " 7   sgpt              582 non-null    float64\n",
      " 8   sgot              582 non-null    float64\n",
      " 9   alkphos           582 non-null    float64\n",
      " 10  is_patient        582 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 54.6 KB\n",
      "None\n",
      "\n",
      "         age  gender  tot_bilirubin  direct_bilirubin  tot_proteins   albumin  \\\n",
      "2  0.271605     1.0       0.006579          0.005495      0.038593  0.001005   \n",
      "4  0.851852     0.0       0.049342          0.032967      0.824133  0.046231   \n",
      "6  0.876543     0.0       0.473684          0.489011      0.467513  0.030653   \n",
      "7  0.333333     0.0       0.029605          0.021978      0.059111  0.009548   \n",
      "8  0.790123     1.0       0.006579          0.000000      0.760625  0.042714   \n",
      "\n",
      "   ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "2  0.007493  0.434783  0.326087     0.18         0.0  \n",
      "4  0.044619  0.405797  0.239130     0.08         0.0  \n",
      "6  0.010899  0.376812  0.282609     0.16         0.0  \n",
      "7  0.007493  0.594203  0.543478     0.28         0.0  \n",
      "8  0.039850  0.275362  0.260870     0.20         0.0  \n",
      "\n",
      "           age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  \\\n",
      "153  0.345679     0.0       0.009868          0.005495      0.061553   \n",
      "55   0.506173     0.0       0.013158          0.005495      0.037616   \n",
      "111  0.037037     0.0       0.003289          0.000000      0.141182   \n",
      "316  0.555556     1.0       0.006579          0.000000      0.059599   \n",
      "49   0.469136     0.0       0.019737          0.010989      0.044455   \n",
      "\n",
      "      albumin  ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "153  0.006030  0.011240  0.681159  0.478261     0.16         1.0  \n",
      "55   0.007035  0.003406  0.521739  0.500000     0.28         1.0  \n",
      "111  0.009045  0.013965  0.753623  0.717391     0.32         1.0  \n",
      "316  0.003518  0.005450  0.565217  0.434783     0.16         1.0  \n",
      "49   0.014070  0.003747  0.594203  0.652174     0.40         1.0  \n"
     ]
    }
   ],
   "source": [
    "print(data_through_oversample.info())\n",
    "print(\"\\n\",data_through_oversample.head())\n",
    "print(\"\\n\",data_through_oversample.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  \\\n",
      "357  0.641975     0.0       0.019737          0.010989      0.064485   \n",
      "223  0.197531     1.0       0.536184          0.456044      0.066927   \n",
      "328  0.382716     0.0       0.013158          0.005495      0.065950   \n",
      "258  0.481481     0.0       0.013158          0.005495      0.063019   \n",
      "69   0.506173     1.0       0.009868          0.005495      0.049340   \n",
      "\n",
      "      albumin  ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "357  0.006030  0.006131  0.449275  0.369565    0.200         1.0  \n",
      "223  0.040704  0.030995  0.608696  0.565217    0.288         0.0  \n",
      "328  0.013065  0.007493  0.623188  0.673913    0.400         1.0  \n",
      "258  0.009548  0.003406  0.478261  0.434783    0.240         1.0  \n",
      "69   0.005528  0.014646  0.260870  0.108696    0.060         1.0  \n",
      "\n",
      "           age  gender  tot_bilirubin  direct_bilirubin  tot_proteins  \\\n",
      "355  0.209877     0.0       0.019737          0.010989      0.038593   \n",
      "266  0.358025     0.0       0.016447          0.038462      0.301417   \n",
      "86   0.296296     0.0       0.006579          0.000000      0.055691   \n",
      "5    0.567901     1.0       0.019737          0.010989      0.062531   \n",
      "68   0.444444     0.0       0.016447          0.010989      0.064973   \n",
      "\n",
      "      albumin  ag_ratio      sgpt      sgot  alkphos  is_patient  \n",
      "355  0.008543  0.003747  0.536232  0.565217     0.36         1.0  \n",
      "266  0.013568  0.010218  0.463768  0.369565     0.20         0.0  \n",
      "86   0.013065  0.006471  0.608696  0.695652     0.44         1.0  \n",
      "5    0.006030  0.007153  0.739130  0.673913     0.28         1.0  \n",
      "68   0.029648  0.012943  0.594203  0.478261     0.20         0.0  \n"
     ]
    }
   ],
   "source": [
    "#Shuffling the dataset \n",
    "data_under = data_through_undersample.sample(frac=1, random_state=0)\n",
    "print(data_under.head())\n",
    "\n",
    "data_over = data_through_oversample.sample(frac=1, random_state=0)\n",
    "print(\"\\n\",data_over.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the under and over sampled dataset\n",
    "X_train_under = data_under.drop([\"is_patient\"], axis=1)\n",
    "y_train_under = data_under[[\"is_patient\"]]\n",
    "\n",
    "X_train_over = data_over.drop([\"is_patient\"], axis=1)\n",
    "y_train_over = data_over[[\"is_patient\"]]\n",
    "\n",
    "X_under = pd.concat([X_train_under, X_test], axis=0)\n",
    "y_under = pd.concat([y_train_under, y_test], axis=0)\n",
    "\n",
    "X_over = pd.concat([X_train_over, X_test], axis=0)\n",
    "y_over = pd.concat([y_train_over, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54775031 0.72116793]\n",
      "0.0    117\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA On Under Sampled Dataset\n",
    "pca_under = PCA(n_components=2)\n",
    "X_pca_under = pca_under.fit_transform(X_train_under)\n",
    "print(pca_under.explained_variance_ratio_.cumsum())\n",
    "y_temp_under = y_train_under\n",
    "y_temp_under[\"PC1\"] = X_pca_under[:,0]\n",
    "y_temp_under[\"PC2\"] = X_pca_under[:,1]\n",
    "sns.scatterplot(data=y_temp_under, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_under[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "357         1.0 -0.269010  0.233227\n",
      "223         0.0  0.710104 -0.109811\n",
      "328         1.0 -0.243876 -0.234564\n",
      "258         1.0 -0.258602  0.083724\n",
      "69          1.0  0.721409  0.518398\n",
      "     is_patient\n",
      "357         1.0\n",
      "223         0.0\n",
      "328         1.0\n",
      "258         1.0\n",
      "69          1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_under.head())\n",
    "y_train_under = y_train_under.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_under.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5588312 0.7331914]\n",
      "0.0    291\n",
      "1.0    291\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZAk2X3Y9+/Lq+6ru6rvc+6dncHM7M5eOHYBAksCMEkItAiCtIJkiCLCCsMOm5ZtmlIwGHTYpmVHWAwbko0AYUpkSBBpmdKKWooUQSyxIPbG7M7szO5cfd/V1XVXVp7Pf3Tv7Bw9PUtsV1fP7vtETExl1uvKX3ZH5K8y33u/J6SUKIqiKMrdaN0OQFEURdnfVKJQFEVRdqQShaIoirIjlSgURVGUHalEoSiKouzI6HYAuy2fz8uJiYluh6EoinJfee2119allIXt3vvAJYqJiQleffXVboehKIpyXxFCzN7tPfXoSVEURdmRShSKoijKjlSiUBRFUXakEoWiKIqyI5UoFEVRlB2pRKEoiqLsSCUKRVEUZUcfuHkU+1kQSpYqNuuNNjHLYDgbIxU1ux2WoijKjlSi2EOXlmu8uVDlnRVApopNnjxSIBlRfwZFUfYv9ehpjzTaPldX69y8TFSl5bFcsbsWk6IoynvR1UQhhPisEOKyEOKaEOJXt3l/TAjxHSHEOSHEeSHE57sR525w/RA/uHM1wbYXdCEaRVGU965riUIIoQNfAz4HHAd+Vghx/LZm/wD4AynlGeDLwD/e2yh3TzpmkI3f2h+hCehNRroUkaIoynvTzTuKR4FrUsopKaULfAv4wm1tJJDeep0BlvYwvl1l6BoPj+foS0UwdUEionNmLMtgJtrt0BRFUXbUzV7UYWD+pu0F4LHb2vwG8GdCiP8cSACf2e6DhBBfAb4CMDY2tuuB7pbeZIRPHeuj3vaIGBoxS3ViK4qy/3XzjkJss+/2h/g/C/yulHIE+Dzwe0KIO2KWUn5dSnlWSnm2UNi2nPq+oWuCbNxSSUJRlPtGNxPFAjB60/YIdz5a+iXgDwCklC8AUSC/J9EpiqIoQHcTxSvAYSHEpBDCYrOz+pnb2swBnwYQQjzAZqIo7mmUiqIoH3JdSxRSSh/4KvCnwFtsjm66KIT4TSHET241+6+BXxZCvAH8C+AXpZR3jjFVFEVROqarD8qllM8Cz96279dven0J+Nhex6UoiqK8S83MVhRFUXakEoWiKIqyI5UoFEVRlB2pRKEoiqLsSCUKRVEUZUcqUSiKoig7UolCURRF2ZFKFIqiKMqOVKJQFEVRdqQSxR6TUlJpudRsr9uhKIqivCeq1vUeqrc9zs2VWa05aEIw3hvn5HCGiKl3OzRFUZS7UncUe+it5RoL5TZeIHH8kCurDWY3Wt0OS1EUZUcqUewRxwtYqrTv2L9csbsQjaIoynunEsUeMXWN2DaPmBIR9fRPUZT9TSWKPaJpgmODKQzt3RVgY5bGRD7RxagURVHuTX2d7QApJXMbLWbWmwCM9yYY64kz3psgZuqs1toYmmAgGyMXt7ocraIoys5UouiA2VKLF6dKhFtr8S1X2wRScrCQpC8dpS8d7W6AiqIofw1dffQkhPisEOKyEOKaEOJX79LmS0KIS0KIi0KIf77XMb4XfhCyVG5xba3OWq3NfKl5I0kAhBKurzW6F6CiKPe1Yr3N6/Nlzs2VWanu/QCYrt1RCCF04GvA08AC8IoQ4pmt5U/faXMY+O+Bj0kpy0KIvu5Ee3deEPLabJnp9SZSgq4JYqaGZWi4fnijXbiVORwvYHq9yVLVJhkxmMwnKKTUHYaiKNtbqdo8f3UdL9i8hlxdbfDYgR7Ge/euf7ObdxSPAteklFNSShf4FvCF29r8MvA1KWUZQEq5tscx3lOx3ma6uJkkAIJQslS1iRrv/moFcKCw+Ud9Y6HKD+YqrFQdrq01+d61dcpNtwuRK4pyP5gqNm8kCQA/lFxZbSCl3OGndlc3E8UwMH/T9sLWvpsdAY4IIf5KCPGiEOKzexbde9R0ArwwpNhoM7XeYLHcwtAEo7kY2bhBJmZwZizLZCFJzfaYv22Cne2GrNTUXApFUbbXcoM79rXd4JbH253Wzc5ssc2+20/dAA4DnwRGgOeFECeklJVbPkiIrwBfARgbG9v9SHeQjpqs1Nosld+dTOeGIUPZOCdHstiuT9MNcP2QQIaE23wLCMI7dimKogAw2hNjre7csm+sN46ubXcJ7YxuJooFYPSm7RFgaZs2L0opPWBaCHGZzcTxys2NpJRfB74OcPbs2T3Ms2CZgrGeOOWGh+0FpKMGD/SnaTgu1bbHhcUqbS8gauqcGskwlI0xW3r3rsLQBf3pyF6GrCjKfWSiN0HLDZhZbyGRjORiHOlP7mkM3UwUrwCHhRCTwCLwZeDnbmvzr4GfBX5XCJFn81HU1J5GeQ9BCFFD54lDvchQomkC2w1oOgFvrzRwt24XbDfg3FyFjx3sJWJoLFZs4pbBsYGU6sxWFOWuIqbOmbEcR/pTSAnJ6N5ftruWKKSUvhDiq8CfAjrwTSnlRSHEbwKvSimf2XrvR4UQl4AA+G+klKVuxbydbMwkETEo3nRraGgCBDeSxDscP8QNQs5O9HDKD9E1gbaHt4+Koty/ulnup6sT7qSUzwLP3rbv1296LYFf2fq3Lxm6xtnxHOcXK5QaLhFD4/hQhpipo4naLR1OmoDoVr0n01DVUxRFuT+omdm7IJewePJwgaYTEDE0TEMjCCWT+cTm0LYwZL3hMJCKcr1Yx3YDxnrjCKHuJhRF2f9UotglQohbnh3qmuDMWI6hbIzrxQb5hEUo4bnL60gpeepogUcmerHUnYWiKPucShQdZBkaA+kol5aq2F7IX11bv/Eo6ttvr5GLRzg+lO5ukIqi3Bdsz6dYdwhDSW8yQipq7tmxVaLokKrtcn2tyUqtTb3t4fvylkkiAsH0eoNjAynVoa0oyo5qtseLU+s4vsQPJJmozmA2hq5rpKIG/aloR68jKlF0gOMFvHh9g9JWaY61WpuNlstkT4KnB5sMB/PoAtqpcYQY7HK0iqLsd9PrTVxfcm6uQiglQsBqtc3D4zkSEYNjgylOj+Y6dnyVKDqg1HDYuKl+Uz5p0fYDPj3qM/zC/4y3+AMCJKmRkwjtV2H8sS5GqyjKftdyPKbWm2w0XQ7k43z3yjpSSIoNh5hlcGWlwWhPnN5EZybvqp7UDgi5tRaJpmn0p6PEq9cRa+cxDQPL0PGWLxBefvZuH6MoigJALh65UTw0CDcLA1q6dqMOlB9K7G1qQu0WlSg6IJ+MkIvf2tGUtHRy9SvYoYEtTTw9BnqEoDwDntedQBVFuS+M9sSYyMcQAoQGqZhONm6R2pqEFzE00h3s3FaPnnaJ4wXomsDQNaKmzuMHenl7pcZ63aU3adGbNJHtDL4fEEiwnZBExEIfOM1602Uwu3cjGBRF2X/KTZf1hoOuCfrT0VtmYieiJp97cAhL17H9gM+fGGKm1KQ3GSFqapwazZKOqUSxb9VaLt+fKvHmYo2EpfHEwV6ODWYwdY0nDuYpN13mNpq8PF1mLPVxHvhoC/+l30VIH+PIp6mPf4ZXZys8nYjemLWtKMqHy/xGi5emNm6U/cnGTD52uJdMzLrRpi8T5W+cGabUdNE1sPR+vCAkGTVJdri8h0oU79N3Lhd57nIRCaSjBn95ucirM2VyiQiZmIEQgtWaw0LZ5qVpm0fGfpRP/uRZZODxsj+IU4nT9kNsz1eJQlE+hIJQcmmpdkttuIrtMbPe4tSodUvbmGUwYn2IigJ+EJSbDucXKjc6rvOpCN+9XORAX4LToyZvLtYwdY2hbJRc3KTYcHhtrslSLcsb8xXOjgf4YZVD/SmSlnr0pCgfRq4fbLs4Ub29f/ouVWf2+6AJcWPxkIihUW66+FulxgFCubksqq4J0jGLQ31JepMWg5koTxzope2FuAHkYta2CxopivLBFzV1elPWHfsLqbsMda0swOwLsHyhw5G9S91RvA+ZuMUjkz08e36FIJRETI2IqdG/9QdOxQyaro/YWswvG7MYSEfoiVs0kj6B3Kwou95wKLdcBjKxbp6OoihdIITg5FAG2wkot1w0IRjpiTHem7iz8fTz8OL/BUs/gGQ/PPTzcOJLEOvsQkYqUbxPHzvYS9IyuLhcYzATpSdukdgqDpiMmDx9PEvLDQikpD8dZTBjUVpbIWEErHhp6m0fTbCnyxoqirK/5BIWP3Ksj3LLRdcFPXHrzurStVV45Rsw9/3N7cosPP+/Qc9BOPhUR+NTieJ9ikdMnjiU5/GDvQghKDddZjearNYcYqZGMqJztD9J3DKoVUoYU88SufY9wtBjaORRrmQ+ipHo7diMSkVR7g+modGX3mG1y+osLL1+6z7P3kwYHaYSxftUtV2Wq22CQNKXjlBIRZkrN6nZHqWGZKHcZqlsk4wb5Jeep/L8N0EziFoGudq/5fSjKYqZH1OFARVF2Vk0B5khWKvduj/R2/FDq0TxQyo3XYp1h9lSk4rt4QUSQxc8PJ7l+moTL3i3c9oPJVNrTXrnXyUMJb7vQhji6Trm3Pdo9H2atheo4bGKotxd4TA89Ivwnf8JnBqgwYmfgv6THT90VxOFEOKzwG+zuWb2N6SUv3WXdn8T+EPgESnlq3sY4h2klFxcqvHWco3rxQZ12+f0WBZTF3iBZK5k44Xvjoc2dUHN9qnbHkQzSEBoOh4aPiYkCrheiBeEKlEoirKz4z8FmVGozkMsC30PQnak44ftWqIQQujA14CngQXgFSHEM1LKS7e1SwH/BfDS3kd5p/WGw8WlGkEocbyQphvw+lyFxw/24gU+jh/Qk4hQrDvA5mQaQxfEIwatoccx516nWqmg6yFGNEl1+BMg2NNFSBRF2Z8cL2C+3KJYd0hFDUZ74rfMznaFht13lvjo45j63s1u6OYdxaPANSnlFIAQ4lvAF4BLt7X7H4B/CPy9vQ1ve7W2T7C1TF0mZlJueTTd4JZ9x4fSXFioslZ3iBgaR/qTLJRtLtcnGXv0q/RV3iYbM3B7jvJHa718+oE7x1ArivLh88ZChWtrTQASls5UsYmhC3Jxi2zcZG7dRiJpeQEJy+BgX4LRXJxIh59GdDNRDAPzN20vALcszCCEOAOMSin/WAhx10QhhPgK8BWAsbGxDoT6roRloAkIJfQkLFpeQMvxMQ3BYDzCg0MZ0jGTjx8u0HR8LF3DNDSGsnEWyk2m1k38niPMOz6rNYeehE7b8zsas6Io+1+56TJbagFbE3hbHq/PV5gsxElYBnMbLT5xuMCr02VW6w4RQ7BUTXN8MM1jBzrbod3NRLHdMJ8bPcBCCA3434FfvNcHSSm/Dnwd4OzZsx2d4lxIRTjUl+TaWgND1zhYSHIgH+dQX4pMzLxl9NI71R+9IKRYd9hoeNhugB9Ao+3f+BZw862loigfTn4Y3ngyYeoa14sNAMJQ0nJ9arbPRsNho7W5LoXjS2wvYHajxZH+FLlE564j3UwUC8DoTdsjwNJN2yngBPDc1sSTAeAZIcRPdrNDW9cEZ8ZyDOditNyAVMSgkIrcOTnmJpeWqlxaqiPZrA9Vd3yODaRoeyEjuTjDWTUjW1E+7LJxi1zc2lpCWRJKia5tfuH0Aolg80vnO4QAXYjNkZQ3DaDphG4mileAw0KISWAR+DLwc++8KaWsAvl3toUQzwF/r9ujnmAzWQzeo9xGEEoWyi3mN1osVGwipsYb8xXmNlpETZ1TIxmODaQ41JfC2MNOKUVR9idT13hksocLCxWa7uaXyYrtkYyY+GFIPmXRn45iaHW8IKAnYZGMGGTjFtkOP5XoWqKQUvpCiK8Cf8rm8NhvSikvCiF+E3hVSvlMt2L7YbRcn2LNwZeSfNJioWxzfr5Kw/G5tFyj7QXk4iblpgd4vL3SQNc0RnoSJFWiUBSFzX7PJ48UtgbIhEwVm8xv2MQsnY8d7EUTELN0ZkpNLF2nPx3h5EgG0+jsNaSr8yiklM8Cz96279fv0vaTexHTD6Nqu3z/Wolya7MssBCS3FaGj1k6li64vNIkF89iaAKhbT53XKu12Wg4HV90RFGU+4cQ4sY14cyYxcnhDLombjzeniykeOxAL44fkrD0HR977xb1VXYXzKy3biQJgKYT8PZqnZilownBWE+cvlQUgWAgE+XUSJbzi1U2Wi5X1xo3Fk1XFEW5naFrdyQDU9dIRow9SRKgEsWuqLRuvdDHTJ0wlGhbf8Rs3OLoQJKTIxkycZPz81V0TTCUiVGzPS4tV7sRtqIo9xHXD1kst5gqNiivr8LMX8Hlfw+rl8BzOnps9cxjF/SlIyxW2gBIJA3HZyQXx/F9Sg2HvnSEnzg1RBCGbDRdDvUlOJBPULV9Gk5Ase7ieEHHJ80oinJ/ansBL09vsFi2kU4Nq3yNh8eyTMo1qC+D24TRRzp2fJUodsFEb4JifXOyzGKlRRhKvCAkHjYY0dqkPY0xQ1IzC/zEmENk/SJyrYWbO8SbYoJIxMDqcGeUoij3r+Vqm4WyvblhV3AdmzeXNAZHs0TdEmxch74HINKZBYxUotgFgYRDfQkSlk5fyuLiUh2/ukp77jnWnCp2ROeC/6MM5pYJFl5jpeUSb6+RmfoeD536acLBJ/fsWaOiKPefmn3T420ZgtfG3qjQ6k0TxQdDbu7vEJUo/hqklCxX25QaDlFTZzATo9Rw+MFcBYlkpdombums19uMNGfwGyVCTceO9mEHkuVKk4uzDnajRiqZ5+OTE0wUX8Y69tFun5qiKPtYNv7OPAkJvgMrF0gYPom35yGRgQd/CqLpjh1fJYptNNo+tueTjpq39BtcWa1zbq7C1ix74laVmGVgewGGLkhEdBbKNv3ZCJQ2O6g1IYinezAyg/z7c1dw3V4y6QJBfY5zKwbjkxkI1KgnRVHubjAT42AhwcziCsHSOWKFcU7nPSLTL0E0AVpnL+UqUdxESsnby3XeWqnh+iHJiMFD4zmGsjFsz+ftlfqNJAGwUnXIxkM0AX4g6UlEmN+wGUjHSB5+kNV2kUI6wejBcb43u8qKreOWa6wABwbGKFfnKGUeY2gPVqhSFOX+ZRkaj0z0cMCq4rSi5Ow5/DBB5eAXycx/B7H8Bhz7fMeOrxLFTdZqDucXqgRyMxvU2j6vzW7QkxjA8UI8/9Z6g5ah4fkhEVMnlJujnU6PZhjMxhgZPUosUyJefIPnZy7R03OWhq6T6J1ANlapezqHxs9QSx9lIJRqKVRFUXakaYKCv4xdvcj5RpL55WmkhKEjP8bp7AESnTx2Bz/7vlO23RtJ4h2NdkDV9khHTXKJWxcXipk6xwbT75a8ldCTjHByOEv/wCDpU38D/8zPUxr4GCWZZiyfYclP08wcoZ0+SO+B01TC2I2KkYqiKDuaf5mpgc9yfWENz2kSSWVo6Bmm48c7elh1R3GT2DbzGExDI2JoaJrgzFiWF6ZKrNcd8kmLkVycyXyCyXyciu0RN3UK6ei7K0/pOhftXkQygvRaTOTjTBYS6JogYmj82ZsrnBjNMtYTZygX3+OzVRTlvuPZLCxcwzj6YxzsMTA2rhI2r2IsRgh7NbT8oY4cViWKmwykowxloyxtTZ7TBBzpT5KNWwTh5ognHY3RnjizpRalpstUscWRgSTHBtLo2zw+qtseqYhJo+3z+lwFY2vq/YmRDG+tNliqO/QmIvxIzFTLoSqKsrPhs6TmvkvKd5Gvfpe2XYPBjxC7+udo/hV46r/tyFwKlShuEjF1Hj/Qy0q1Tcv1ycZNBtKb5cSXKjbnF6rETI0ray2mii1SUYNjAxrn56ukogZjPTc9JQxD3KU3eKD8FufsASwvxng+wULZ5tXZMk0v4ORwmlLL43qxwcMTOZUoFEXZ2dhjHAziFKcv0FywYOAkuqYxEGnD9W/Dg1+A4Yd3/bAqUdwmaupM5O/sFio1HKTcHO66Wt2sq9JyfWwvIG4ZrFUdCqkIMXPzVxrOvsDG87+DNJOU24dwggItfQjb1XGDkLWaQ9oyyEQNTF3b9m5EURTlFrEM/cc/TsoSVFrT0NogFayTqs9CNAN6pCOHVYniPYpa7/RfbPYvNN0AXROYuqBiuyxWbRarNrmExemhONHrz9F2HLQg5EAhyfUVCFpV+jODrDccDhYSlJouw1aMB4fS9HZwGUNFUT5Y4tk+4sESVN4EGWzuPPYTkD/WkeOpRPEeDWdjTK01aTg+RwdTvDJTpj8dxQsklabLaC5Ove3TdGwymsMDno2hCVpth0jlGoeGP8PU5TLlqsNPnBpiLGPgtG2Oj/czVkhjGaogoKIo71FqEJ76VVg6B6WrMHQaxp4AozOXdJUo7sELQoq1Ni0v5ORIGscPsb2Ak8MZ2l6I7fr0p6M0HP/Gz8zWBMcGT2GVS5SCEFpFhq3X+aknPkvRNUlWr7Bx7iJjaYOgkYaHPg3pyS6epaIo9wXfhet/AZf/BLwWTDwFT/xnkOrv6GG7miiEEJ8FfpvNpVC/IaX8rdve/xXg7wA+UAT+tpRydq/ic/2Q12bLzJSaSAmGJjg5nOHkcPZGm+n1JrMbJSxDw9I1JBIvkKyPfJLpei8rizMM9Gaxkj0Y0SRjwTKrc69gej4X51x0sUw+nWBgcAR01ZmtKMoOFl6B7/8fYEQgcOAH39z8/9Ff6uhhu5YohBA68DXgaWABeEUI8YyU8tJNzc4BZ6WULSHE3wX+IfAzexXjWr3NzHrzxoQ6P5RcWq4xnIuRjm1e1PtSEQbTEWY2WsyWWpi64OOH87y06LDkjVKNJHmjIsiLNMcSGtMz06yXmgghsHQNQUi1vAZOHeI9e3VqiqLcR1aqNmt1B309wDj0tyktTRE3NcbNKrm5F+GBH+/oXUU37ygeBa5JKacAhBDfAr4A3EgUUsrv3NT+ReBv7WWATcfn9jnTFdtlbqNJOmbRn4qQiBhYpkap4SAAPwiZLjZYrTk4XkjJMSk3XepBixMDSXp7C8xdChCawJY+qahOJpUEM7aXp6Yoyh7y/JBASqI/xOJkU8UGr8yUCULJ3JRNe22NswNZZqbfZDaZ4ZNHT5Hp8NOIbiaKYWD+pu0F4LEd2v8S8CfbvSGE+ArwFYCxsbHdio90zEQT3CgEWG65bDRdptdb1Ns1+lIRHhrPUqy7SAQV20MT4G7VhEpFDdwgwDIsDheSGLpG79Akhw8dYnbmGroQHBnMkZw4oxKFonwAhaHk+nqDKyt1vEAynItxfDBNIvLeLr2eH/L2So0glLS9gHU/im97bIQZomaMZrPJUu4RMh1+GtHNRLHdxIFtix4JIf4WcBZ4arv3pZRfB74OcPbs2V0rnNSfivLAYJorq3XaXkC97fHgUJqWuzkcba3uUKw7+EHAaq2NlDCci/GDuTLT600ihkY+afHEwTznF6qsVRpUG02++MhnefyhVYQMqZBkRfQzuFtBK4qybyxWbF6bKd/4snl1tYHGZk24pYpNzNQZ743Tm9x+/oMXhjje5g+HUiIjGeg7QSsakBk4ii/i+FKHVhniuY6dRzcTxQIwetP2CLB0eyMhxGeAvw88JaXs7Arit9E0wamtWkyVlsvllTq1tn9LEb+q7TKZT/LC9Q0SEZ2VWptraw1Oj2UpN100TXB+oUJv3EIXPmeHE+jlKXr1ZeZnrxJkD5M7dBYY2MtTUxRlDyxX7VuWJjB1wbW1BvZi9caQ+NmNJp880kdum7lUccugL20xW9pMKqmogSEsHhyOEK3XsBI9DJgNmP7u5qzsDulmongFOCyEmAQWgS8DP3dzAyHEGeD/Bj4rpVzb+xA35RIW6ZjJ9WIT/7ZKr7l4hOFsjE8/0E+p0eZqscmJ4TSr1TaGLtCkwPFCQHLCWiF95c9p1lbQDo9wfKCXYvEN4s0sjfYhkqqEh6J8oFj6rQW6I4bGhYUKozeV+7HdkMWKvW2iADgxnMELJMW6w8GcQbpeo/Xma/QM5Mm6M8QpQK4P2hWIZrf9jPera4lCSukLIb4K/Cmbw2O/KaW8KIT4TeBVKeUzwP8KJIE/3FpTek5K+ZPdiFfXBKdGsrw0XaLW9tEEjPTEGe2JEzV1To9lOb9YAQHPXqizWLFptAOGc1FODGWYjNbRr/8Z7doCEcvCXrlKcv08fQeeolmeYb3eVolCUT5gRnIxrhebOP7metYCyCUiGLclEC+4+3rXmZjFk4cLVNsutaVrVOZfJD4ygnflLyhuzOH1FBC9PcRb63CmM+N9ujqPQkr5LPDsbft+/abXn9nzoHZQSEf49PE+yk0XU9foTURuLDg0lI3Rm7B4Y77MKzNlyi0Xz5ccLCToiZukwyptT6JjMTIwikuTtukQ1y201DAbDY+JQpdPUFGUXZVPRXnySJ7ZUgvHDxnJxcjELRbK9o02moD+9M41mjRNkItHaDZXIJKkXS3SXr0OQKVWRc8MEb/0b2DkcSjsfqlxNTP7rylmGsSy2//aIqZOKmpiGRofO5inJ2lRa9qkIgYTuQLFxQQnHjyIPvMcslHCSeYQBz9DM38KXa0hpSgfSIVUlEIqemO7J2Fh6hortTaWLjg6kGIw895GPSZ7hlmQF4h5dYikQAii2X6q1TKFFETdekfOQSWKXTbak+CR8R4WKjYvT5eoNByeOmqyEuaI9R2msfAiFM5SykaIpnLEqj51KoweGup26Iqi7IFU1OSJg73Yro+haZjGe/uSKKXES4+SPPoUWukK4eyLxGIxtFgG3wd9dALynVnpTiWK98n1A9peSNzSNxclihqM98Z5YWqdjYaDScDbyzVGegawCsdophL85cVZHM+n4hbpT0V48nSeZsuG9/itQlGU+1/Meu+XX8cL+MFchbmNFo2KILD7+cTTv4Y8/4c0S/MMn/gE5gOfh0iXyowLIdJAQUp5/bb9H5FSnu9IVPeJmfUmF5eq2F5IJmZyaiRDXzpKxfYZ60kQhBDVAooNn8Vyi1Q6zsvLAVPrNkEoSURMSutrrNQPk6itwaAq4aEoyp3myy2m15sAxNx1mpVFzmmDPHT0xxgSTXpbM6B37nv/jvc8QogvAW8D/0oIcVEI8chNb/9ux6G2MREAACAASURBVKK6D5SaDq/MbFC1fVw/pFh3eHl6A8cLkFKy0XSp2R4vzFS5XGxybqZIjQTRdJ5MMk7M0pGejZUdYKXh0Bu9+6gHRVE+3NYbN00hM6IkvDLR6gwj7gz9y8+huxubfRYdcq8U9GvAw1LKZSHEo8DvCSF+TUr5/7H9zOoPjXLTxQtunVNRa/uUWy6D2Si251OxPSxDx9I1jvYlmFotM5obJDdQI+a0CYRFUxocHe0nn0536UwURdnv0lETGmvQ2gC/DckCsZhBJGFCIwkHPw2Z4Y4d/16JQpdSLgNIKV8WQnwK+GMhxAh3KbfxYWHqd96MGZrA1DUGMlGeOJDHDyFh6RwdSFGtVijXW6RjaayBfspzFwjDkI+O9vNArwG5kS6chaIo94NRisyVzrFRXoelc1jJHh585KOY61fgIz8NI4/c+0Peh3sliroQ4uA7/RNbdxafBP418GBHI9vn+tNRCqkIxfq7t4TjvXF6EhZBKEnFdI4Ppri80uDbb60ylosylI4j7Cpjpe8yno0T1XxYexG/+pcQj8DQR7p4Roqi7Feppe/xVGqRVUPgJUfp9Vfoufz/QGYE1t6CwTMd7aO41yf/XW57xCSlrG8tOPSljkW1T0kpkXJz8kvU1PnowV4Wyi3qbZ/eZIThbBQhBIYu+MhwjreW6lRtl5YTcGVxHS0f4ck+gytXzxE3NUK7wuDgCKnWNFTnVKJQFGV71UVi1WtMLL+O43lIoROY1uaSqIGHXpmBvs6slw33ThRNoB+4dtv+x9lcH+JDQUrJTKnFldU6XhAy3pvgSF+SRMTg6MD2fQuOF4AQjPXEqcZcjEBjeX0ZeWKSg0dP4AeStO7RF6wQWSuDldzjs1IU5b4xcBx/+QL1oSepvv2XIEPiw4dImFlkaoKmLejkYqj3ShT/iM0O7dvZW+/9xK5HtA8tVmxemirdqAJ5YaFKEIacHr17Wd/VusPceoua4zFbatEbhYnCEHokRv7wo5TXFtgol0B4JI5/Aa2D3wYURbm/tQcfo1FtUJp5k/jER9H8Fq2eo9SGz7K26iH0eFcTxcR2cyWklK8KISY6EtE+tFBuEcrNOwvHDzF0wcx6i2MD6W1XrGpsjX7qy0SYnmoQSkk2EeO/OrqBePkbuPV1RkYepDX6AI3Iw6xnehjQo9scWVGUDzvb83lxVadsPUlubIKYHuJJk5LtU1rxOTLSTzvcvvLsbrlXotjp6vWhmUasCUHT9VjYsGm6AaYuODaQuuv4YC8IqbV9+tIRRnviNByfXzkdEHntd1hbmgWguT5P4phHKWUSJAcZiKhHT4qibKraLkuVNq4fYuhQsT3qbsj3l9MUtDqN4jSG32Sot4dcs0a6v7ej8dyryMgrQohfvn2nEOKXgNc6E9L+M5SNsVRpU7V9/EDSdkMihk697W3bPh0z6YmZXFlpMFVsUkhEiNZnCdDBiOL5AWEo8RbeoDcuiccTHR2xoCjK/aPScvnLy0XOzVW4uFTjuctFAikpJKMMpy2qjSalII5Mj3Jiop+EvcSgKHY0pntdnf5L4I+EEP8J7yaGs4AFfLGTge0nUUPjobEscxs27lapYFPXKDZc8qk7b7p0TfDwRI65ss1SpcXBvgSlMMlCK0kyNU4+Z2NsXMVKJ2llCyR1twtnpSjKfjS/0aLhBDe2Y6bB9bUGZydyFJIGiVwUmTUpxDV8z2W8v4DmNToa046JQkq5Cnx0a6Ldia3d/05K+RcdjWqfMXSNthcymImiCYHtBXhBsO2ku3fkEhE+80CBbNzgtZkyRjTLkUiGysY0rqlzMNVH9PCnEOleGrOvkU4mOjqzUlGU+0PLDW7Zjpo6/ekouhC8vWoz4NeJaJJqXeA1XMq5LL3Jzi5ms2OiEEJEgf8UOARcAH5HSul3NKJ9KBu3OJBPcHn13aydjZkMZnbugE5HLZIRA0MXzHppkqM/Tl9hFi9s4B0+Tq22ztyrz9N/7HForKpEoSgK/ekoU8XmLaUvDhQSDGeiTBQSLJWGWV9bgsBjKJfGSY9DZqyjMd3r0dM/BTzgeeBzwANsPo760Dk5kqUnGWGt1iYVNRjNxUlEdv71aZrYHCWlCRbWysxVihjSIJcc5PN5nUfr50n2DvP8UpXB3AidK+mlKMr9YiQX4/hwmutrDYJQkk9afGQkiwRqts/FVRsZZjHxyJhp1rU8Q0Z3Rz0dl1KeBBBC/A7w8m4efGuG92+zuWb2N6SUv3Xb+xHgnwEPAyXgZ6SUM7sZw3tlGRqT+QST+cS9G29Jx0wmeuNcX2uwXKqQ0jSM0Gc0IfGWLuD4KyStGCcLBhsipxKFoigYusapkSwHC0m8ICATtdA0QcvxODOWZTATpeX66EKjYnu8OL3ByZEsQnSuTuu9EsWNYT1SSn83AxFC6MDXgKeBBTZHWD0jpbx0U7NfAspSykNCiC8D/wvwM7sWxB44OpDherHJwwf6IAx4bAAKpVcwGstED38UbfFlMsGLyAOPdjtURVH2kWTE4J1L9FLF5t++vsR3r67xxaNRjuk1NE3DGu7jakPHC0Is4845XbvlXonilBCitvVaALGtbQFIKeX7qY39KHBNSjkFIIT4FvAF4OZE8QXgN7Ze/7/A/ymEEFLK+6ZyrWVotNyAajvg8yMu0dd/n1p9jaG+XswXnkVMPkW8tYyp20C82+EqirLP2K7P966u8+23Vvj5Bw3WX/8j3mhU6EtG6Mn38cRjP97RJAH3mEchpdSllOmtfykppXHT6/e7gMIwMH/T9sLWvm3bbHWiV4E7ZpYIIb4ihHhVCPFqsdjZ8cQ/jFzc5PGjI6RrV4inMgyPjJOJGjiRXkTpGpGRU5jJzk6YURTl/lS1PWZLTQbSUaLF8zRLiwR2Hd+1cVfepj13jjDs7Hfn97aqd2ds9xzr9rN9L22QUn5dSnlWSnm2UOjsMLEfxmg2jhtIslZAPJ2jEiZYkHlmcp+gMvnj6BNPdjtERVH2MSHgQN7Cr60Q+h4iDNBDD8238SvzBB1+yNLNRLEAjN60PQIs3a2NEMIAMsDGnkS3ixquT+D76KOPsEKBVE8fWW8NWbxCNbAoCdWNrSjK9gxNMJiJYukG2YEJNAGpRIy45mH4TTIDB3ec07UbupkoXgEOCyEmhRAW8GXgmdvaPAP8wtbrvwn8xf3UP/EOXROkoxrXijaTPVEsr4oTH4LcBM9fmqM++4Nuh6goyj5lGTrZuMWZyTy5sRN87lOf4sRIloGUzsRHPkFs4AhtL7j3B70PXSswtDWK6qvAn7I5PPabUsqLQojfBF6VUj4D/A6b63RfY/NO4svdivf96EmY1N4+R33uDWacRYxED0HfCYLkIGZ4FWdjEdwWWKozW1GUW6VjJpP5JCtVm4UwR51DZIf7iUejtHN5phtZjtQdRns6d/3oaiU6KeWzwLO37fv1m163gZ/e67h2y0bDpe54JL0yjbk3cB2X+MGP8txby5Suv0HPAUE8kifM9tDwBMnOzplRFOU+9cBgimRE5w9fLXN5JUJMCDSh09dj8OCwTvAB7sz+QHtrqca3317lheslfLdNJh7BiKeZbqcIfYdE1CRhQNNuMS+GCERnh7cpinL/EkIQhJJcwiIRtXBEFEdYLFfbmIZGb4e/Zara1h1QbrlcXKrhBZJUVOftepRDB44w0G5xtSHIDBwCt4ZI91O2Yyy7cTJxdTuhKB9GUkraXoBl6Oja3Sc167ogahocG0ixXN1cGydpGRzMJ0hFzY7GqBJFBzQdHzcIAYibBoXmVSrXXybRWqSXLMncERYHH+V8LY4Z0zjUrxYtUpQPo42mw4XFKhsNj7ilc2I4w3Bu+zXhEpaBEBLHDxjNRRFCMJlPcaDQ+euHevTUAYmIgbU1XG0y0ab6xp9wfXGFa3aSbK6AXa8QER6XV2vUHZ+Iof4MivJh4/oBL01tsFhuY3sBpabLi1Mlyq0716dZbzi8MrPB47kGn0guMdy+yoPxKscj67jN2jafvrvUFaoDcnGLB4fSGLog5ZcRbg0diW5FubrhUaq3KFgOnzzSx2A6yh+/sUyl6XQ7bEVR9lC56VFp3bpKpuOHlBp3XguurzU4JhaJrJ/Ha9VYrdr8h+e/z++/cJVLc7dPP9t96tFThzwwlGYgG0E0NA6PDiBlSEOLsFBu4fkBhm3wrVen+Y9ODlFseKw3XbKJSLfDVhRlj+i6QNPEHSOWDO3O7++hlLy9WMJthLy01uJKsUXONIleu8y/qrskMn08MJrvWKwqUXRAqeEwXWxSbXsM55IcePAzHDZfYKXSYCzjYw4e5XXf4kiqznq1xul+i554ZzujFEXZX3riFiO5GLOl1o19uYRJX/rOL4x+IJlfXSOfy7BQ2cBuNhGJBP26Ra3R4lqxyeGhHowOzdBWiWIXBaFker3By1Mb6LogaRlcW23yYmOQ8cyTGPoSiYjB1LWLhK3L/PjBj+FbOmeGNHraC5A81O1TUBRlj2ia4KHxLPmkRbHukImZjPcmiFt3XpYdP6Ad68OKCIb7ehnpLxCEktBN4utxGq6k6XpkYp15KqESxS66tFzjO2+tMrW++Q3h+GCKphswv9HC11aorq+wtFHjickczaXrDPZOcejEIxxqnQfnoS5HryjKXouZBkcH0hwd2LldIRXl+8YAfkwQybR5e7FEfy7LA+MT6LpBNmFh6Z2bi6U6s3dJo+1zdbV+SxXHphuwWrOxdIHjtrHbbbJRnWiyh0PDffTJdUprSxDNQGaki9ErirKfTeYTnBjr4dkpB4TGcEIQbMywsDDPmeEohwtJYtvciewWlSh2ieuH+IEkGTUx9M1JM2Eo0YVGzNIhkqUtTdYaLvVmnStziyzIArZVoJU9DMn9Vx5dUZT9IR0zeWg0y4F8jJX5a5QXr+LU11ldnGJ6ZobJhN3R46tHT7skHTPIxk38UHKgkGCl2sZ2fT52KM9qvU25UiCRqzBUyDGatNFPP4Ez+AjSiKMNHOx2+Iqi7HPZeISI8AiaG+i6BkikDAnbdaqlIj2p/o4dWyWKXWLoGg+P5zg3V8HUBUOZKEf6UxzpT7Fac3h9zkIbyaM7VV6eXeZK1aS2WOULp+MY5SkYONLtU1AUZR/LJixOj+S4cl7H97zNmdkDvcS8Ctqd67ntKpUodlFvMsKnjvVRb3tEDO3GM8PhXIyWm+Lla2v88xfmCcMAL3Rx/ZDz132eFqv0pAsQz3X5DBRF2c8+MpGn/ehRysUlTDyM1gL9yWGy+c7dTYBKFO+bF4SsVNs02h6JqMFAOkY2bmG7PtfW6tTbHpmYid4uY9sN2o6L7zpYWkBvMg3tGu3KCmxMQfzhbp+Ooij7WA82Z/p0ZknS3FhicGKM8XxqmwWid5dKFO9DGEpen6twba2BZHOB78lCgo+MpHl5usxSpY1EYgrQ1i6Q1mPkIwGuaWCZUfKUGctmSQY1sFRhQEVRdra6Mod24Q84JB303DiGV8Z9c5pYKgepvo4dVyWK96HUdJhab95I5hKYWW+SihosV9oA2K6PHQoSrSoDvSafOz3B996cotkocmCywFNjJmnrGPQd7dp5KIqy/5UaDpazgb12BUePoi9eQNpVssc+iSM1OlkAqCuJQgjRA/xLYAKYAb4kpSzf1uY08E+ANBAA/6OU8l/ubaQ7s93wjjotodxMDu/s9UKJpcFG4gAvfP975NMJPvPgKfozBzkardCfiuKlHkAV8FAUZSeeH7IeZFme+Hnq5TX6+gRj9dcRmiDITHb02N2aR/GrwLellIeBb29t364F/LyU8kHgs8A/EkJk9zDGe8rGzTtKhFu6Rn86dqPMeNTQiZkGLy+F+NlxVhsez7/86maBLzPNzHqNRmfXRVcU5QOg1vb4F68s8B+mHS6Udb476zA99h/jjz9FJJHp6LG79ejpC8Ant17/U+A54L+7uYGU8spNr5eEEGtAAajsTYj3lo6ZPDye442FCrYbEDF1Tg5nGO2JE4aSC4tV3ECjZnsM5+Lo4RjJgQLZiCStuSRlHdFbYLqVRI13UhRlJ/MbTcpBFNsWrJoDGKaBswCHJx8gZXW28nS3EkW/lHIZQEq5LITYsRdGCPEoYAHX7/L+V4CvAIyNje1yqLdyvIDp9SbzZZuoqXGokOTp4/00HZ+4ZZCIbP5Kx/MJBjJRmo7PufkyrXqN5NqbiFYRKgskhg8TX3GJOhtoD/ws0NPRuBVFub95joNuxYj3HcBr1ylWGujxLK3oPQpF7YKOJQohxJ8D253B3/9rfs4g8HvAL0gpw+3aSCm/Dnwd4OzZsx0dKHZpucZby/Ub2yvVNk8dKdCXjt7RNmLqhFKiIznV61NcLmMbFnr/IU4OxojUp2HtIun8MZg41cmwFUW5zx3L67h9Ncpzl5BmBP/oEfxMgWqjde8ffp86liiklJ+523tCiFUhxODW3cQgsHaXdmng3wH/QEr5YodCfc9ars/M+q1/FC+QLFXsbRMFQEQTPBRZJLryHVpDAUEsi16ZIn35LyA9BMMPI1beALcFVnwvTkNRlPvQqHud9cabtEObZqPOkNGkMJrj0nqMh45IhBAdO3a3OrOfAX5h6/UvAP/m9gZCCAv4I+CfSSn/cA9juyspQW4zsyWUd7+J0VYvYL35LWgsk575E3Lf+w3SzRloFKG1ATJEZkehXe1c4Iqi3N88B33pdTQhiEUiFHoyrJRbXLp0gVwy1tEkAd1LFL8FPC2EuAo8vbWNEOKsEOIbW22+BDwJ/KIQ4vWtf6e7E+6mRMRgtOfWb/2GJhjMxu7+Q6vnifp1NCMCgb9ZUrwyD4OnITcJZoIwOQwJVT1WUZS7EAIPHT87STF5hB+0+nELJxkYGsF2A9peZ4dOdqUzW0pZAj69zf5Xgb+z9fr3gd/f49Du6cRwmoihMbfRImroHBlIMpjZIVEIjdCM4dsN9PQQwm2iRbOQzMPSG8iDP4I3cApTV3MfFUW5C8PCHv04Lz33JtcWi0QsA6dtEOs/RI/uUWm5DOx0HXq/h+/YJ39AxUyDj4xkOTGUQdPew+3ewCnqKzMIt0hUCgglQXKAcPENzL5j+FqU9cgonR2rpSjK/a4Um4RsDaseErMMkrE4U5fPcypaILmyAPHHwVRLoe4r7ylJAAyepF4PSK++CGsu4YNfJPRdxOSP4Jgx2itXESpLKIpyD6FmkCyMkSRLpLlAc+ktkpaG4UaIX/42RCMw/nhHjq0SRYdJKZmVffT5CfKZQ7Qv/clm7XjfITF2BvfoF0nHVAEPRVF2lk9apEWbrGZTdT2MnlEmegwOOD9A81qweqFjiUIthdoBXhCyVLGZLTVZrthoToP19TWu1nQ49Bn8zARi8COUeh/i26txgtpKt0NWFGWfy8QsJnqjCOkj/DZ50yMf8ZCeA4HX0QrU6o5il9mezyvTZRYrNlLCcNrALi0zmB/FWbtOjQCz5wgVu42MjzE16zE1N0fPgHr+pCjK3dXbHrPLRUb1KpPjBbyp77H81gbLRyc5pPkwdKZjx1aJYpctlm0Wyu8udJ71i7hWjKvBYY4NCGZWirhNj4Ghw8TaFR4aGqXa2DflqxRF2adcP6ShpVhp1vEbkr7+x4g2l2kXxuHA56DQuaUKVKLYZdWWd+sOGRL1q9StEV6a0xC2BRisXJ1lsj/NqYkM1b6JboSqKMp9JGpq1AODJT9BJGzhEsVKnuSTh45Bb2cXPlOJYpdl4tYt22syh1F8mdyRg1SdCim/CJ6Da1dZXStw8tBBJsY6W0teUZT7X6XlcbQ/zeN5h3x9AWFvEOs/gq77HT+2ShS7bCQXY6UaZ6HcIpTgiQjhwGn6ohrZ/CBvX23QaBv0pQscSIGQHvGoGvWkKMrd+UHITKlJzl9l8u1v8P+3d+fBVdbnAse/z9lyQjaSkEAghMUIsggpBPBSBTcmve29kWut6FSQgdJRq06nLaNeHUbwH+5leruMzrRapoK3FJRpgVsRBSyVVlAWg2xi2MlSEhISsp/td/84h4iYHI7Jec/J8nxmMnmXX97f85wD5znv9nt9F4/jtIH/qI+Uby6CqfMt7V8LRZS5nXZuG51BdWMSXp8h1e3g8KlmxNvM/rIWqnyZ+MRQ1WRwZKQzx6/nJ5RS4V243ELpxUb+LfEcnrN7EGMgwYXL7sB24h0YeTtkWndkQi+PtYDDbiMnLZG8zAEMTHIxfdxI/K5UEtKy8GKnxRvAZnfS6A1QnzQy3uEqpXq48rpmEvHibKtBWi5jWmrxNdWRSBs2TwN4miztX/coYiDBaafBI1TUtQTHY0l20dpUz6V6oWlAbrzD6xO8Xi9lZWW0trbGO5Rez+12k5ubi9Oph0R7CrfDjufyOVqyU7AlJENrPWK80FqHf/RsHJmjLe1fC0UM1DV7SHV4+OZQGw0X/4ltQApNGXm4kjLA7rrxBtQNlZWVkZKSwsiRIy0fcrkvM8ZQU1NDWVkZo0bpRRY9xYjMAZz2N7Hn8GfcOfsnyLHNuNouI4PHYG590PJn2WihiIGaK81kX3iPBN8VmnIG0dh4icGZQlpuJg5vLZAZ7xB7vdbWVi0SUSAiZGZmUl1dHe9Q1DWyUtzMvmUopw8c5bOyavInP0KCp5o2bysmKQer9/20UFjM6w/guXQeKTtAnq2RlrJDiDMB9+km3LIYkzsNvHmWjfrYn2iRiA59HXumwamppOUk0HxsG/7TVbSkDSXxjqdISB9qed9aKCx2pcULxktyYgL+c/uw+VoQfyt2pw1b/XkYmAu+Zi0USqnwcm4hwRbAPngcAW8bpA7DNfRWJNKRrLtBC4XFEhx2qkhnyKB8fCe3E/D5EAGTnIWxOXD4PZCYHu8wlVK9gAwej3Pw+Jj3G5fLY0UkQ0S2i0hp6Henn5Qikioi5SLycixjjJZktwN3UhrnMr+Ju+B7uLJvwj2iEMYU0VxfC1nj4h2iipKZM2da3semTZs4duxY+/yyZcvYsWNHl7ZVUlLC1q1boxWaipG62kuUnfmcmovlMeszXvdRPAvsNMbcDOwMzXfmJeBvMYnKIvnZSVzwpHAx798xE79HW3Ie9TVV2Kc+AiNmxDs8FSUffvih5X1cXyhWrFjBvffe26VtaaHofT4/cYwdW/6XD/78W3Zuep1DB/YQ8Fo/hEe8CsV9wJrQ9BpgbkeNRGQqMBh4L0ZxWSJ9QAIZ/kvs3/M++y+5uDCwkKq874C3DQKBeIenoiQ5OTgwW2VlJbNmzaKgoICJEyeye/fusH/z05/+lClTpnDPPfe0X2302muvMW3aNCZPnsx3v/tdmpub+fDDD9myZQtLly6loKCAU6dOsXDhQjZu3AjAgQMHmD17NlOnTqWoqIjKykoA7rzzTp555hmmT5/OmDFj2L17Nx6Ph2XLlrFhwwYKCgrYsGGDxa+O6q762ksc3vsenpqzIDZ8zZf57MO/UF15yvK+41UoBhtjKgFCv7OvbyAiNuDnwNIbbUxEfigi+0Vkf0+8rM9mE6YkVDJ5dA4uWwDxexlpLpBUtd/yOypV7K1bt46ioiJKSko4dOgQBQUFnbZtampiypQpHDx4kNmzZ7N8+XIA7r//fvbt28ehQ4cYN24cq1evZubMmRQXF7Nq1SpKSkq46aab2rfj9Xp56qmn2LhxIwcOHGDRokU8//zz7et9Ph8ff/wxv/zlL1m+fDkul4sVK1Ywb948SkpKmDdvnnUviIqKpiu1tNWUAQIttdB0CX9rPY1X6i3v27KT2SKyAxjSwarnO1jWkSeArcaYCze6XM8Y8yrwKkBhYaH5OnHGSmJyErec28ktCUngaYXmNhg+A9wp8Q5NRdm0adNYtGgRXq+XuXPnhi0UNput/UP6kUce4f777wfgyJEjvPDCC9TV1dHY2EhRUVHYPk+cOMGRI0eYM2cOAH6/n5ycnPb1V7c7depUzp492530VJwkut24UjLxlJWA8QNg87eRZPdb3rdlhcIY0+mBUxG5KCI5xphKEckBqjpo9i/AHSLyBJAMuESk0RgT7nxGzzW0EBprIeCn2Wew4ych/+54R6UsMGvWLD744APefvtt5s+fz9KlS1mwYEFEf3v1S9HChQvZtGkTkydP5vXXX2fXrl1h/84Yw4QJE9izZ0+H6xMSgpdf2+12fD7rj2mr6Esfksf4ydM5Ul2K02nH5kggd/wMsmo+gbphMNC6p2TG69DTFuDR0PSjwObrGxhjvm+MyTPGjAR+BqzttUUCaG1toQE3Z8orOFXTzPGEWznRlkEg0CN3gFQ3nDt3juzsbJYsWcLixYs5ePBgp20DgUD7OYZ169Zx++23A9DQ0EBOTg5er5c//OEP7e1TUlJoaGj4ynbGjh1LdXV1e6Hwer0cPXo0bJydbUv1XONS2pj0ncewT5mPbfI80pJToPoYiLV3OsTrPoqVwJsishg4D3wPQEQKgceMMT+IU1yWaGhoxHPwTc6c/pyq2npEhIx/nqRh8gISE/LJy0iKd4gqinbt2sWqVatwOp0kJyezdu3aTtsmJSVx9OhRpk6dSlpaWvtJ5ZdeeokZM2YwYsQIbr311vYP9IceeoglS5bw61//ur3AALhcLjZu3MjTTz9NfX09Pp+PH//4x0yYMKHTvu+66y5WrlxJQUEBzz33nJ6n6AXK3aM49N5q/E2XAdgndgJF32dMmrV3Z4sxfesbbWFhodm/f3+8w/iS6lOHaPnbr/j8shdPmwcAh8NO1sz5eIdNZ/ooHeupu44fP864cb3vnpTk5GQaGxvjHcZX9NbXs6/7+8lqzp84DJdOgLcZMm9i4PCJFE25CXs379AWkQPGmMKO1umd2THQ5g+QlJxEmt/g8foJYMfjacVgw+Wwxzs8pVQvEQgAg/KDPyF+p4PgF37rhvLQQhEDqUlJuBJc5NirOFdxAZvDTWrOONocqYzJSIx3eCoGZsyYQVtb25eWswxw9gAADXNJREFUvfHGGz1yb0L1XHkZA6iobSDQ1gyuZLDZGJ2VhMNu7elmLRQxMODcTrzJg8giQGJyOg2ODCR3KslSQaZ/FB1fRaz6ko8++ijeIag+IM9zCp//FCcrK/AnZDByQiE3Zydb3q8Wihhw1J7C3lCBr+ozUpMHk2782FqOw+Dx0DQGUrVQKKVu4PJZbH//H/IbKhidPATjtWMvPQBDn4HkLEu71kIRC1ljkJrPcV4pg7qzwWUTH4DWBnCnxjU0pVQvUXsG6s8DYLtSFlxWfwFqT1teKOJ1H0X/MngCpA6DIZPAngC5MyAhBXKnQPqIeEenlOoN7E6+8pFtd8bkccpaKGLB4YakbJgyH+a+AlMWwKAxMKzDK9FUL7Vt2zbGjh1Lfn4+K1eu/Mr6trY25s2bR35+PjNmzNChNNTXM2gsDJ/25WWjZkPWWMu71kNPsZA9ASo+IVCyHq+3hYDdjWPqAiQjX9+AONn0STmr3j1BRV0LQwcmsrRoLHO/MazL2/P7/fzoRz9i+/bt5ObmMm3aNIqLixk//ouHzKxevZr09HROnjzJ+vXreeaZZ3TUVhW55CyY8RgMLYDas18UDtcAy7vWz6lYcLkxkx+mOXMi/sZq2txZHPMPJ+n8ZaaMyOj2jTLq69n0STnP/ekwLd7gYGrldS0896fDAF0uFh9//DH5+fmMHj0aCN5BvXnz5i8Vis2bN/Piiy8C8MADD/Dkk09ijNFnVKvIpY+Iy+FqPfQUIzVeB1trh/Gup4D9bXlUNvg5Vd3EuUs6zHisrXr3RHuRuKrF62fVuye6vM3y8nKGDx/ePp+bm0t5eXmnbRwOB2lpadTU1HS5T6ViRfcoYqTF48dpt5HosvH+8Sp8AYPLYeNKq4f73LkMTnXHO8R+o6Ku5Wstj0RHQ+Fcv6cQSRuleiLdo4iRtEQHEOCvn1Xz+cVGTlc3cfFKKwEDpVU6gmcsDR3Y8d3wnS2PRG5uLhcuXGifLysrY+jQoZ228fl81NfXk5GR0eU+lYoVLRQxEjDQ6g3Q4gk+C8BmAxHw+AyNrdY/eER9YWnRWBKdXx5jK9FpZ2lR168emTZtGqWlpZw5cwaPx8P69espLi7+Upvi4mLWrAk+AXjjxo3cfffdukehegU99BQjXn8Ap93GN/IG4vEHsNtsOO02fP4Aw9J1vKdYunrCOppXPTkcDl5++WWKiorw+/0sWrSICRMmsGzZMgoLCykuLmbx4sXMnz+f/Px8MjIyWL9+fbRSUspSOsx4jHh8fnYer8LnN5TXNXOupgW7De4am8XM/EEkurRmd4cOix1d+nr2PzrMeA/gctgpHJnOwfN1DEtPZHRWEsMzBjAuJy3eoSmlVFhaKGIoK8XNPbdk09jmw+2043bqsyiUUj2fFooYc9htDBxg/dgsSikVLXG56klEMkRku4iUhn6nd9IuT0TeE5HjInJMREbGNlKllFLxujz2WWCnMeZmYGdoviNrgVXGmHHAdKAqRvEppZQKiVehuA9YE5peA8y9voGIjAccxpjtAMaYRmNMc+xCVEqpnsXnD/DP+lbK65rb78mKhXgVisHGmEqA0O/sDtqMAepE5E8i8omIrBKRDs/+isgPRWS/iOyvrq62MGylOrdo0SKys7OZOHFih+uNMTz99NPk5+czadIkDh48GOMIVW/W7PHxj5OX2HWiir+duMSO4xepvtJ24z+MAssKhYjsEJEjHfzcF+EmHMAdwM+AacBoYGFHDY0xrxpjCo0xhVlZ1j7pSfURn74Jv5gILw4M/v70zW5vcuHChWzbtq3T9e+88w6lpaWUlpby6quv8vjjj3e7T9V/nKtpprwuOOwPQEOrn8MVdQQC1t8LZ9lVT8aYeztbJyIXRSTHGFMpIjl0fO6hDPjEGHM69DebgNuA1ZYErPqPT9+E/3savKFBAOsvBOcBJj3Y5c3OmjUr7MOINm/ezIIFCxARbrvtNurq6qisrCQnJ6fLfar+o7bJ0z7tDwQQEeqavbR4/SQlWHsBa7wOPW0BHg1NPwps7qDNPiBdRK7uItwNHItBbKqv27niiyJxlbcluNxCkQxFrlRn0gc48fkDlNe1cLTiCscq6vH4Arjs1n+Mx6tQrATmiEgpMCc0j4gUisjvAIwxfoKHnXaKyGFAgNfiFK/qS+rLvt7yKNFhxlV35GUmYbcJFZdbaPUGcNhsJCXYKevG8PiRissNd8aYGuCeDpbvB35wzfx2YFIMQ1P9QVpu8HBTR8stFMlQ5Ep1JsFhY3Cam9ljszAGHHahuc3PhdpmRg1KsrRvHWZc9T/3LAPndSP2OhODyy1UXFzM2rVrMcawd+9e0tLS9PyEipgQHFy02eOnxeunodWH3xgcduv3SnUID9X/XD1hvXNF8HBTWm6wSHTjRDbAww8/zK5du7h06RK5ubksX74cr9cLwGOPPca3v/1ttm7dSn5+PgMGDOD3v/99dzNR/YjDbiM/O4UD5y5z9SimwyaMyLR2bwK0UKj+atKD3S4M1/vjH/8Ydr2I8Morr0S1T9W/5Gcl47TbOF/ThNNuY8SgJIZ148mMkdJCoZRSvYTNJowalGT5OYmv9BvT3pRSSvU6WihUn9HXntYYL/o6qutpoVB9gtvtpqamRj/kuskYQ01NDW63O96hqB5Ez1GoPiE3N5eysjJ0UMjuc7vd5OZae0+J6l20UKg+wel0MmrUqHiHoVSfpIeelFJKhaWFQimlVFhaKJRSSoUlfe0qERGpBs5F0HQQcMnicOKhr+YFmltv1Vdz62t5jTDGdPjktz5XKCIlIvuNMYXxjiPa+mpeoLn1Vn01t76aV0f00JNSSqmwtFAopZQKqz8XilfjHYBF+mpeoLn1Vn01t76a11f023MUSimlItOf9yiUUkpFQAuFUkqpsPpNoRCRDBHZLiKlod/pYdqmiki5iLwcyxi7IpK8RKRARPaIyFER+VRE5sUj1kiJyLdE5ISInBSRZztYnyAiG0LrPxKRkbGP8uuLIK+fiMix0Hu0U0RGxCPOrrhRbte0e0BEjIj0mstKI8lNRB4MvXdHRWRdrGO0nDGmX/wA/w08G5p+FvivMG1/BawDXo533NHICxgD3ByaHgpUAgPjHXsn+diBU8BowAUcAsZf1+YJ4Deh6YeADfGOO0p53QUMCE0/3hvyijS3ULsU4ANgL1AY77ij+L7dDHwCpIfms+Mdd7R/+s0eBXAfsCY0vQaY21EjEZkKDAbei1Fc3XXDvIwxnxtjSkPTFUAV0OEdmD3AdOCkMea0McYDrCeY47WuzXkjcI+ISAxj7Iob5mWM+asxpjk0uxfoLWN9R/KeAbxE8ItNayyD66ZIclsCvGKMuQxgjKmKcYyW60+FYrAxphIg9Dv7+gYiYgN+DiyNcWzdccO8riUi0wl+MzoVg9i6Yhhw4Zr5stCyDtsYY3xAPZAZk+i6LpK8rrUYeMfSiKLnhrmJyDeA4caYv8QysCiI5H0bA4wRkX+IyF4R+VbMoouRPvU8ChHZAQzpYNXzEW7iCWCrMeZCT/qCGoW8rm4nB3gDeNQYE4hGbBbo6IW//hruSNr0NBHHLCKPAIXAbEsjip6wuYW+gP0CWBirgKIokvfNQfDw050E9wJ3i8hEY0ydxbHFTJ8qFMaYeztbJyIXRSTHGFMZ+sDsaPfwX4A7ROQJIBlwiUijMabTk3OxEIW8EJFU4G3gBWPMXotCjYYyYPg187lARSdtykTEAaQBtbEJr8siyQsRuZfgF4DZxpi2GMXWXTfKLQWYCOwKfQEbAmwRkWJjzP6YRdk1kf573GuM8QJnROQEwcKxLzYhWq8/HXraAjwamn4U2Hx9A2PM940xecaYkcDPgLXxLhIRuGFeIuIC/kwwn7diGFtX7ANuFpFRobgfIpjjta7N+QHgfRM6i9iD3TCv0OGZ3wLFvew4d9jcjDH1xphBxpiRof9bewnm2NOLBET273ETwQsREJFBBA9FnY5plBbrT4ViJTBHREqBOaF5RKRQRH4X18i6J5K8HgRmAQtFpCT0UxCfcMMLnXN4EngXOA68aYw5KiIrRKQ41Gw1kCkiJ4GfELzaq0eLMK9VBPdk3wq9R9d/IPVIEebWK0WY27tAjYgcA/4KLDXG1MQnYmvoEB5KKaXC6k97FEoppbpAC4VSSqmwtFAopZQKSwuFUkqpsLRQKKWUCksLhVJRIiL+0GWtR0TkLREZEFo+RETWi8ip0AijW0VkTGjdNhGpE5HeNrSF6ke0UCgVPS3GmAJjzETAAzwWGqzwz8AuY8xNxpjxwH8SHHgSgvdOzI9PuEpFRguFUtbYDeQTvGPXa4z5zdUVxpgSY8zu0PROoCE+ISoVGS0USkVZaPypfwUOExzj6EB8I1Kqe7RQKBU9iSJSAuwHzhMcakSpXq9PjR6rVJy1GGO+NIaWiBwlOHChUr2W7lEoZa33gQQRWXJ1gYhME5He8qwJpbRQKGWl0PDn/0FwhN9ToT2MFwk900BEdgNvEXyca5mIFMUtWKU6oaPHKqWUCkv3KJRSSoWlhUIppVRYWiiUUkqFpYVCKaVUWFoolFJKhaWFQimlVFhaKJRSSoX1/+oyqEE4vqCNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for Over Sampled Dataset\n",
    "pca_over = PCA(n_components=2)\n",
    "X_pca_over = pca_over.fit_transform(X_train_over)\n",
    "print(pca_over.explained_variance_ratio_.cumsum())\n",
    "y_temp_over = y_train_over\n",
    "y_temp_over[\"PC1\"] = X_pca_over[:,0]\n",
    "y_temp_over[\"PC2\"] = X_pca_over[:,1]\n",
    "sns.scatterplot(data=y_temp_over, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_over[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "355         1.0 -0.285029 -0.220116\n",
      "266         0.0 -0.288030  0.087318\n",
      "86          1.0 -0.282254 -0.318068\n",
      "5           1.0  0.717958 -0.169057\n",
      "68          0.0 -0.283063 -0.025754\n",
      "     is_patient\n",
      "355         1.0\n",
      "266         0.0\n",
      "86          1.0\n",
      "5           1.0\n",
      "68          0.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_over.head())\n",
    "y_train_over = y_train_over.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_over.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"second\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Undersample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9411764705882353\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5454545454545454\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.38      0.55       125\n",
      "         1.0       0.38      0.94      0.54        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.66      0.66      0.54       175\n",
      "weighted avg       0.78      0.54      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Undersample dataset:\n",
      "[0.61165049 0.65686275 0.60784314 0.61764706] \n",
      "\n",
      "0.623500856653341\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On under sample dataset\n",
    "print(\"Naive Bayes on Undersample dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on under sampled datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Undersample dataset:\")\n",
    "crossValidation(GaussianNB(), X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Undersample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.9066666666666666\n",
      "Specificity : 0.86\n",
      "F-Score : 0.68\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.54      0.68       125\n",
      "         1.0       0.43      0.86      0.57        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.67      0.70      0.63       175\n",
      "weighted avg       0.77      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM on Undersample dataset:\n",
      "[0.59223301 0.7254902  0.65686275 0.68627451] \n",
      "\n",
      "0.6652151151722825\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2 SVM Classifier On under sampled dataset\n",
    "print(\"SVM Classifier on Undersample dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on under sampled datset\n",
    "print(\"\\nCross Validation of SVM on Undersample dataset:\")\n",
    "crossValidation(LinearSVC(), X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression on Undersample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8695652173913043\n",
      "Specificity : 0.76\n",
      "F-Score : 0.7373271889400922\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.64      0.74       125\n",
      "         1.0       0.46      0.76      0.57        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.66      0.70      0.65       175\n",
      "weighted avg       0.75      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression on Undersample dataset:\n",
      "[0.54368932 0.70588235 0.64705882 0.64705882] \n",
      "\n",
      "0.6359223300970873\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3 Logistic Regression Classifier On under sampled dataset\n",
    "print(\"Logistic Regression on Undersample dataset:\")\n",
    "clfFitPredict(LogisticRegression(random_state=1), X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression on under sampled datset\n",
    "print(\"\\nCross Validation of Logistic Regression on Undersample dataset:\")\n",
    "crossValidation(LogisticRegression(random_state=1), X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN on Undersample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[98 27]\n",
      " [34 16]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.784\n",
      "Precision: 0.7424242424242424\n",
      "Specificity : 0.32\n",
      "F-Score : 0.7626459143968871\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.78      0.76       125\n",
      "         1.0       0.37      0.32      0.34        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.56      0.55      0.55       175\n",
      "weighted avg       0.64      0.65      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN on Undersample dataset:\n",
      "[0.53398058 0.64705882 0.62745098 0.6372549 ] \n",
      "\n",
      "0.6114363221016562\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4 KNN Classifier On under sampled dataset\n",
    "print(\"KNN on Undersample dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on KNN on under sampled datset\n",
    "print(\"\\nCross Validation of KNN on Undersample dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "RandomForest on Undersample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8831168831168831\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6732673267326733\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.42      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest on Undersample dataset:\n",
      "[0.65048544 0.7254902  0.76470588 0.60784314] \n",
      "\n",
      "0.6871311631448697\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5 RandomForest Classifier On under sampled dataset\n",
    "print(\"RandomForest on Undersample dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on RF on under sampled datset\n",
    "print(\"\\nCross Validation of Random Forest on Undersample dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on under sampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8987341772151899\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6960784313725489\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.57      0.70       125\n",
      "         1.0       0.44      0.84      0.58        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.67      0.70      0.64       175\n",
      "weighted avg       0.77      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on under sampled dataset:\n",
      "[0.57281553 0.70588235 0.65686275 0.65686275] \n",
      "\n",
      "0.6481058442794593\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for UnderSampled Dataset\n",
    "print(\"Voting Classifier on under sampled dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC())]\n",
    "vclf1 = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf1, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on UnderSampled datset\n",
    "print(\"\\nCross Validation of Voting Classifier on under sampled dataset:\")\n",
    "crossValidation(vclf1, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[69 56]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.552\n",
      "Precision: 0.8846153846153846\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6798029556650247\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.55      0.68       125\n",
      "         1.0       0.42      0.82      0.56        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.65      0.69      0.62       175\n",
      "weighted avg       0.75      0.63      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on undersampled dataset:\n",
      "[0.65048544 0.68627451 0.70588235 0.62745098] \n",
      "\n",
      "0.6675233200076147\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on undersampled Dataset\n",
    "\n",
    "dt_under = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_under = AdaBoostClassifier(base_estimator=dt_under, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_under, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on undersampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on undersampled dataset:\")\n",
    "crossValidation(adb_clf_under, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[56 69]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.448\n",
      "Precision: 0.9333333333333333\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6054054054054054\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.45      0.61       125\n",
      "         1.0       0.40      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.67      0.68      0.58       175\n",
      "weighted avg       0.78      0.58      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on undersampled dataset:\n",
      "[0.5631068  0.59803922 0.61764706 0.62745098] \n",
      "\n",
      "0.6015610127546164\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_under = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_under = AdaBoostClassifier(base_estimator=svc_adb_under, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_under, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Orginial datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on undersampled dataset:\")\n",
    "crossValidation(adb_clf_svc_under, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8352941176470589\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6761904761904761\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.57      0.68       125\n",
      "         1.0       0.40      0.72      0.51        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.62      0.64      0.60       175\n",
      "weighted avg       0.71      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on undersampled dataset:\n",
      "[0.6407767  0.69607843 0.73529412 0.6372549 ] \n",
      "\n",
      "0.6773510375023796\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On undersampled Dataset\n",
    "\n",
    "gbc_under = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the undersampled dataset:\")\n",
    "clfFitPredict(gbc_under, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on undersampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on undersampled dataset:\")\n",
    "crossValidation(gbc_under, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8247422680412371\n",
      "Specificity : 0.66\n",
      "F-Score : 0.7207207207207208\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.64      0.72       125\n",
      "         1.0       0.42      0.66      0.52        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.62      0.65      0.62       175\n",
      "weighted avg       0.71      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on undersampled dataset:\n",
      "[0.59223301 0.58823529 0.58823529 0.59803922] \n",
      "\n",
      "0.5916857034075766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the undersampled Dataset\n",
    "\n",
    "xgb_clf_under = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the undersampled dataset:\")\n",
    "clfFitPredict(xgb_clf_under, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on undersampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on undersampled dataset:\")\n",
    "crossValidation(xgb_clf_under, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[87 38]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.696\n",
      "Precision: 0.8207547169811321\n",
      "Specificity : 0.62\n",
      "F-Score : 0.7532467532467533\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.70      0.75       125\n",
      "         1.0       0.45      0.62      0.52        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.64      0.66      0.64       175\n",
      "weighted avg       0.71      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on UnderSampled dataset :\n",
      "[0.61165049 0.65686275 0.76470588 0.64705882] \n",
      "\n",
      "0.6700694841043213\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[87 38]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.696\n",
      "Precision: 0.8207547169811321\n",
      "Specificity : 0.62\n",
      "F-Score : 0.7532467532467533\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.70      0.75       125\n",
      "         1.0       0.45      0.62      0.52        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.64      0.66      0.64       175\n",
      "weighted avg       0.71      0.67      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On UnderSampled Dataset\n",
      "[0.61165049 0.65686275 0.76470588 0.64705882] \n",
      "\n",
      "0.6700694841043213\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 29  21]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7803030303030303\n",
      "Specificity : 0.42\n",
      "F-Score : 0.801556420233463\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       125\n",
      "         1.0       0.49      0.42      0.45        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.63      0.62      0.63       175\n",
      "weighted avg       0.70      0.71      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On UnderSampled Dataset\n",
      "[0.58252427 0.60784314 0.69607843 0.62745098] \n",
      "\n",
      "0.628474205216067\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[63 62]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.504\n",
      "Precision: 0.7682926829268293\n",
      "Specificity : 0.62\n",
      "F-Score : 0.6086956521739131\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.50      0.61       125\n",
      "         1.0       0.33      0.62      0.43        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.55      0.56      0.52       175\n",
      "weighted avg       0.64      0.54      0.56       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On UnderSampled Dataset\n",
      "[0.53398058 0.61764706 0.66666667 0.60784314] \n",
      "\n",
      "0.6065343613173425\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8409090909090909\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6948356807511737\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.59      0.69       125\n",
      "         1.0       0.41      0.72      0.53        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.63      0.66      0.61       175\n",
      "weighted avg       0.72      0.63      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On UnderSampled Dataset\n",
      "[0.63106796 0.65686275 0.65686275 0.6372549 ] \n",
      "\n",
      "0.6455120883304778\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [13 37]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8505747126436781\n",
      "Specificity : 0.74\n",
      "F-Score : 0.6981132075471698\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.59      0.70       125\n",
      "         1.0       0.42      0.74      0.54        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.64      0.67      0.62       175\n",
      "weighted avg       0.73      0.63      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On UnderSampled Dataset\n",
      "[0.63106796 0.69607843 0.71568627 0.62745098] \n",
      "\n",
      "0.6675709118598896\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8888888888888888\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7441860465116279\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.64      0.74       125\n",
      "         1.0       0.47      0.80      0.59        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.68      0.72      0.67       175\n",
      "weighted avg       0.77      0.69      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On UnderSampled Dataset\n",
      "[0.55339806 0.67647059 0.69607843 0.60784314] \n",
      "\n",
      "0.633447553778793\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on UnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on UnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on UnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_under, X_test, y_train_under, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_under, y_under, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[108  17]\n",
      " [ 33  17]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 0.864\n",
      "Precision: 0.7659574468085106\n",
      "Specificity : 0.34\n",
      "F-Score : 0.8120300751879698\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.86      0.81       125\n",
      "         1.0       0.50      0.34      0.40        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.63      0.60      0.61       175\n",
      "weighted avg       0.69      0.71      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on UnderSampled dataset :\n",
      "[0.63106796 0.62745098 0.6372549  0.60784314] \n",
      "\n",
      "0.625904245193223\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The UnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on UnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on UnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54775031 0.72116793 0.82227    0.90717459 0.95267518 0.98177\n",
      " 0.99355516 0.99794462 0.99913443 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With UnderSampled PCA Training dataset\n",
    "\n",
    "pca_under_1 = PCA()\n",
    "X_pca_under_1 = pca_under_1.fit_transform(X_train_under)\n",
    "print(pca_under_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_under1 = PCA(n_components=6)\n",
    "X_pca_train_under1 = pd.DataFrame(pca_under1.fit_transform(X_train_under))\n",
    "X_pca_test_under1 = pd.DataFrame(pca_under1.transform(X_test))\n",
    "\n",
    "X_pca_under1 = pd.concat([X_pca_train_under1, X_pca_test_under1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[55 70]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.5142857142857142\n",
      "Sensitivity : 0.44\n",
      "Precision: 0.7857142857142857\n",
      "Specificity : 0.7\n",
      "F-Score : 0.5641025641025641\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.44      0.56       125\n",
      "         1.0       0.33      0.70      0.45        50\n",
      "\n",
      "    accuracy                           0.51       175\n",
      "   macro avg       0.56      0.57      0.51       175\n",
      "weighted avg       0.66      0.51      0.53       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on UnderSampled PCA Training dataset:\n",
      "[0.61165049 0.6372549  0.62745098 0.57843137] \n",
      "\n",
      "0.6136969350847135\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8831168831168831\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6732673267326733\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.42      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on UnderSampled PCA Training dataset:\n",
      "[0.5631068  0.7254902  0.66666667 0.66666667] \n",
      "\n",
      "0.6554825813820673\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.8777777777777778\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7348837209302325\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.63      0.73       125\n",
      "         1.0       0.46      0.78      0.58        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.67      0.71      0.66       175\n",
      "weighted avg       0.76      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on UnderSampled PCA Training dataset::\n",
      "[0.5631068  0.69607843 0.66666667 0.62745098] \n",
      "\n",
      "0.6383257186369693\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[98 27]\n",
      " [37 13]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.784\n",
      "Precision: 0.725925925925926\n",
      "Specificity : 0.26\n",
      "F-Score : 0.7538461538461539\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.78      0.75       125\n",
      "         1.0       0.33      0.26      0.29        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.53      0.52      0.52       175\n",
      "weighted avg       0.61      0.63      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on UnderSampled PCA Training dataset:\n",
      "[0.54368932 0.62745098 0.62745098 0.61764706] \n",
      "\n",
      "0.6040595849990482\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [20 30]]\n",
      "\n",
      "Accuracy : 0.5771428571428572\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.7802197802197802\n",
      "Specificity : 0.6\n",
      "F-Score : 0.6574074074074073\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.57      0.66       125\n",
      "         1.0       0.36      0.60      0.45        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.57      0.58      0.55       175\n",
      "weighted avg       0.66      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on UnderSampled PCA Training dataset:\n",
      "[0.54368932 0.69607843 0.67647059 0.6372549 ] \n",
      "\n",
      "0.6383733104892442\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8705882352941177\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7047619047619046\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.59      0.70       125\n",
      "         1.0       0.43      0.78      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.65      0.69      0.63       175\n",
      "weighted avg       0.75      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on UnderSampled PCA Training dataset:\n",
      "[0.5631068  0.7254902  0.66666667 0.6372549 ] \n",
      "\n",
      "0.6481296402055967\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [21 29]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.776595744680851\n",
      "Specificity : 0.58\n",
      "F-Score : 0.6666666666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.58      0.67       125\n",
      "         1.0       0.36      0.58      0.44        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.57      0.58      0.55       175\n",
      "weighted avg       0.66      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on undersampled PCA Training dataset:\n",
      "[0.53398058 0.66666667 0.60784314 0.62745098] \n",
      "\n",
      "0.6089853417094994\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.9076923076923077\n",
      "Specificity : 0.88\n",
      "F-Score : 0.6210526315789474\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.47      0.62       125\n",
      "         1.0       0.40      0.88      0.55        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.65      0.68      0.59       175\n",
      "weighted avg       0.76      0.59      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVC as base estimator on undersampled PCA Training dataset:\n",
      "[0.54368932 0.59803922 0.58823529 0.60784314] \n",
      "\n",
      "0.5844517418617933\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8021978021978022\n",
      "Specificity : 0.64\n",
      "F-Score : 0.675925925925926\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.58      0.68       125\n",
      "         1.0       0.38      0.64      0.48        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.59      0.61      0.58       175\n",
      "weighted avg       0.68      0.60      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on undersampled dataset:\n",
      "[0.61165049 0.65686275 0.67647059 0.59803922] \n",
      "\n",
      "0.6357557586141253\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[99 26]\n",
      " [34 16]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.792\n",
      "Precision: 0.7443609022556391\n",
      "Specificity : 0.32\n",
      "F-Score : 0.7674418604651163\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.79      0.77       125\n",
      "         1.0       0.38      0.32      0.35        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.56      0.56      0.56       175\n",
      "weighted avg       0.64      0.66      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on undersampled PCA Training dataset:\n",
      "[0.59223301 0.58823529 0.58823529 0.59803922] \n",
      "\n",
      "0.5916857034075766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[87 38]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.696\n",
      "Precision: 0.8207547169811321\n",
      "Specificity : 0.62\n",
      "F-Score : 0.7532467532467533\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.70      0.75       125\n",
      "         1.0       0.45      0.62      0.52        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.64      0.66      0.64       175\n",
      "weighted avg       0.71      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on UnderSampled dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61165049 0.65686275 0.76470588 0.64705882] \n",
      "\n",
      "0.6700694841043213\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[87 38]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.696\n",
      "Precision: 0.8207547169811321\n",
      "Specificity : 0.62\n",
      "F-Score : 0.7532467532467533\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.70      0.75       125\n",
      "         1.0       0.45      0.62      0.52        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.64      0.66      0.64       175\n",
      "weighted avg       0.71      0.67      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On UnderSampled Dataset\n",
      "[0.61165049 0.65686275 0.76470588 0.64705882] \n",
      "\n",
      "0.6700694841043213\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 29  21]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7803030303030303\n",
      "Specificity : 0.42\n",
      "F-Score : 0.801556420233463\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       125\n",
      "         1.0       0.49      0.42      0.45        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.63      0.62      0.63       175\n",
      "weighted avg       0.70      0.71      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On UnderSampled Dataset\n",
      "[0.58252427 0.60784314 0.69607843 0.62745098] \n",
      "\n",
      "0.628474205216067\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[63 62]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.504\n",
      "Precision: 0.7682926829268293\n",
      "Specificity : 0.62\n",
      "F-Score : 0.6086956521739131\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.50      0.61       125\n",
      "         1.0       0.33      0.62      0.43        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.55      0.56      0.52       175\n",
      "weighted avg       0.64      0.54      0.56       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On UnderSampled Dataset\n",
      "[0.53398058 0.61764706 0.66666667 0.60784314] \n",
      "\n",
      "0.6065343613173425\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8409090909090909\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6948356807511737\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.59      0.69       125\n",
      "         1.0       0.41      0.72      0.53        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.63      0.66      0.61       175\n",
      "weighted avg       0.72      0.63      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On UnderSampled Dataset\n",
      "[0.63106796 0.65686275 0.65686275 0.6372549 ] \n",
      "\n",
      "0.6455120883304778\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [13 37]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8505747126436781\n",
      "Specificity : 0.74\n",
      "F-Score : 0.6981132075471698\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.59      0.70       125\n",
      "         1.0       0.42      0.74      0.54        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.64      0.67      0.62       175\n",
      "weighted avg       0.73      0.63      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On UnderSampled Dataset\n",
      "[0.63106796 0.69607843 0.71568627 0.62745098] \n",
      "\n",
      "0.6675709118598896\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8888888888888888\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7441860465116279\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.64      0.74       125\n",
      "         1.0       0.47      0.80      0.59        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.68      0.72      0.67       175\n",
      "weighted avg       0.77      0.69      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On UnderSampled Dataset\n",
      "[0.55339806 0.67647059 0.69607843 0.60784314] \n",
      "\n",
      "0.633447553778793\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[108  17]\n",
      " [ 33  17]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 0.864\n",
      "Precision: 0.7659574468085106\n",
      "Specificity : 0.34\n",
      "F-Score : 0.8120300751879698\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.86      0.81       125\n",
      "         1.0       0.50      0.34      0.40        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.63      0.60      0.61       175\n",
      "weighted avg       0.69      0.71      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on UnderSampled dataset :\n",
      "[0.63106796 0.62745098 0.6372549  0.60784314] \n",
      "\n",
      "0.625904245193223\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On UnderSampled PCA Training dataset\n",
    "print(\"Naive Bayes on UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on UnderSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Naive Bayes on UnderSampled PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On UnderSampled PCA Training dataset:\n",
    "print(\"SVM Classifier on UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on UnderSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of SVM Classifier on UnderSampled PCA Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On UnderSampled PCA Training dataset:\n",
    "print(\"Logistic Regression Classifier on UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on UnderSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on UnderSampled PCA Training dataset::\")\n",
    "crossValidation(LogisticRegression(), X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On UnderSampled PCA Training dataset\n",
    "print(\"KNN Classifier on UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on UnderSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of KNN Classifier on UnderSampled PCA Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On UnderSampled PCA Training dataset:\n",
    "print(\"Random Forest Classifier on UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on UnderSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Random Forest Classifier on UnderSampled PCA Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for UnderSampled PCA Training dataset:\n",
    "print(\"Voting Classifier on UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on UnderSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Voting Classifier on UnderSampled PCA Training dataset:\")\n",
    "crossValidation(vclf, X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_under, X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier with Decision Tree on undersampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_under, X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator on undersampled PCA Training Dataset \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_under, X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on undersampled PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVC as base estimator on undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_under, X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier on the undersampled PCA Training dataset:\")\n",
    "clfFitPredict(gbc_under, X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on undersampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on undersampled dataset:\")\n",
    "crossValidation(gbc_under, X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the undersampled PCA Training Dataset\n",
    "print(\"\\nXGBClassifier on the undersampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_under, X_pca_train_under1, X_pca_test_under1, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on undersampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_under, X_pca_under1, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Bagging Classifier On the UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on UnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on UnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on UnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_under, X_test, y_train_under, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_under, y_under, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The UnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on UnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on UnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_under.pkl']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC On UnderSampled Dataset\n",
    "random_svc_under = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_svc_under.fit(X_train_under, y_train_under.values.ravel())\n",
    "joblib.dump(random_svc_under, \"RSCV_SVC_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on SVC for UnderSampled Dataset - \n",
      "\n",
      "Best Score : 0.6885869565217391\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Accuracy Score : 0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on SVC for UnderSampled Dataset - \")\n",
    "RSCV_SVC_under = joblib.load(\"RSCV_SVC_under.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_SVC_under.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_under.best_params_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_SVC_under.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_pca_under.pkl']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC On UnderSampled PCA Dataset\n",
    "random_svc_pca_under = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_svc_pca_under.fit(X_pca_train_under1, y_train_under.values.ravel())\n",
    "joblib.dump(random_svc_pca_under, \"RSCV_SVC_pca_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on SVC for UnderSampled PCA Dataset - \n",
      "\n",
      "Best Score : 0.6797101449275362\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on SVC for UnderSampled PCA Dataset - \")\n",
    "RSCV_SVC_pca_under = joblib.load(\"RSCV_SVC_pca_under.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_SVC_pca_under.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_pca_under.best_params_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_SVC_pca_under.predict(X_pca_test_under1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    7.0s finished\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_under.pkl']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning on LR on UnderSampled Dataset\n",
    "random_logreg_under = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,\n",
    "                            scoring='accuracy', \n",
    "                            refit=True,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1,\n",
    "                            n_iter=100,\n",
    "                            random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_under.fit(X_train_under, y_train_under.values.ravel())\n",
    "joblib.dump(random_logreg_under, \"RSCV_LR_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on Logistic Regression on UnderSampled Dataset -\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 50}\n",
      "\n",
      "Best Score : 0.7268115942028986\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on Logistic Regression on UnderSampled Dataset -\")\n",
    "RSCV_LR_under_loaded = joblib.load(\"RSCV_LR_under.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_under_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_under_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_under_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_under.pkl']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logreg_pca_under = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_under.fit(X_pca_train_under1, y_train_under.values.ravel())\n",
    "joblib.dump(random_logreg_pca_under, \"RSCV_LR_pca_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR on UnderSampled PCA Dataset -\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.6753623188405797\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR on UnderSampled PCA Dataset -\")\n",
    "RSCV_LR_pca_under_loaded = joblib.load(\"RSCV_LR_pca_under.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_under_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_under_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_under_loaded.predict(X_pca_test_under1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_under.pkl']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rf_under = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False, \n",
    "                               cv=10,\n",
    "                               scoring='accuracy', \n",
    "                               refit=True,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=0\n",
    "                              )\n",
    "random_rf_under.fit(X_train_under, y_train_under.values.ravel())\n",
    "joblib.dump(random_rf_under, \"RSCV_RF_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF for UnderSampled Dataset -\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7126811594202899\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF for UnderSampled Dataset -\")\n",
    "RSCV_RF_under_loaded = joblib.load(\"RSCV_RF_under.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_under_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_under_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_under_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_under.pkl']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rf_pca_under = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_rf_pca_under.fit(X_pca_train_under1, y_train_under.values.ravel())\n",
    "joblib.dump(random_rf_pca_under, \"RSCV_RF_pca_under.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF for UnderSampled PCA Dataset -\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.30000000000000004, 'max_features': 'auto', 'max_depth': 22.0, 'bootstrap': True}\n",
      "\n",
      "Best Score : 0.6286231884057971\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF for UnderSampled PCA Dataset -\")\n",
    "RSCV_RF_pca_under_loaded = joblib.load(\"RSCV_RF_pca_under.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_under_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_under_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_under_loaded.predict(X_pca_test_under1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_under.pkl']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomizedSearchCV for GradientBoostingClassifier on UnderSampled Dataset\n",
    "clf_gbc_under = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy',\n",
    "                             refit=True, \n",
    "                             n_jobs=-1,\n",
    "                             verbose=False,\n",
    "                             random_state=0\n",
    "                            )\n",
    "clf_gbc_under.fit(X_train_under, y_train_under.values.ravel())\n",
    "joblib.dump(clf_gbc_under,'RSCV_GBC_under.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GradientBoostingClassifier on UnderSampled Dataset :\n",
      "\n",
      "Best Score : 0.7175724637681159\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 1.0, 'min_samples_leaf': 0.1, 'max_depth': 22.0, 'learning_rate': 0.005}\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GradientBoostingClassifier on UnderSampled Dataset :\")\n",
    "RSCV_GBC_under_loaded = joblib.load(\"RSCV_GBC_under.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_under_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_under_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_under_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_under.pkl']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomizedSearchCV for GradientBoostingClassifier on UnderSampled PCA Dataset\n",
    "clf_gbc_pca_under = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy',\n",
    "                             refit=True, \n",
    "                             n_jobs=-1,\n",
    "                             verbose=False,\n",
    "                             random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_under.fit(X_pca_train_under1, y_train_under.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_under,'RSCV_GBC_pca_under.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC on UnderSampled PCA Dataset :\n",
      "\n",
      "Best Score - 0.6666666666666665\n",
      "\n",
      "Best Parameter - {'n_estimators': 300, 'min_samples_split': 0.6, 'min_samples_leaf': 0.4, 'max_depth': 24.0, 'learning_rate': 0.05}\n",
      "\n",
      "Accuracy Score - 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC on UnderSampled PCA Dataset :\")\n",
    "RSCV_GBC_pca_under_loaded = joblib.load(\"RSCV_GBC_pca_under.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_GBC_pca_under_loaded.best_score_)\n",
    "print(\"\\nBest Parameter -\", RSCV_GBC_pca_under_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_GBC_pca_under_loaded.predict(X_pca_test_under1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_under.pkl']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier on UnderSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_under = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_under.fit(X_train_under, y_train_under.values.ravel())\n",
    "joblib.dump(random_adaboost_under, \"RSCV_ADC_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for AdaBoostClassifier with Decision Tree as base classifier on Undersampled Dataset :\n",
      "\n",
      "Best Score - 0.5702898550724639\n",
      "\n",
      "Best Parameters - {'n_estimators': 64, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for AdaBoostClassifier with Decision Tree as base classifier on Undersampled Dataset :\")\n",
    "RSCV_ADC_under_loaded = joblib.load(\"RSCV_ADC_under.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_under_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_under_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_under_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_under.pkl']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_under = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "\n",
    "random_adaboost_svc_under.fit(X_train_under, y_train_under.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_under, \"RSCV_ADC_SVC_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on UnderSampled Dataset -\n",
      "\n",
      "Best Score : 0.48695652173913045\n",
      "\n",
      "Best Parameter : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Accuracy Score : 0.6228571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on UnderSampled Dataset -\")\n",
    "RSCV_ADC_SVC_under_loaded = joblib.load(\"RSCV_ADC_SVC_under.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_SVC_under_loaded.best_score_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_SVC_under_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_under_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_pca_under.pkl']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for ADC with SVC as base estimator on UnderSampled PCA Dataset\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_under = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "\n",
    "#X_pca_train_under1, X_pca_test_under1, y_train_under, y_test\n",
    "random_adaboost_svc_pca_under.fit(X_pca_train_under1, y_train_under.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_under, \"RSCV_ADC_SVC_pca_under.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC as base estimator on UnderSampled PCA Dataset :\n",
      "\n",
      "Best Score - 0.49112318840579716\n",
      "\n",
      "Best Parameter - {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Accuracy Score - 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC as base estimator on UnderSampled PCA Dataset :\")\n",
    "RSCV_ADC_SVC_pca_under_loaded = joblib.load(\"RSCV_ADC_SVC_pca_under.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_SVC_pca_under_loaded.best_score_)\n",
    "print(\"\\nBest Parameter -\", RSCV_ADC_SVC_pca_under_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_ADC_SVC_pca_under_loaded.predict(X_pca_test_under1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning on XGBoostClassifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"third\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Oversample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9411764705882353\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5454545454545454\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.38      0.55       125\n",
      "         1.0       0.38      0.94      0.54        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.66      0.66      0.54       175\n",
      "weighted avg       0.78      0.54      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Oversample dataset:\n",
      "[0.66315789 0.64550265 0.65608466 0.64021164] \n",
      "\n",
      "0.651239209133946\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Over sample dataset\n",
    "print(\"Naive Bayes on Oversample dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Over sampled datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Oversample dataset:\")\n",
    "crossValidation(GaussianNB(), X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Oversample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8831168831168831\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6732673267326733\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.42      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Oversample dataset:\n",
      "[0.73157895 0.68253968 0.67195767 0.66666667] \n",
      "\n",
      "0.6881857421331106\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2 SVM Classifier On Over sample dataset\n",
    "print(\"SVM Classifier on Oversample dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Over sampled datset\n",
    "print(\"\\nCross Validation of SVM Classifier on Oversample dataset:\")\n",
    "crossValidation(LinearSVC(), X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Oversample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8809523809523809\n",
      "Specificity : 0.8\n",
      "F-Score : 0.708133971291866\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.59      0.71       125\n",
      "         1.0       0.44      0.80      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.70      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Oversample dataset:\n",
      "[0.68947368 0.64550265 0.64550265 0.67724868] \n",
      "\n",
      "0.6644319131161236\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3 Logistic Regression Classifier On Over sample dataset\n",
    "print(\"Logistic Regression Classifier on Oversample dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Over sampled datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Oversample dataset:\")\n",
    "crossValidation(LogisticRegression(), X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Oversample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 33  17]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7573529411764706\n",
      "Specificity : 0.34\n",
      "F-Score : 0.789272030651341\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79       125\n",
      "         1.0       0.44      0.34      0.38        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.60      0.58      0.59       175\n",
      "weighted avg       0.67      0.69      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Oversample dataset:\n",
      "[0.78947368 0.80952381 0.76190476 0.6984127 ] \n",
      "\n",
      "0.7648287385129491\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4 KNN Classifier On Over sample dataset\n",
    "print(\"KNN Classifier on Oversample dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Over sampled datset\n",
    "print(\"\\nCross Validation of KNN Classifier on Oversample dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Oversample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8791208791208791\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7407407407407407\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.64      0.74       125\n",
      "         1.0       0.46      0.78      0.58        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.67      0.71      0.66       175\n",
      "weighted avg       0.76      0.68      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Oversample dataset:\n",
      "[0.83157895 0.75132275 0.6984127  0.68783069] \n",
      "\n",
      "0.7422862712336397\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5 Random Forest Classifier On Over sample dataset\n",
    "print(\"Random Forest Classifier on Oversample dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Over sampled datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Oversample dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on over sampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8809523809523809\n",
      "Specificity : 0.8\n",
      "F-Score : 0.708133971291866\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.59      0.71       125\n",
      "         1.0       0.44      0.80      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.70      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on under sampled dataset:\n",
      "[0.74210526 0.6984127  0.66666667 0.66137566] \n",
      "\n",
      "0.6921400724032303\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for OverSampled Dataset\n",
    "\n",
    "print(\"Voting Classifier on over sampled dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on UnderSampled datset\n",
    "print(\"\\nCross Validation of Voting Classifier on under sampled dataset:\")\n",
    "crossValidation(vclf, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Oversampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8987341772151899\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6960784313725489\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.57      0.70       125\n",
      "         1.0       0.44      0.84      0.58        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.67      0.70      0.64       175\n",
      "weighted avg       0.77      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Oversampled dataset:\n",
      "[0.76842105 0.68783069 0.67195767 0.69312169] \n",
      "\n",
      "0.7053327763854079\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Oversampled Dataset\n",
    "\n",
    "dt_over = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_over = AdaBoostClassifier(base_estimator=dt_over, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Oversampled Dataset:\")\n",
    "clfFitPredict(adb_clf_over, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Oversampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Oversampled dataset:\")\n",
    "crossValidation(adb_clf_over, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Oversampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[88 37]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.704\n",
      "Precision: 0.8301886792452831\n",
      "Specificity : 0.64\n",
      "F-Score : 0.7619047619047619\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.70      0.76       125\n",
      "         1.0       0.46      0.64      0.54        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.65      0.67      0.65       175\n",
      "weighted avg       0.73      0.69      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Oversampled dataset:\n",
      "[0.69473684 0.64021164 0.6031746  0.6031746 ] \n",
      "\n",
      "0.6353244221665275\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator on OverSampled Dataset\n",
    "\n",
    "svc_adb_over = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_over = AdaBoostClassifier(base_estimator=svc_adb_over, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Oversampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_over, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Oversampled datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Oversampled dataset:\")\n",
    "crossValidation(adb_clf_svc_over, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Oversampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[84 41]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.672\n",
      "Precision: 0.8484848484848485\n",
      "Specificity : 0.7\n",
      "F-Score : 0.75\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.67      0.75       125\n",
      "         1.0       0.46      0.70      0.56        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.65      0.69      0.65       175\n",
      "weighted avg       0.74      0.68      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Oversampled dataset:\n",
      "[0.75263158 0.74603175 0.62962963 0.72486772] \n",
      "\n",
      "0.7132901698691172\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Oversampled Dataset\n",
    "\n",
    "gbc_over = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the Oversampled dataset:\")\n",
    "clfFitPredict(gbc_over, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Oversampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Oversampled dataset:\")\n",
    "crossValidation(gbc_over, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Oversampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.8144329896907216\n",
      "Specificity : 0.64\n",
      "F-Score : 0.7117117117117119\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.63      0.71       125\n",
      "         1.0       0.41      0.64      0.50        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.61      0.64      0.61       175\n",
      "weighted avg       0.70      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Oversampled dataset:\n",
      "[0.54736842 0.55026455 0.55026455 0.55026455] \n",
      "\n",
      "0.5495405179615706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Oversampled Dataset\n",
    "\n",
    "xgb_clf_over = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the Oversampled dataset:\")\n",
    "clfFitPredict(xgb_clf_over, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Oversampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Oversampled dataset:\")\n",
    "crossValidation(xgb_clf_over, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on OverSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.6971428571428572\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7686567164179104\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7953667953667953\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.82      0.80       125\n",
      "         1.0       0.46      0.38      0.42        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.62      0.60      0.61       175\n",
      "weighted avg       0.68      0.70      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on OverSampled dataset :\n",
      "[0.86842105 0.82539683 0.78835979 0.71957672] \n",
      "\n",
      "0.8004385964912281\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.6971428571428572\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7686567164179104\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7953667953667953\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.82      0.80       125\n",
      "         1.0       0.46      0.38      0.42        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.62      0.60      0.61       175\n",
      "weighted avg       0.68      0.70      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On OverSampled Dataset\n",
      "[0.86842105 0.82539683 0.78835979 0.71957672] \n",
      "\n",
      "0.8004385964912281\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 32  18]]\n",
      "\n",
      "Accuracy : 0.6914285714285714\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.762962962962963\n",
      "Specificity : 0.36\n",
      "F-Score : 0.7923076923076923\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79       125\n",
      "         1.0       0.45      0.36      0.40        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.61      0.59      0.60       175\n",
      "weighted avg       0.67      0.69      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On OverSampled Dataset\n",
      "[0.59473684 0.67724868 0.66666667 0.58730159] \n",
      "\n",
      "0.6314884433305485\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.8229166666666666\n",
      "Specificity : 0.66\n",
      "F-Score : 0.7149321266968326\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.63      0.71       125\n",
      "         1.0       0.42      0.66      0.51        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.62      0.65      0.61       175\n",
      "weighted avg       0.71      0.64      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On OverSampled Dataset\n",
      "[0.73157895 0.73015873 0.65608466 0.6984127 ] \n",
      "\n",
      "0.7040587580061264\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.8837209302325582\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7203791469194313\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.61      0.72       125\n",
      "         1.0       0.45      0.80      0.58        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.67      0.70      0.65       175\n",
      "weighted avg       0.76      0.66      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On OverSampled Dataset\n",
      "[0.75263158 0.61904762 0.62433862 0.67724868] \n",
      "\n",
      "0.6683166248955722\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[89 36]\n",
      " [27 23]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.712\n",
      "Precision: 0.7672413793103449\n",
      "Specificity : 0.46\n",
      "F-Score : 0.7385892116182572\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.71      0.74       125\n",
      "         1.0       0.39      0.46      0.42        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.58      0.59      0.58       175\n",
      "weighted avg       0.66      0.64      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On OverSampled Dataset\n",
      "[0.85789474 0.83068783 0.71957672 0.6984127 ] \n",
      "\n",
      "0.7766429963798385\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[82 43]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6914285714285714\n",
      "Sensitivity : 0.656\n",
      "Precision: 0.8817204301075269\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7522935779816514\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.66      0.75       125\n",
      "         1.0       0.48      0.78      0.59        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.68      0.72      0.67       175\n",
      "weighted avg       0.77      0.69      0.71       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On OverSampled Dataset\n",
      "[0.72631579 0.67195767 0.64550265 0.6984127 ] \n",
      "\n",
      "0.685547201336675\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the OverSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on OverSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on OverSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on OverSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On OverSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_over, X_test, y_train_over, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On OverSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_over, y_over, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on OverSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[92 33]\n",
      " [22 28]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.736\n",
      "Precision: 0.8070175438596491\n",
      "Specificity : 0.56\n",
      "F-Score : 0.7698744769874476\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.74      0.77       125\n",
      "         1.0       0.46      0.56      0.50        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.63      0.65      0.64       175\n",
      "weighted avg       0.71      0.69      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on OverSampled dataset :\n",
      "[0.59473684 0.65608466 0.61375661 0.56084656] \n",
      "\n",
      "0.6063561681982734\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The OverSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on OverSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_over, X_test, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on OverSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on OverSampled dataset :\")\n",
    "crossValidation(clf_percept, X_over, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5588312  0.7331914  0.82880525 0.91173706 0.95034121 0.97520245\n",
      " 0.99524933 0.99806641 0.99938238 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With OverSampled PCA Training dataset:\n",
    "\n",
    "pca_over_1 = PCA()\n",
    "X_pca_over_1 = pca_over_1.fit_transform(X_train_over)\n",
    "print(pca_over_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_over1 = PCA(n_components=5)\n",
    "X_pca_train_over1 = pd.DataFrame(pca_over1.fit_transform(X_train_over))\n",
    "X_pca_test_over1 = pd.DataFrame(pca_over1.transform(X_test))\n",
    "\n",
    "X_pca_over1 = pd.concat([X_pca_train_over1, X_pca_test_over1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.8309859154929577\n",
      "Specificity : 0.76\n",
      "F-Score : 0.6020408163265306\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.47      0.60       125\n",
      "         1.0       0.37      0.76      0.49        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.60      0.62      0.55       175\n",
      "weighted avg       0.70      0.55      0.57       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on OverSampled PCA Training dataset:\n",
      "[0.65789474 0.57142857 0.58730159 0.6031746 ] \n",
      "\n",
      "0.6049498746867168\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[72 53]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.576\n",
      "Precision: 0.8888888888888888\n",
      "Specificity : 0.82\n",
      "F-Score : 0.699029126213592\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.58      0.70       125\n",
      "         1.0       0.44      0.82      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.70      0.63       175\n",
      "weighted avg       0.76      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on OverSampled PCA Training dataset:\n",
      "[0.71052632 0.65079365 0.62433862 0.65079365] \n",
      "\n",
      "0.6591130604288499\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.8735632183908046\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7169811320754718\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.61      0.72       125\n",
      "         1.0       0.44      0.78      0.57        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.66      0.69      0.64       175\n",
      "weighted avg       0.75      0.66      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on OverSampled PCA Training dataset::\n",
      "[0.65789474 0.63492063 0.6031746  0.67195767] \n",
      "\n",
      "0.6419869117237539\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[108  17]\n",
      " [ 32  18]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.864\n",
      "Precision: 0.7714285714285715\n",
      "Specificity : 0.36\n",
      "F-Score : 0.8150943396226416\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.86      0.82       125\n",
      "         1.0       0.51      0.36      0.42        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.64      0.61      0.62       175\n",
      "weighted avg       0.70      0.72      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on OverSampled PCA Training dataset:\n",
      "[0.78421053 0.7989418  0.74074074 0.71957672] \n",
      "\n",
      "0.7608674463937622\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8095238095238095\n",
      "Specificity : 0.68\n",
      "F-Score : 0.6507177033492824\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.54      0.65       125\n",
      "         1.0       0.37      0.68      0.48        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.59      0.61      0.57       175\n",
      "weighted avg       0.68      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on OverSampled PCA Training dataset:\n",
      "[0.76315789 0.73015873 0.71428571 0.61904762] \n",
      "\n",
      "0.7066624895572264\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8902439024390244\n",
      "Specificity : 0.82\n",
      "F-Score : 0.7053140096618358\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.58      0.71       125\n",
      "         1.0       0.44      0.82      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.67      0.70      0.64       175\n",
      "weighted avg       0.76      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on OverSampled PCA Training dataset:\n",
      "[0.72105263 0.64021164 0.62433862 0.65608466] \n",
      "\n",
      "0.6604218880534669\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Oversampled PCA Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.8205128205128205\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6305418719211823\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.51      0.63       125\n",
      "         1.0       0.37      0.72      0.49        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.60      0.62      0.56       175\n",
      "weighted avg       0.69      0.57      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Oversampled PCA dataset:\n",
      "[0.73684211 0.67195767 0.64550265 0.58201058] \n",
      "\n",
      "0.6590782511835143\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on oversampled PCA Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8902439024390244\n",
      "Specificity : 0.82\n",
      "F-Score : 0.7053140096618358\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.58      0.71       125\n",
      "         1.0       0.44      0.82      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.67      0.70      0.64       175\n",
      "weighted avg       0.76      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Oversampled PCA Training dataset:\n",
      "[0.68947368 0.63492063 0.5978836  0.60846561] \n",
      "\n",
      "0.632685881370092\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Oversampled PCA dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [21 29]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.7789473684210526\n",
      "Specificity : 0.58\n",
      "F-Score : 0.6727272727272727\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.59      0.67       125\n",
      "         1.0       0.36      0.58      0.45        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.57      0.59      0.56       175\n",
      "weighted avg       0.66      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Oversampled PCA Training dataset:\n",
      "[0.8        0.71428571 0.7037037  0.62962963] \n",
      "\n",
      "0.7119047619047619\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Oversampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[97 28]\n",
      " [31 19]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.776\n",
      "Precision: 0.7578125\n",
      "Specificity : 0.38\n",
      "F-Score : 0.766798418972332\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.78      0.77       125\n",
      "         1.0       0.40      0.38      0.39        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.58      0.58      0.58       175\n",
      "weighted avg       0.66      0.66      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Oversampled PCA Training dataset:\n",
      "[0.54736842 0.55026455 0.55026455 0.55026455] \n",
      "\n",
      "0.5495405179615706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on OverSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[102  23]\n",
      " [ 33  17]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.816\n",
      "Precision: 0.7555555555555555\n",
      "Specificity : 0.34\n",
      "F-Score : 0.7846153846153846\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.78       125\n",
      "         1.0       0.42      0.34      0.38        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.59      0.58      0.58       175\n",
      "weighted avg       0.66      0.68      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on OverSampled dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91578947 0.83068783 0.78835979 0.70899471] \n",
      "\n",
      "0.8109579504316347\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[102  23]\n",
      " [ 33  17]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.816\n",
      "Precision: 0.7555555555555555\n",
      "Specificity : 0.34\n",
      "F-Score : 0.7846153846153846\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.78       125\n",
      "         1.0       0.42      0.34      0.38        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.59      0.58      0.58       175\n",
      "weighted avg       0.66      0.68      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On UnderSampled Dataset\n",
      "[0.91578947 0.83068783 0.78835979 0.70899471] \n",
      "\n",
      "0.8109579504316347\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[100  25]\n",
      " [ 29  21]]\n",
      "\n",
      "Accuracy : 0.6914285714285714\n",
      "Sensitivity : 0.8\n",
      "Precision: 0.7751937984496124\n",
      "Specificity : 0.42\n",
      "F-Score : 0.7874015748031497\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79       125\n",
      "         1.0       0.46      0.42      0.44        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.62      0.61      0.61       175\n",
      "weighted avg       0.68      0.69      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On UnderSampled Dataset\n",
      "[0.67894737 0.63492063 0.59259259 0.57671958] \n",
      "\n",
      "0.6207950431634642\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.8061224489795918\n",
      "Specificity : 0.62\n",
      "F-Score : 0.7085201793721974\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.63      0.71       125\n",
      "         1.0       0.40      0.62      0.49        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.60      0.63      0.60       175\n",
      "weighted avg       0.69      0.63      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On UnderSampled Dataset\n",
      "[0.72631579 0.73015873 0.66137566 0.70899471] \n",
      "\n",
      "0.7067112225006962\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.8837209302325582\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7203791469194313\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.61      0.72       125\n",
      "         1.0       0.45      0.80      0.58        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.67      0.70      0.65       175\n",
      "weighted avg       0.76      0.66      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On UnderSampled Dataset\n",
      "[0.70526316 0.65608466 0.59259259 0.68783069] \n",
      "\n",
      "0.6604427736006683\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[94 31]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.752\n",
      "Precision: 0.7704918032786885\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7611336032388664\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.75      0.76       125\n",
      "         1.0       0.42      0.44      0.43        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.59      0.60      0.59       175\n",
      "weighted avg       0.67      0.66      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On UnderSampled Dataset\n",
      "[0.88421053 0.82010582 0.77248677 0.6984127 ] \n",
      "\n",
      "0.7938039543302702\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[81 44]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.648\n",
      "Precision: 0.8804347826086957\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7465437788018433\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.65      0.75       125\n",
      "         1.0       0.47      0.78      0.59        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.68      0.71      0.67       175\n",
      "weighted avg       0.76      0.69      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On UnderSampled Dataset\n",
      "[0.67368421 0.66137566 0.6031746  0.67724868] \n",
      "\n",
      "0.6538707880813144\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on OverSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on OverSampled dataset :\n",
      "[0.70526316 0.60846561 0.56613757 0.66666667] \n",
      "\n",
      "0.6366332497911444\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On OverSampled PCA Training dataset:\n",
    "print(\"Naive Bayes on OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on OverSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Naive Bayes on OverSampled PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On OverSampled PCA Training dataset:\n",
    "print(\"SVM Classifier on OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on OverSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of SVM Classifier on OverSampled PCA Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On OverSampled PCA Training dataset:\n",
    "print(\"Logistic Regression Classifier on OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on OverSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on OverSampled PCA Training dataset::\")\n",
    "crossValidation(LogisticRegression(), X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On OverSampled PCA Training dataset\n",
    "print(\"KNN Classifier on OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on OverSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of KNN Classifier on OverSampled PCA Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On OverSampled PCA Training dataset:\n",
    "print(\"Random Forest Classifier on OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on OverSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Random Forest Classifier on OverSampled PCA Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for OverSampled PCA Training dataset:\n",
    "print(\"Voting Classifier on OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on OverSampled PCA Training dataset:\n",
    "print(\"\\nCross Validation of Voting Classifier on OverSampled PCA Training dataset:\")\n",
    "crossValidation(vclf, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Oversampled PCA Dataset:\")\n",
    "clfFitPredict(adb_clf_over, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Oversampled PCA Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Oversampled PCA dataset:\")\n",
    "crossValidation(adb_clf_over, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on oversampled PCA Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_over, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Oversampled PCA Training  datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Oversampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_over, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Oversampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier on the Oversampled PCA dataset:\")\n",
    "clfFitPredict(gbc_over, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Oversampled PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Oversampled PCA Training dataset:\")\n",
    "crossValidation(gbc_over, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Oversampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nXGBClassifier on the Oversampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_over, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Oversampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Oversampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_over, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#11 Bagging Classifier On the OverSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on OverSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on OverSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on OverSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_over1, y_over, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#12 Perceptron On The OverSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on OverSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_over1, X_pca_test_over1, y_train_over, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on OverSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on OverSampled dataset :\")\n",
    "crossValidation(clf_percept, X_pca_over1, y_over, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_over.pkl']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on OverSampled Dataset \n",
    "random_svc_over = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "random_svc_over.fit(X_train_over, y_train_over.values.ravel())\n",
    "joblib.dump(random_svc_over, \"RSCV_SVC_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC on OverSampled Dataset :\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.005, 'C': 100}\n",
      "\n",
      "Best Score : 0.6871420222092344\n",
      "\n",
      "Accuracy Score : 0.5828571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC on OverSampled Dataset :\")\n",
    "RSCV_SVC_over_loaded = joblib.load(\"RSCV_SVC_over.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_over_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_over_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_pca_over.pkl']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC with OverSampled PCA Dataset\n",
    "random_svc_pca_over = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "\n",
    "random_svc_pca_over.fit(X_pca_train_over1, y_train_over.values.ravel())\n",
    "joblib.dump(random_svc_pca_over, \"RSCV_SVC_pca_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on SVC with OverSampled PCA Dataset :\n",
      "\n",
      "Best Score - 0.6888661601402688\n",
      "\n",
      "Best Paramters - {'kernel': 'sigmoid', 'gamma': 0.005, 'C': 100}\n",
      "\n",
      "Accuracy Score - 0.5828571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on SVC with OverSampled PCA Dataset :\")\n",
    "RSCV_SVC_pca_over_loaded = joblib.load(\"RSCV_SVC_pca_over.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_SVC_pca_over_loaded.best_score_)\n",
    "print(\"\\nBest Paramters -\", RSCV_SVC_pca_over_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_SVC_pca_over_loaded.predict(X_pca_test_over1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    1.2s\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_over.pkl']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression \n",
    "\n",
    "#https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "random_logreg_over = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,\n",
    "                            scoring='accuracy', \n",
    "                            refit=True,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1,\n",
    "                            n_iter=100,\n",
    "                            random_state=0\n",
    "                           )\n",
    "#X_train_over, X_test, y_train_over, y_test\n",
    "random_logreg_over.fit(X_train_over, y_train_over.values.ravel())\n",
    "joblib.dump(random_logreg_over, \"RSCV_LR_over.pkl\")\n",
    "# print(\"\\nBest Parameters :\",random_logreg.best_params_) \n",
    "# print(\"\\nBest Score :\",random.best_score_)\n",
    "# print(\"\\nAccuracy Score :\",accuracy_score(y_test, random_logreg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR on OverSampled Dataset :\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l1', 'C': 100}\n",
      "\n",
      "Best Score : 0.7471361776738749\n",
      "\n",
      "Accuracy Score : 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR on OverSampled Dataset :\")\n",
    "RSCV_LR_over_loaded = joblib.load(\"RSCV_LR_over.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_over_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_over_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_over.pkl']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for LR with OverSampled PCA Dataset\n",
    "random_logreg_pca_over = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "#X_pca_train_over1, X_pca_test_over1, y_train_over, y_test\n",
    "random_logreg_pca_over.fit(X_pca_train_over1, y_train_over.values.ravel())\n",
    "joblib.dump(random_logreg_pca_over, \"RSCV_LR_pca_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on LR with OverSampled PCA Dataset :\n",
      "\n",
      "Best params - {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score -  0.7042665108123904\n",
      "\n",
      "Accuracy Score - 0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on LR with OverSampled PCA Dataset :\")\n",
    "RSCV_LR_pca_over_loaded = joblib.load(\"RSCV_LR_pca_over.pkl\")\n",
    "print(\"\\nBest params -\", RSCV_LR_pca_over_loaded.best_params_)\n",
    "print(\"\\nBest Score - \", RSCV_LR_pca_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_LR_pca_over_loaded.predict(X_pca_test_over1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_over.pkl']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On OverSampled Dataset\n",
    "#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "#https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6\n",
    "\n",
    "random_rf_over = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False, \n",
    "                               cv=10,\n",
    "                               scoring='accuracy', \n",
    "                               refit=True,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=0\n",
    "                              )\n",
    "#X_train_over, X_test, y_train_over, y_test\n",
    "random_rf_over.fit(X_train_over, y_train_over.values.ravel())\n",
    "joblib.dump(random_rf_over, \"RSCV_RF_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on OverSampled Dataset -\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 26.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7197253068381063\n",
      "\n",
      "Accuracy Score : 0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on OverSampled Dataset -\")\n",
    "RSCV_RF_over_loaded = joblib.load(\"RSCV_RF_over.pkl\")\n",
    "print(\"\\nBest Parameter :\",RSCV_RF_over_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_over_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_over.pkl']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On Oversampled PCA Dataset\n",
    "random_rf_pca_over = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf, \n",
    "                            refit=True,\n",
    "                            verbose=True,\n",
    "                            scoring='accuracy',\n",
    "                            cv=10, \n",
    "                            n_jobs=-1, \n",
    "                            random_state = 0\n",
    "                           )\n",
    "#X_pca_train_over1, X_pca_test_over1, y_train_over, y_test\n",
    "random_rf_pca_over.fit(X_pca_train_over1, y_train_over.values.ravel())\n",
    "joblib.dump(random_rf_pca_over, \"RSCV_RF_pca_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on OverSampled PCA Dataset -\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_features': 'auto', 'max_depth': 1.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.6872004675628287\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on OverSampled PCA Dataset -\")\n",
    "RSCV_RF_pca_over_loaded = joblib.load(\"RSCV_RF_pca_over.pkl\")\n",
    "print(\"\\nBest Parameter :\",RSCV_RF_pca_over_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_over_loaded.predict(X_pca_test_over1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_over.pkl']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On OverSampled Dataset\n",
    "\n",
    "clf_gbc_over = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy',\n",
    "                             refit=True, \n",
    "                             n_jobs=-1,\n",
    "                             verbose=False,\n",
    "                             random_state=0\n",
    "                            )\n",
    "#X_train_over, X_test, y_train_over, y_test\n",
    "clf_gbc_over.fit(X_train_over, y_train_over.values.ravel())\n",
    "joblib.dump(clf_gbc_over,'RSCV_GBC_over.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GradientBoostingClassifier on OverSampled Dataset -\n",
      "\n",
      "Best Score : 0.8556107539450613\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.6971428571428572\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GradientBoostingClassifier on OverSampled Dataset -\")\n",
    "RSCV_GBC_over_loaded = joblib.load(\"RSCV_GBC_over.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_over_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_over_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_GBC_over_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_over.pkl']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On OverSampled PCA Dataset\n",
    "clf_gbc_pca_over = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy',\n",
    "                             refit=True, \n",
    "                             n_jobs=-1,\n",
    "                             verbose=False,\n",
    "                             random_state=0\n",
    "                            )\n",
    "#X_pca_train_over1, X_pca_test_over1, y_train_over, y_test\n",
    "clf_gbc_pca_over.fit(X_pca_train_over1, y_train_over.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_over,'RSCV_GBC_pca_over.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GradientBoostingClassifier on OverSampled PCA Dataset :\n",
      "\n",
      "Best Score : 0.8452074810052601\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 0.6, 'min_samples_leaf': 0.2, 'max_depth': 30.0, 'learning_rate': 0.25}\n",
      "\n",
      "Accuracy Score : 0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GradientBoostingClassifier on OverSampled PCA Dataset :\")\n",
    "RSCV_GBC_pca_over_loaded = joblib.load(\"RSCV_GBC_pca_over.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_pca_over_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_over_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_GBC_pca_over_loaded.predict(X_pca_test_over1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_over.pkl']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for AdaBoost Classifier On OverSampled Dataset\n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_over = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "#X_train_over, X_test, y_train_over, y_test\n",
    "random_adaboost_over.fit(X_train_over, y_train_over.values.ravel())\n",
    "joblib.dump(random_adaboost_over, \"RSCV_ADC_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for AdaBoostClassifier on OverSampled Dataset :\n",
      "\n",
      "Best Score - 0.5379602571595558\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for AdaBoostClassifier on OverSampled Dataset :\")\n",
    "RSCV_ADC_over_loaded = joblib.load(\"RSCV_ADC_over.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_over_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_over_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_over_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_pca_over.pkl']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for AdaBoostClassifier On OverSampled PCA Dataset\n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_pca_over = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "#X_pca_train_over1, X_pca_test_over1, y_train_over, y_test\n",
    "random_adaboost_pca_over.fit(X_pca_train_over1, y_train_over.values.ravel())\n",
    "joblib.dump(random_adaboost_pca_over, \"RSCV_ADC_pca_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC on OverSampled PCA Dataset :\n",
      "\n",
      "Best Score - 0.5827878433664525\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.5657142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC on OverSampled PCA Dataset :\")\n",
    "RSCV_ADC_pca_over_loaded = joblib.load(\"RSCV_ADC_pca_over.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_pca_over_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_pca_over_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_pca_over_loaded.predict(X_pca_test_over1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_over.pkl']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostClassifier with SVC as base estimator On OverSampled Dataset\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_over = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "#X_train_over, X_test, y_train_over, y_test\n",
    "random_adaboost_svc_over.fit(X_train_over, y_train_over.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_over, \"RSCV_ADC_SVC_over.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC as base estimator on OverSampled Dataset :\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5965809468147282\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC as base estimator on OverSampled Dataset :\")\n",
    "RSCV_ADC_SVC_over_loaded = joblib.load(\"RSCV_ADC_SVC_over.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_SVC_over_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_SVC_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_over_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_pca_over.pkl']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for ADC with SVC as base estimator on OverSampled PCA Dataset\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_over = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "#X_pca_train_over1, X_pca_test_over1, y_train_over, y_test\n",
    "random_adaboost_svc_pca_over.fit(X_pca_train_over1, y_train_over.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_over, \"RSCV_ADC_SVC_pca_over.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC as base estimator on OverSampled PCA Dataset :\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.6000292226767971\n",
      "\n",
      "Accuracy Score : 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC as base estimator on OverSampled PCA Dataset :\")\n",
    "RSCV_ADC_SVC_pca_over_loaded = joblib.load(\"RSCV_ADC_SVC_pca_over.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_SVC_pca_over_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_SVC_pca_over_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_pca_over_loaded.predict(X_pca_test_over1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rus\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Original Training Dataset Distribution: \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After Random Under Sampling: \n",
      "\n",
      "1.0    117\n",
      "0.0    117\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "#RandomUnderSampler On the Training Dataset and testing with the unbalanced Testing Dataset\n",
    "rus1 = RandomUnderSampler(random_state=42, sampling_strategy='majority')\n",
    "X_train_rus, y_train_rus = rus1.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution: \\n\")\n",
    "print(y_train['is_patient'].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After Random Under Sampling: \\n\")\n",
    "print(pd.Series(y_train_rus).value_counts())\n",
    "X_train_rus = pd.DataFrame(X_train_rus)\n",
    "y_train_rus = pd.DataFrame(y_train_rus)\n",
    "y_train_rus = y_train_rus.rename(columns={0:\"is_patient\"})\n",
    "X_temp_rus = pd.concat([X_train_rus, y_train_rus], axis=1)\n",
    "\n",
    "#shuffling the training dataset\n",
    "X_temp_rus = X_temp_rus.sample(frac=1, random_state=1)\n",
    "\n",
    "X_train_rus  = X_temp_rus.drop([\"is_patient\"], axis=1)\n",
    "y_train_rus  = X_temp_rus[[\"is_patient\"]]\n",
    "X_rus = pd.concat([X_train_rus, X_test], axis=0)\n",
    "y_rus = pd.concat([y_train_rus, y_test], axis=0)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5486141  0.73464389]\n",
      "0.0    117\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for Random Under Sampled Dataset\n",
    "pca_random_under = PCA(n_components=2)\n",
    "X_pca_random_under = pca_random_under.fit_transform(X_train_rus)\n",
    "print(pca_random_under.explained_variance_ratio_.cumsum())\n",
    "y_temp_rus = y_train_rus\n",
    "y_temp_rus[\"PC1\"] = X_pca_random_under[:,0]\n",
    "y_temp_rus[\"PC2\"] = X_pca_random_under[:,1]\n",
    "sns.scatterplot(data=y_temp_rus, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_rus[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "199         1.0  0.732684  0.298147\n",
      "69          0.0  0.744576 -0.057108\n",
      "233         1.0  0.756407 -0.190036\n",
      "39          0.0 -0.333367  0.250382\n",
      "138         1.0 -0.256523  0.093402\n",
      "     is_patient\n",
      "199         1.0\n",
      "69          0.0\n",
      "233         1.0\n",
      "39          0.0\n",
      "138         1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_rus.head())\n",
    "y_train_rus = y_train_rus.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_rus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fourth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Random Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9411764705882353\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5454545454545454\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.38      0.55       125\n",
      "         1.0       0.38      0.94      0.54        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.66      0.66      0.54       175\n",
      "weighted avg       0.78      0.54      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Random Undersample Training dataset:\n",
      "[0.66019417 0.6372549  0.59803922 0.61764706] \n",
      "\n",
      "0.6282838378069675\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 Naive Bayes On Random Under Sampled Training dataset\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"Naive Bayes on Random Under sampled Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Random Under Sampled Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Random Undersample Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Random Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.88\n",
      "Specificity : 0.82\n",
      "F-Score : 0.66\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.53      0.66       125\n",
      "         1.0       0.41      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.65      0.67      0.60       175\n",
      "weighted avg       0.75      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Random Undersample Training dataset:\n",
      "[0.72815534 0.65686275 0.60784314 0.69607843] \n",
      "\n",
      "0.6722349133828289\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2 SVM Classifier On Random UnderSampled Training dataset\n",
    "print(\"SVM Classifier on Random Undersample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Random Under Training sampled datset\n",
    "print(\"\\nCross Validation of SVM Classifier on Random Undersample Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Random Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.9146341463414634\n",
      "Specificity : 0.86\n",
      "F-Score : 0.7246376811594203\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.60      0.72       125\n",
      "         1.0       0.46      0.86      0.60        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.69      0.73      0.66       175\n",
      "weighted avg       0.79      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Radom Under sample Training dataset:\n",
      "[0.68932039 0.64705882 0.60784314 0.67647059] \n",
      "\n",
      "0.6551732343422807\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3 Logistic Regression Classifier On Random Undersampled Training dataset\n",
    "print(\"Logistic Regression Classifier on Random Undersample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Random Under sampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Radom Under sample Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Random Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[91 34]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.728\n",
      "Precision: 0.7647058823529411\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7459016393442623\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.73      0.75       125\n",
      "         1.0       0.39      0.44      0.42        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.58      0.58      0.58       175\n",
      "weighted avg       0.66      0.65      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Random Undersample Training dataset:\n",
      "[0.60194175 0.56862745 0.60784314 0.64705882] \n",
      "\n",
      "0.6063677898343803\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4 KNN Classifier On Random Under Sample Training dataset\n",
    "print(\"KNN Classifier on Random Undersample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "\n",
    "#Cross Validation on KNN Classifier on Random Under sampled Training datset\n",
    "print(\"\\nCross Validation of KNN Classifier on Random Undersample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Random Undersample training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.88\n",
      "Specificity : 0.82\n",
      "F-Score : 0.66\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.53      0.66       125\n",
      "         1.0       0.41      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.65      0.67      0.60       175\n",
      "weighted avg       0.75      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Random Undersample Training dataset:\n",
      "[0.75728155 0.69607843 0.62745098 0.62745098] \n",
      "\n",
      "0.6770654863887302\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5 Random Forest Classifier On Random Under sample Training dataset\n",
    "print(\"Random Forest Classifier on Random Undersample training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Random under sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Random Undersample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Random Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.872093023255814\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7109004739336493\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.60      0.71       125\n",
      "         1.0       0.44      0.78      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.69      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Random under sampled Training dataset:\n",
      "[0.70873786 0.62745098 0.57843137 0.66666667] \n",
      "\n",
      "0.6453217209213783\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Radnom UnderSampled Training Dataset\n",
    "\n",
    "print(\"Voting Classifier on Random Under sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), \n",
    "        ('svm',LinearSVC()), ('knn', KNeighborsClassifier(n_neighbors = 2))]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Random UnderSampled Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on Random under sampled Training dataset:\")\n",
    "crossValidation(vclf, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Random Undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[63 62]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.504\n",
      "Precision: 0.9\n",
      "Specificity : 0.86\n",
      "F-Score : 0.6461538461538462\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.50      0.65       125\n",
      "         1.0       0.41      0.86      0.55        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.65      0.68      0.60       175\n",
      "weighted avg       0.76      0.61      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Random undersampled dataset:\n",
      "[0.70873786 0.67647059 0.68627451 0.64705882] \n",
      "\n",
      "0.6796354464115743\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Random Undersampled Dataset\n",
    "\n",
    "dt_rus = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_rus = AdaBoostClassifier(base_estimator=dt_rus, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Random Undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_rus, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Random Undersampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Random undersampled dataset:\")\n",
    "crossValidation(adb_clf_rus, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Random undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[83 42]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.664\n",
      "Precision: 0.83\n",
      "Specificity : 0.66\n",
      "F-Score : 0.7377777777777779\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.66      0.74       125\n",
      "         1.0       0.44      0.66      0.53        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.64      0.66      0.63       175\n",
      "weighted avg       0.72      0.66      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Random undersampled dataset:\n",
      "[0.63106796 0.53921569 0.64705882 0.64705882] \n",
      "\n",
      "0.6161003236245954\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_rus = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_rus = AdaBoostClassifier(base_estimator=svc_adb_rus, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Random undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_rus, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Random Undersampled datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Random undersampled dataset:\")\n",
    "crossValidation(adb_clf_svc_rus, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Random undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8607594936708861\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6666666666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.54      0.67       125\n",
      "         1.0       0.41      0.78      0.53        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.63      0.66      0.60       175\n",
      "weighted avg       0.73      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Random undersampled dataset:\n",
      "[0.73786408 0.60784314 0.65686275 0.71568627] \n",
      "\n",
      "0.679564058633162\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Random undersampled Dataset\n",
    "\n",
    "gbc_rus = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the Random undersampled dataset:\")\n",
    "clfFitPredict(gbc_rus, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Random undersampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Random undersampled dataset:\")\n",
    "crossValidation(gbc_rus, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Random undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [19 31]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.8020833333333334\n",
      "Specificity : 0.62\n",
      "F-Score : 0.6968325791855204\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.62      0.70       125\n",
      "         1.0       0.39      0.62      0.48        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.60      0.62      0.59       175\n",
      "weighted avg       0.69      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Random undersampled dataset:\n",
      "[0.59223301 0.58823529 0.58823529 0.59803922] \n",
      "\n",
      "0.5916857034075766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Random undersampled Dataset\n",
    "\n",
    "xgb_clf_rus = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the Random undersampled dataset:\")\n",
    "clfFitPredict(xgb_clf_rus, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Random undersampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Random undersampled dataset:\")\n",
    "crossValidation(xgb_clf_rus, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on RandomUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[81 44]\n",
      " [21 29]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.648\n",
      "Precision: 0.7941176470588235\n",
      "Specificity : 0.58\n",
      "F-Score : 0.7136563876651983\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.65      0.71       125\n",
      "         1.0       0.40      0.58      0.47        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.60      0.61      0.59       175\n",
      "weighted avg       0.68      0.63      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on RandomUnderSampled dataset :\n",
      "[0.74757282 0.65686275 0.71568627 0.64705882] \n",
      "\n",
      "0.6917951646678089\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[81 44]\n",
      " [21 29]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.648\n",
      "Precision: 0.7941176470588235\n",
      "Specificity : 0.58\n",
      "F-Score : 0.7136563876651983\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.65      0.71       125\n",
      "         1.0       0.40      0.58      0.47        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.60      0.61      0.59       175\n",
      "weighted avg       0.68      0.63      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled Dataset\n",
      "[0.74757282 0.65686275 0.71568627 0.64705882] \n",
      "\n",
      "0.6917951646678089\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.9054054054054054\n",
      "Specificity : 0.86\n",
      "F-Score : 0.6733668341708543\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.54      0.67       125\n",
      "         1.0       0.43      0.86      0.57        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.67      0.70      0.62       175\n",
      "weighted avg       0.77      0.63      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On RandomUnderSampled Dataset\n",
      "[0.66019417 0.6372549  0.62745098 0.69607843] \n",
      "\n",
      "0.6552446221206929\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[61 64]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.488\n",
      "Precision: 0.8133333333333334\n",
      "Specificity : 0.72\n",
      "F-Score : 0.61\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.49      0.61       125\n",
      "         1.0       0.36      0.72      0.48        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.59      0.60      0.54       175\n",
      "weighted avg       0.68      0.55      0.57       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On RandomUnderSampled Dataset\n",
      "[0.65048544 0.65686275 0.55882353 0.62745098] \n",
      "\n",
      "0.6234056729487911\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8831168831168831\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6732673267326733\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.42      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On RandomUnderSampled Dataset\n",
      "[0.6407767  0.65686275 0.67647059 0.67647059] \n",
      "\n",
      "0.6626451551494384\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8795180722891566\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7019230769230769\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.58      0.70       125\n",
      "         1.0       0.43      0.80      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.69      0.63       175\n",
      "weighted avg       0.75      0.65      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On RandomUnderSampled Dataset\n",
      "[0.70873786 0.69607843 0.65686275 0.60784314] \n",
      "\n",
      "0.66738054445079\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.8850574712643678\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7264150943396226\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.62      0.73       125\n",
      "         1.0       0.45      0.80      0.58        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.67      0.71      0.65       175\n",
      "weighted avg       0.76      0.67      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On RandomUnderSampled Dataset\n",
      "[0.67961165 0.64705882 0.60784314 0.70588235] \n",
      "\n",
      "0.6600989910527318\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the RandomUnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on RandomUnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on RandomUnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on RandomUnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On RandomUnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_rus, X_test, y_train_rus, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On RandomUnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_rus, y_rus, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on RandomUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[39 86]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.5028571428571429\n",
      "Sensitivity : 0.312\n",
      "Precision: 0.975\n",
      "Specificity : 0.98\n",
      "F-Score : 0.4727272727272727\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.31      0.47       125\n",
      "         1.0       0.36      0.98      0.53        50\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.67      0.65      0.50       175\n",
      "weighted avg       0.80      0.50      0.49       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on RandomUnderSampled dataset :\n",
      "[0.65048544 0.62745098 0.62745098 0.61764706] \n",
      "\n",
      "0.6307586141252618\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The RandomUnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on RandomUnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_rus, X_test, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on RandomUnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on RandomUnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_rus, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5486141  0.73464389 0.84740938 0.92879486 0.96903557 0.98625515\n",
      " 0.99485509 0.99898767 0.99968489 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With Random UnderSampled PCA Training dataset:\n",
    "\n",
    "pca_rus_1 = PCA()\n",
    "X_pca_rus_1 = pca_rus_1.fit_transform(X_train_rus)\n",
    "print(pca_rus_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_rus1 = PCA(n_components=5)\n",
    "X_pca_train_rus1 = pd.DataFrame(pca_rus1.fit_transform(X_train_rus))\n",
    "X_pca_test_rus1 = pd.DataFrame(pca_rus1.transform(X_test))\n",
    "\n",
    "X_pca_rus1 = pd.concat([X_pca_train_rus1, X_pca_test_rus1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Random UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[54 71]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.5257142857142857\n",
      "Sensitivity : 0.432\n",
      "Precision: 0.8181818181818182\n",
      "Specificity : 0.76\n",
      "F-Score : 0.5654450261780104\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.43      0.57       125\n",
      "         1.0       0.35      0.76      0.48        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.58      0.60      0.52       175\n",
      "weighted avg       0.68      0.53      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Random UnderSampled PCA Training dataset:\n",
      "[0.65048544 0.66666667 0.55882353 0.55882353] \n",
      "\n",
      "0.60869979059585\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Random UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[62 63]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.496\n",
      "Precision: 0.8985507246376812\n",
      "Specificity : 0.86\n",
      "F-Score : 0.6391752577319587\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.50      0.64       125\n",
      "         1.0       0.41      0.86      0.55        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.65      0.68      0.60       175\n",
      "weighted avg       0.76      0.60      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Random UnderSampled PCA Training dataset:\n",
      "[0.69902913 0.65686275 0.60784314 0.68627451] \n",
      "\n",
      "0.6625023795926137\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Random UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.9058823529411765\n",
      "Specificity : 0.84\n",
      "F-Score : 0.7333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.62      0.73       125\n",
      "         1.0       0.47      0.84      0.60        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.69      0.73      0.67       175\n",
      "weighted avg       0.78      0.68      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Random UnderSampled PCA Training dataset:\n",
      "[0.68932039 0.64705882 0.60784314 0.68627451] \n",
      "\n",
      "0.6576242147344376\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Random UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[99 26]\n",
      " [31 19]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.792\n",
      "Precision: 0.7615384615384615\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7764705882352941\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.79      0.78       125\n",
      "         1.0       0.42      0.38      0.40        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.59      0.59      0.59       175\n",
      "weighted avg       0.66      0.67      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Random UnderSampled PCA Training dataset:\n",
      "[0.59223301 0.56862745 0.6372549  0.66666667] \n",
      "\n",
      "0.6161955073291452\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Random UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[62 63]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.496\n",
      "Precision: 0.8732394366197183\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6326530612244897\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.50      0.63       125\n",
      "         1.0       0.39      0.82      0.53        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.63      0.66      0.58       175\n",
      "weighted avg       0.74      0.59      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Random UnderSampled PCA Training dataset:\n",
      "[0.66990291 0.57843137 0.61764706 0.67647059] \n",
      "\n",
      "0.6356129830573006\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Random UnderSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.9047619047619048\n",
      "Specificity : 0.84\n",
      "F-Score : 0.7272727272727273\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.61      0.73       125\n",
      "         1.0       0.46      0.84      0.60        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.68      0.72      0.66       175\n",
      "weighted avg       0.78      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Random UnderSampled PCA Training dataset:\n",
      "[0.66019417 0.65686275 0.58823529 0.68627451] \n",
      "\n",
      "0.6478916809442223\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Random Undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[61 64]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.488\n",
      "Precision: 0.9104477611940298\n",
      "Specificity : 0.88\n",
      "F-Score : 0.6354166666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.49      0.64       125\n",
      "         1.0       0.41      0.88      0.56        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.66      0.68      0.60       175\n",
      "weighted avg       0.77      0.60      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Random undersampled PCA Training dataset:\n",
      "[0.59223301 0.62745098 0.62745098 0.65686275] \n",
      "\n",
      "0.6259994288977727\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Random undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[85 40]\n",
      " [20 30]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.68\n",
      "Precision: 0.8095238095238095\n",
      "Specificity : 0.6\n",
      "F-Score : 0.7391304347826089\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.68      0.74       125\n",
      "         1.0       0.43      0.60      0.50        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.62      0.64      0.62       175\n",
      "weighted avg       0.70      0.66      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Random undersampled PCA Training dataset:\n",
      "[0.66019417 0.54901961 0.64705882 0.64705882] \n",
      "\n",
      "0.6258328574148105\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Random undersampled PCA training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8095238095238095\n",
      "Specificity : 0.68\n",
      "F-Score : 0.6507177033492824\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.54      0.65       125\n",
      "         1.0       0.37      0.68      0.48        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.59      0.61      0.57       175\n",
      "weighted avg       0.68      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Random undersampled PCA Training dataset:\n",
      "[0.70873786 0.60784314 0.66666667 0.6372549 ] \n",
      "\n",
      "0.6551256424900057\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Random undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[87 38]\n",
      " [27 23]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.696\n",
      "Precision: 0.7631578947368421\n",
      "Specificity : 0.46\n",
      "F-Score : 0.7280334728033472\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.70      0.73       125\n",
      "         1.0       0.38      0.46      0.41        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.57      0.58      0.57       175\n",
      "weighted avg       0.65      0.63      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Random undersampled PCA Training dataset:\n",
      "[0.59223301 0.58823529 0.58823529 0.59803922] \n",
      "\n",
      "0.5916857034075766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on RandomUnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[81 44]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.648\n",
      "Precision: 0.8526315789473684\n",
      "Specificity : 0.72\n",
      "F-Score : 0.7363636363636363\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.65      0.74       125\n",
      "         1.0       0.45      0.72      0.55        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.65      0.68      0.65       175\n",
      "weighted avg       0.74      0.67      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on RandomUnderSampled PCA dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63106796 0.66666667 0.60784314 0.6372549 ] \n",
      "\n",
      "0.6357081667618504\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[81 44]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.648\n",
      "Precision: 0.8526315789473684\n",
      "Specificity : 0.72\n",
      "F-Score : 0.7363636363636363\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.65      0.74       125\n",
      "         1.0       0.45      0.72      0.55        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.65      0.68      0.65       175\n",
      "weighted avg       0.74      0.67      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.63106796 0.66666667 0.60784314 0.6372549 ] \n",
      "\n",
      "0.6357081667618504\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.9014084507042254\n",
      "Specificity : 0.86\n",
      "F-Score : 0.6530612244897959\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.51      0.65       125\n",
      "         1.0       0.41      0.86      0.56        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.66      0.69      0.61       175\n",
      "weighted avg       0.76      0.61      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.63106796 0.64705882 0.6372549  0.69607843] \n",
      "\n",
      "0.6528650295069485\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[69 56]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.5771428571428572\n",
      "Sensitivity : 0.552\n",
      "Precision: 0.7931034482758621\n",
      "Specificity : 0.64\n",
      "F-Score : 0.6509433962264152\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.55      0.65       125\n",
      "         1.0       0.36      0.64      0.46        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.58      0.60      0.56       175\n",
      "weighted avg       0.67      0.58      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.66019417 0.64705882 0.58823529 0.66666667] \n",
      "\n",
      "0.6405387397677518\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.9142857142857143\n",
      "Specificity : 0.88\n",
      "F-Score : 0.6564102564102564\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.51      0.66       125\n",
      "         1.0       0.42      0.88      0.57        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.67      0.70      0.61       175\n",
      "weighted avg       0.77      0.62      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.60194175 0.62745098 0.64705882 0.6372549 ] \n",
      "\n",
      "0.6284266133637921\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.8701298701298701\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6633663366336634\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.54      0.66       125\n",
      "         1.0       0.41      0.80      0.54        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.64      0.67      0.60       175\n",
      "weighted avg       0.74      0.61      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.63106796 0.61764706 0.60784314 0.64705882] \n",
      "\n",
      "0.625904245193223\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8791208791208791\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7407407407407407\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.64      0.74       125\n",
      "         1.0       0.46      0.78      0.58        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.67      0.71      0.66       175\n",
      "weighted avg       0.76      0.68      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.66990291 0.6372549  0.58823529 0.69607843] \n",
      "\n",
      "0.647867885018085\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on RandomUnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.8260869565217391\n",
      "Specificity : 0.76\n",
      "F-Score : 0.5876288659793814\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.46      0.59       125\n",
      "         1.0       0.36      0.76      0.49        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.59      0.61      0.54       175\n",
      "weighted avg       0.69      0.54      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on RandomUnderSampled PCA dataset :\n",
      "[0.59223301 0.55882353 0.61764706 0.62745098] \n",
      "\n",
      "0.5990386445840472\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Random UnderSampled PCA Training dataset\n",
    "print(\"Naive Bayes on Random UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Random UnderSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Naive Bayes on Random UnderSampled PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On Random UnderSampled PCA Training dataset\n",
    "print(\"SVM Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Random UnderSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of SVM Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On Random UnderSampled PCA Training dataset\n",
    "print(\"Logistic Regression Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Random UnderSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On Random UnderSampled PCA Training dataset\n",
    "print(\"KNN Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Random UnderSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On Random UnderSampled PCA Training dataset\n",
    "print(\"Random Forest Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Random UnderSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Random UnderSampled PCA Training dataset\n",
    "print(\"Voting Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Random UnderSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Voting Classifier on Random UnderSampled PCA Training dataset:\")\n",
    "crossValidation(vclf, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Random Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Random Undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_rus, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Random Undersampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Random undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_rus, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Random undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_rus, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Random Undersampled PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Random undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_rus, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Random undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier on the Random undersampled PCA training dataset:\")\n",
    "clfFitPredict(gbc_rus, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Random undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Random undersampled PCA Training dataset:\")\n",
    "crossValidation(gbc_rus, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Random Undersampled Training PCA Training Dataset\n",
    "\n",
    "print(\"\\nXGBClassifier on the Random undersampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_rus, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Random undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Random undersampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_rus, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#11 Bagging Classifier On the RandomUnderSampled PCA Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on RandomUnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on RandomUnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on RandomUnderSampled PCA dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On RandomUnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On RandomUnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_rus1, y_rus, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#12 Perceptron On The RandomUnderSampled PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on RandomUnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on RandomUnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Perceptron on RandomUnderSampled PCA dataset :\")\n",
    "crossValidation(clf_percept, X_pca_rus1, y_rus, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_rus.pkl']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on RandomUnderSampled Dataset\n",
    "\n",
    "random_svc_rus = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10, n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "#X_train_rus, X_test, y_train_rus, y_test\n",
    "random_svc_rus.fit(X_train_rus, y_train_rus.values.ravel())\n",
    "joblib.dump(random_svc_rus, \"RSCV_SVC_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC on RandomUnderSampled Dataset :\n",
      "\n",
      "Best Params - {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score - 0.7217391304347827\n",
      "\n",
      "Accuracy Score - 0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC on RandomUnderSampled Dataset :\")\n",
    "RSCV_SVC_rus_loaded = joblib.load(\"RSCV_SVC_rus.pkl\")\n",
    "print(\"\\nBest Params -\", RSCV_SVC_rus_loaded.best_params_)\n",
    "print(\"\\nBest Score -\", RSCV_SVC_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_SVC_rus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_pca_rus.pkl']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test\n",
    "random_svc_pca_rus = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_pca_rus.fit(X_pca_train_rus1, y_train_rus.values.ravel())\n",
    "joblib.dump(random_svc_pca_rus, \"RSCV_SVC_pca_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC on RandomUnderSampled PCA Dataset :\n",
      "\n",
      "Best Params - {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score - 0.6922101449275363\n",
      "\n",
      "Accuracy Score - 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC on RandomUnderSampled PCA Dataset :\")\n",
    "RSCV_SVC_pca_rus_loaded = joblib.load(\"RSCV_SVC_pca_rus.pkl\")\n",
    "print(\"\\nBest Params -\", RSCV_SVC_pca_rus_loaded.best_params_)\n",
    "print(\"\\nBest Score -\", RSCV_SVC_pca_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_SVC_pca_rus_loaded.predict(X_pca_test_rus1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    4.6s finished\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_rus.pkl']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression With RandomUnderSampled Dataset\n",
    "\n",
    "random_logreg_rus = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "#X_train_rus, X_test, y_train_rus, y_test\n",
    "random_logreg_rus.fit(X_train_rus, y_train_rus.values.ravel())\n",
    "joblib.dump(random_logreg_rus, \"RSCV_LR_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR on RandomUnderSampled Dataset :\n",
      "\n",
      "Best Parameters : {'solver': 'lbfgs', 'penalty': 'l2', 'C': 1000}\n",
      "\n",
      "Best Score : 0.7469202898550724\n",
      "\n",
      "Accuracy Score : 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR on RandomUnderSampled Dataset :\")\n",
    "RSCV_LR_rus_loaded = joblib.load(\"RSCV_LR_rus.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_rus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\",RSCV_LR_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_rus_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_rus.pkl']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression With RandomUnderSampled PCA Dataset\n",
    "random_logreg_pca_rus = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "#X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test\n",
    "random_logreg_pca_rus.fit(X_pca_train_rus1, y_train_rus.values.ravel())\n",
    "joblib.dump(random_logreg_pca_rus, \"RSCV_LR_pca_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR on RandomUnderSampled PCA Dataset :\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.7088768115942029\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR on RandomUnderSampled PCA Dataset :\")\n",
    "RSCV_LR_pca_rus_loaded = joblib.load(\"RSCV_LR_pca_rus.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_rus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_rus_loaded.predict(X_pca_test_rus1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_rus.pkl']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest on RandomUnderSampled Dataset\n",
    "\n",
    "random_rf_rus = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "#X_train_rus, X_test, y_train_rus, y_test\n",
    "random_rf_rus.fit(X_train_rus, y_train_rus.values.ravel())\n",
    "joblib.dump(random_rf_rus, \"RSCV_RF_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on RUS Dataset :\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7047101449275363\n",
      "\n",
      "Accuracy Score : 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on RUS Dataset :\")\n",
    "RSCV_RF_rus_loaded = joblib.load(\"RSCV_RF_rus.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_rus_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_rus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_rus.pkl']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest on RandomUnderSampled PCA Dataset\n",
    "random_rf_pca_rus = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "#X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test\n",
    "random_rf_pca_rus.fit(X_pca_train_rus1, y_train_rus.values.ravel())\n",
    "joblib.dump(random_rf_pca_rus, \"RSCV_RF_pca_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on RUS PCA Dataset :\n",
      "\n",
      "Best Parameter : {'n_estimators': 32, 'min_samples_split': 1.0, 'min_samples_leaf': 0.4, 'max_features': 'sqrt', 'max_depth': 14.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.6672101449275363\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on RUS PCA Dataset :\")\n",
    "RSCV_RF_pca_rus_loaded = joblib.load(\"RSCV_RF_pca_rus.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_rus_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_rus_loaded.predict(X_pca_test_rus1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_rus.pkl']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier on RUS Dataset\n",
    "\n",
    "clf_gbc_rus = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "#X_train_rus, X_test, y_train_rus, y_test\n",
    "clf_gbc_rus.fit(X_train_rus, y_train_rus.values.ravel())\n",
    "joblib.dump(clf_gbc_rus,'RSCV_GBC_rus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on GBC with RUS Dataset\n",
      "\n",
      "Best Score : 0.7253623188405797\n",
      "\n",
      "Best Parameters : {'n_estimators': 32, 'min_samples_split': 0.5, 'min_samples_leaf': 0.2, 'max_depth': 27.0, 'learning_rate': 0.1}\n",
      "\n",
      "Accuracy Score : 0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on GBC with RUS Dataset\")\n",
    "RSCV_GBC_rus_loaded = joblib.load(\"RSCV_GBC_rus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_rus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\",RSCV_GBC_rus_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_rus_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_rus_pca.pkl']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier on RUS PCA Dataset\n",
    "\n",
    "clf_gbc_rus_pca = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "#X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test\n",
    "clf_gbc_rus_pca.fit(X_pca_train_rus1, y_train_rus.values.ravel())\n",
    "joblib.dump(clf_gbc_rus_pca,'RSCV_GBC_rus_pca.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV on GBC with RUS PCA Dataset\n",
      "\n",
      "Best Score : 0.6873188405797102\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 1.0, 'min_samples_leaf': 0.1, 'max_depth': 22.0, 'learning_rate': 0.005}\n",
      "\n",
      "Accuracy Score : 0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV on GBC with RUS PCA Dataset\")\n",
    "RSCV_GBC_rus_pca_loaded = joblib.load(\"RSCV_GBC_rus_pca.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_rus_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\",RSCV_GBC_rus_pca_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_rus_pca_loaded.predict(X_pca_test_rus1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_rus.pkl']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier \n",
    "                \n",
    "#dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(random_state=0) #base_estimator=dTC, \n",
    "\n",
    "random_adaboost_rus = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "#X_train_rus, X_test, y_train_rus, y_test\n",
    "random_adaboost_rus.fit(X_train_rus, y_train_rus.values.ravel())\n",
    "joblib.dump(random_adaboost_rus, \"RSCV_ADC_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC for RUS Dataset :\n",
      "\n",
      "Best Score - 0.6960144927536231\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC for RUS Dataset :\")\n",
    "RSCV_ADC_rus_loaded = joblib.load(\"RSCV_ADC_rus.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_rus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_rus_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_rus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_pca_rus.pkl']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA Original Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_pca_rus = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "#X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test\n",
    "random_adaboost_pca_rus.fit(X_pca_train_rus1, y_train_rus.values.ravel())\n",
    "joblib.dump(random_adaboost_pca_rus, \"RSCV_ADC_pca_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC for RUS PCA Dataset :\n",
      "\n",
      "Best Score - 0.5702898550724639\n",
      "\n",
      "Best Parameters - {'n_estimators': 64, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.5657142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC for RUS PCA Dataset :\")\n",
    "RSCV_ADC_pca_rus_loaded = joblib.load(\"RSCV_ADC_pca_rus.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_pca_rus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_pca_rus_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_pca_rus_loaded.predict(X_pca_test_rus1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_rus.pkl']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_rus = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "\n",
    "random_adaboost_svc_rus.fit(X_train_rus, y_train_rus.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_rus, \"RSCV_ADC_SVC_rus.pkl\")\n",
    "#X_train_rus, X_test, y_train_rus, y_test\n",
    "#X_pca_train_rus1, X_pca_test_rus1, y_train_rus, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on RUS\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5327898550724639\n",
      "\n",
      "Accuracy Score : 0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on RUS\")\n",
    "RSCV_ADC_SVC_rus_loaded = joblib.load(\"RSCV_ADC_SVC_rus.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_ADC_SVC_rus_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_SVC_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_rus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_SVC_pca_rus.pkl']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_rus = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "\n",
    "random_adaboost_svc_pca_rus.fit(X_pca_train_rus1, y_train_rus.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_rus, \"RSCV_ADC_SVC_pca_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on RUS Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5369565217391304\n",
      "\n",
      "Accuracy Score : 0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on RUS Dataset\")\n",
    "RSCV_ADC_SVC_pca_rus_loaded = joblib.load(\"RSCV_ADC_SVC_pca_rus.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_ADC_SVC_pca_rus_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_SVC_pca_rus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_SVC_pca_rus_loaded.predict(X_pca_test_rus1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ros\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Original Training Dataset Distribution: \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After Random Over Sampling: \n",
      "\n",
      "0.0    291\n",
      "1.0    291\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#RandomOverSampler On the Training Dataset\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution: \\n\")\n",
    "print(y_train['is_patient'].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After Random Over Sampling: \\n\")\n",
    "print(pd.Series(y_train_ros).value_counts())\n",
    "X_train_ros = pd.DataFrame(X_train_ros)\n",
    "y_train_ros = pd.DataFrame(y_train_ros)\n",
    "y_train_ros = y_train_ros.rename(columns={0:\"is_patient\"})\n",
    "X_temp_ros = pd.concat([X_train_ros, y_train_ros], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_ros = X_temp_ros.sample(frac=1, random_state=1)\n",
    "X_train_ros  = X_temp_ros.drop([\"is_patient\"], axis=1)\n",
    "y_train_ros  = X_temp_ros[[\"is_patient\"]]\n",
    "X_ros = pd.concat([X_train_ros, X_test], axis=0)\n",
    "y_ros = pd.concat([y_train_ros, y_test], axis=0)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56256164 0.73330707]\n",
      "0.0    291\n",
      "1.0    291\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for Random Over Sampled Dataset\n",
    "pca_random_over = PCA(n_components=2)\n",
    "X_pca_random_over = pca_random_over.fit_transform(X_train_ros)\n",
    "print(pca_random_over.explained_variance_ratio_.cumsum())\n",
    "y_temp_ros = y_train_ros\n",
    "y_temp_ros[\"PC1\"] = X_pca_random_over[:,0]\n",
    "y_temp_ros[\"PC2\"] = X_pca_random_over[:,1]\n",
    "sns.scatterplot(data=y_temp_ros, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_ros[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "457         1.0 -0.274678  0.024499\n",
      "225         1.0  0.718415  0.144603\n",
      "162         0.0 -0.296888  0.640445\n",
      "195         0.0 -0.287466  0.067029\n",
      "267         0.0 -0.278075  0.085863\n",
      "     is_patient\n",
      "457         1.0\n",
      "225         1.0\n",
      "162         0.0\n",
      "195         0.0\n",
      "267         0.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_ros.head())\n",
    "y_train_ros = y_train_ros.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_ros.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fifth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Random Over sampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[47 78]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.376\n",
      "Precision: 0.94\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5371428571428571\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.38      0.54       125\n",
      "         1.0       0.38      0.94      0.54        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.66      0.66      0.54       175\n",
      "weighted avg       0.78      0.54      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Random Over sampled dataset:\n",
      "[0.66842105 0.64550265 0.65608466 0.64021164] \n",
      "\n",
      "0.6525549986076302\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Random Over sampled Training dataset\n",
    "print(\"Naive Bayes on Random Over sampled dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Random Over sampled datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Random Over sampled dataset:\")\n",
    "crossValidation(GaussianNB(), X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Random Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.868421052631579\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6567164179104478\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.53      0.66       125\n",
      "         1.0       0.40      0.80      0.54        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.64      0.66      0.60       175\n",
      "weighted avg       0.74      0.61      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Random Oversampled Training dataset:\n",
      "[0.7        0.6984127  0.67195767 0.71428571] \n",
      "\n",
      "0.6961640211640212\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2 SVM Classifier On Random OverSampled Training dataset\n",
    "print(\"SVM Classifier on Random Oversample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Random Oversampled datset\n",
    "print(\"\\nCross Validation of SVM Classifier on Random Oversampled Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Random Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.872093023255814\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7109004739336493\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.60      0.71       125\n",
      "         1.0       0.44      0.78      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.69      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Random Oversampled Training dataset:\n",
      "[0.67368421 0.68783069 0.61904762 0.70899471] \n",
      "\n",
      "0.6723893065998329\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3 Logistic Regression Classifier On Random Over Sampled Training  dataset\n",
    "print(\"Logistic Regression Classifier on Random Oversample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Random Over Sampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Random Oversampled Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Random Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[97 28]\n",
      " [33 17]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.776\n",
      "Precision: 0.7461538461538462\n",
      "Specificity : 0.34\n",
      "F-Score : 0.7607843137254902\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.76       125\n",
      "         1.0       0.38      0.34      0.36        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.56      0.56      0.56       175\n",
      "weighted avg       0.64      0.65      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Random Oversample Training dataset:\n",
      "[0.72631579 0.75661376 0.75661376 0.67724868] \n",
      "\n",
      "0.7291979949874687\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4 KNN Classifier On Randm Oversampled Training dataset\n",
    "print(\"KNN Classifier on Random Oversample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Random Over sampled Training datset\n",
    "print(\"\\nCross Validation of KNN Classifier on Random Oversample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Random Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8705882352941177\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7047619047619046\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.59      0.70       125\n",
      "         1.0       0.43      0.78      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.65      0.69      0.63       175\n",
      "weighted avg       0.75      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Random Oversample Training dataset:\n",
      "[0.74736842 0.75132275 0.74074074 0.6984127 ] \n",
      "\n",
      "0.7344611528822056\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5 Random Forest Classifier On Random Over Sampled Training dataset\n",
    "print(\"Random Forest Classifier on Random Oversample Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Radnom Over Sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Random Oversample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Random Over sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[70 55]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.56\n",
      "Precision: 0.8641975308641975\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6796116504854369\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.56      0.68       125\n",
      "         1.0       0.41      0.78      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.64      0.67      0.61       175\n",
      "weighted avg       0.74      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Random Over sampled Training dataset:\n",
      "[0.70526316 0.71428571 0.67195767 0.71957672] \n",
      "\n",
      "0.7027708159287107\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Random OverSampled Training Dataset\n",
    "print(\"Voting Classifier on Random Over sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Random OverSampled Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on Random Over sampled Training dataset:\")\n",
    "crossValidation(vclf, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Random Oversampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[69 56]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.552\n",
      "Precision: 0.8625\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6731707317073171\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.55      0.67       125\n",
      "         1.0       0.41      0.78      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.64      0.67      0.61       175\n",
      "weighted avg       0.73      0.62      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Random Oversampled dataset:\n",
      "[0.66315789 0.68783069 0.67195767 0.68253968] \n",
      "\n",
      "0.6763714842662212\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Random Oversampled Dataset\n",
    "\n",
    "dt_ros = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_ros = AdaBoostClassifier(base_estimator=dt_ros, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Random Oversampled Dataset:\")\n",
    "clfFitPredict(adb_clf_ros, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Random Oversampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Random Oversampled dataset:\")\n",
    "crossValidation(adb_clf_ros, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Random Oversampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.8933333333333333\n",
      "Specificity : 0.84\n",
      "F-Score : 0.67\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.54      0.67       125\n",
      "         1.0       0.42      0.84      0.56        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.66      0.69      0.61       175\n",
      "weighted avg       0.76      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Random Oversampled dataset:\n",
      "[0.63157895 0.65608466 0.6031746  0.65608466] \n",
      "\n",
      "0.6367307156780841\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_ros = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_ros = AdaBoostClassifier(base_estimator=svc_adb_ros, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Random Oversampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_ros, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Random Oversampled datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Random Oversampled dataset:\")\n",
    "crossValidation(adb_clf_svc_ros, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Random Oversampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8421052631578947\n",
      "Specificity : 0.7\n",
      "F-Score : 0.7272727272727272\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.64      0.73       125\n",
      "         1.0       0.44      0.70      0.54        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.64      0.67      0.63       175\n",
      "weighted avg       0.73      0.66      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Random Oversampled dataset:\n",
      "[0.7        0.74603175 0.7037037  0.71428571] \n",
      "\n",
      "0.716005291005291\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Random Oversampled Dataset\n",
    "\n",
    "gbc_ros = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the Random Oversampled dataset:\")\n",
    "clfFitPredict(gbc_ros, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Random Oversampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Random Oversampled dataset:\")\n",
    "crossValidation(gbc_ros, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier on the Random Oversampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[72 53]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.576\n",
      "Precision: 0.8571428571428571\n",
      "Specificity : 0.76\n",
      "F-Score : 0.6889952153110047\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.58      0.69       125\n",
      "         1.0       0.42      0.76      0.54        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.64      0.67      0.61       175\n",
      "weighted avg       0.73      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Random Oversampled dataset:\n",
      "[0.54736842 0.55026455 0.55026455 0.55026455] \n",
      "\n",
      "0.5495405179615706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10 XGBClassifier on the Random Oversampled Dataset\n",
    "\n",
    "xgb_clf_ros = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the Random Oversampled dataset:\")\n",
    "clfFitPredict(xgb_clf_ros, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Random Oversampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Random Oversampled dataset:\")\n",
    "crossValidation(xgb_clf_ros, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on RandomUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[108  17]\n",
      " [ 32  18]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.864\n",
      "Precision: 0.7714285714285715\n",
      "Specificity : 0.36\n",
      "F-Score : 0.8150943396226416\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.86      0.82       125\n",
      "         1.0       0.51      0.36      0.42        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.64      0.61      0.62       175\n",
      "weighted avg       0.70      0.72      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on RandomUnderSampled dataset :\n",
      "[0.8        0.84656085 0.83068783 0.70899471] \n",
      "\n",
      "0.7965608465608465\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[108  17]\n",
      " [ 32  18]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.864\n",
      "Precision: 0.7714285714285715\n",
      "Specificity : 0.36\n",
      "F-Score : 0.8150943396226416\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.86      0.82       125\n",
      "         1.0       0.51      0.36      0.42        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.64      0.61      0.62       175\n",
      "weighted avg       0.70      0.72      0.70       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled Dataset\n",
      "[0.8        0.84656085 0.83068783 0.70899471] \n",
      "\n",
      "0.7965608465608465\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[97 28]\n",
      " [23 27]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.776\n",
      "Precision: 0.8083333333333333\n",
      "Specificity : 0.54\n",
      "F-Score : 0.7918367346938776\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.79       125\n",
      "         1.0       0.49      0.54      0.51        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.65      0.66      0.65       175\n",
      "weighted avg       0.72      0.71      0.71       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On RandomUnderSampled Dataset\n",
      "[0.60526316 0.61375661 0.61375661 0.68253968] \n",
      "\n",
      "0.6288290169869117\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[72 53]\n",
      " [23 27]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.576\n",
      "Precision: 0.7578947368421053\n",
      "Specificity : 0.54\n",
      "F-Score : 0.6545454545454545\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.58      0.65       125\n",
      "         1.0       0.34      0.54      0.42        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.55      0.56      0.53       175\n",
      "weighted avg       0.64      0.57      0.59       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On RandomUnderSampled Dataset\n",
      "[0.65263158 0.70899471 0.65079365 0.63492063] \n",
      "\n",
      "0.6618351434140908\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.868421052631579\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6567164179104478\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.53      0.66       125\n",
      "         1.0       0.40      0.80      0.54        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.64      0.66      0.60       175\n",
      "weighted avg       0.74      0.61      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On RandomUnderSampled Dataset\n",
      "[0.64210526 0.7037037  0.68783069 0.72486772] \n",
      "\n",
      "0.6896268448900027\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[88 37]\n",
      " [25 25]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.704\n",
      "Precision: 0.7787610619469026\n",
      "Specificity : 0.5\n",
      "F-Score : 0.7394957983193277\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.70      0.74       125\n",
      "         1.0       0.40      0.50      0.45        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.59      0.60      0.59       175\n",
      "weighted avg       0.67      0.65      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On RandomUnderSampled Dataset\n",
      "[0.82105263 0.8042328  0.80952381 0.70899471] \n",
      "\n",
      "0.7859509885825675\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On RandomUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8902439024390244\n",
      "Specificity : 0.82\n",
      "F-Score : 0.7053140096618358\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.58      0.71       125\n",
      "         1.0       0.44      0.82      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.67      0.70      0.64       175\n",
      "weighted avg       0.76      0.65      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On RandomUnderSampled Dataset\n",
      "[0.67368421 0.68253968 0.62433862 0.7037037 ] \n",
      "\n",
      "0.6710665552770816\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the RandomUnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on RandomUnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on RandomUnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on RandomUnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On RandomUnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_ros, X_test, y_train_ros, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On RandomUnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_ros, y_ros, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on RandomUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[30 95]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.4514285714285714\n",
      "Sensitivity : 0.24\n",
      "Precision: 0.967741935483871\n",
      "Specificity : 0.98\n",
      "F-Score : 0.38461538461538464\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.24      0.38       125\n",
      "         1.0       0.34      0.98      0.51        50\n",
      "\n",
      "    accuracy                           0.45       175\n",
      "   macro avg       0.65      0.61      0.44       175\n",
      "weighted avg       0.79      0.45      0.42       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on RandomUnderSampled dataset :\n",
      "[0.65789474 0.58730159 0.65608466 0.63492063] \n",
      "\n",
      "0.6340504037872459\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The RandomUnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on RandomUnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_ros, X_test, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on RandomUnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on RandomUnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_ros, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56256164 0.73330707 0.82833474 0.91223202 0.94980686 0.974728\n",
      " 0.99522245 0.99801175 0.99936417 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With Random OverSampled PCA Training dataset:\n",
    "\n",
    "pca_ros_1 = PCA()\n",
    "X_pca_ros_1 = pca_ros_1.fit_transform(X_train_ros)\n",
    "print(pca_ros_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_ros1 = PCA(n_components=5)\n",
    "X_pca_train_ros1 = pd.DataFrame(pca_ros1.fit_transform(X_train_ros))\n",
    "X_pca_test_ros1 = pd.DataFrame(pca_ros1.transform(X_test))\n",
    "\n",
    "X_pca_ros1 = pd.concat([X_pca_train_ros1, X_pca_test_ros1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Random OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.5485714285714286\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.8108108108108109\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6030150753768844\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.48      0.60       125\n",
      "         1.0       0.36      0.72      0.48        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.58      0.60      0.54       175\n",
      "weighted avg       0.68      0.55      0.57       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Random OverSampled PCA Training dataset:\n",
      "[0.61052632 0.61904762 0.65079365 0.6031746 ] \n",
      "\n",
      "0.6208855472013367\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Random OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8831168831168831\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6732673267326733\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.42      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Random OverSampled PCA Training dataset:\n",
      "[0.65263158 0.64550265 0.65079365 0.7037037 ] \n",
      "\n",
      "0.6631578947368421\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Random OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.8823529411764706\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7142857142857143\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.60      0.71       125\n",
      "         1.0       0.44      0.80      0.57        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.66      0.70      0.64       175\n",
      "weighted avg       0.76      0.66      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Random OverSampled PCA Training dataset:\n",
      "[0.61578947 0.63492063 0.57671958 0.7037037 ] \n",
      "\n",
      "0.6327833472570314\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Random OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 34  16]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7518248175182481\n",
      "Specificity : 0.32\n",
      "F-Score : 0.7862595419847328\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.82      0.79       125\n",
      "         1.0       0.42      0.32      0.36        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.59      0.57      0.57       175\n",
      "weighted avg       0.66      0.68      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Random OverSampled PCA Training dataset:\n",
      "[0.71578947 0.77777778 0.77248677 0.6984127 ] \n",
      "\n",
      "0.7411166805903648\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Random OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[83 42]\n",
      " [20 30]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.664\n",
      "Precision: 0.8058252427184466\n",
      "Specificity : 0.6\n",
      "F-Score : 0.7280701754385964\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.66      0.73       125\n",
      "         1.0       0.42      0.60      0.49        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.61      0.63      0.61       175\n",
      "weighted avg       0.69      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Random OverSampled PCA Training dataset:\n",
      "[0.71052632 0.69312169 0.71428571 0.7037037 ] \n",
      "\n",
      "0.7054093567251463\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Random OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8690476190476191\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6985645933014353\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.58      0.70       125\n",
      "         1.0       0.43      0.78      0.55        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.65      0.68      0.63       175\n",
      "weighted avg       0.74      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Random OverSampled PCA Training dataset:\n",
      "[0.67368421 0.65608466 0.64550265 0.70899471] \n",
      "\n",
      "0.6710665552770816\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Random Oversampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[78 47]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.624\n",
      "Precision: 0.8478260869565217\n",
      "Specificity : 0.72\n",
      "F-Score : 0.7188940092165899\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.62      0.72       125\n",
      "         1.0       0.43      0.72      0.54        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.64      0.67      0.63       175\n",
      "weighted avg       0.73      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Random Oversampled PCA Training dataset:\n",
      "[0.63157895 0.69312169 0.66137566 0.67724868] \n",
      "\n",
      "0.6658312447786132\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Random Oversampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8795180722891566\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7019230769230769\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.58      0.70       125\n",
      "         1.0       0.43      0.80      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.69      0.63       175\n",
      "weighted avg       0.75      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Random Oversampled PCA Training dataset:\n",
      "[0.61578947 0.64021164 0.5978836  0.66137566] \n",
      "\n",
      "0.6288150932887775\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Random Oversampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[86 39]\n",
      " [24 26]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.688\n",
      "Precision: 0.7818181818181819\n",
      "Specificity : 0.52\n",
      "F-Score : 0.7319148936170212\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.69      0.73       125\n",
      "         1.0       0.40      0.52      0.45        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.59      0.60      0.59       175\n",
      "weighted avg       0.67      0.64      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Random Oversampled PCA Training dataset:\n",
      "[0.69473684 0.74603175 0.68253968 0.7037037 ] \n",
      "\n",
      "0.7067529935950988\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Random Oversampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[94 31]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.752\n",
      "Precision: 0.7704918032786885\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7611336032388664\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.75      0.76       125\n",
      "         1.0       0.42      0.44      0.43        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.59      0.60      0.59       175\n",
      "weighted avg       0.67      0.66      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Random Oversampled PCA Training dataset:\n",
      "[0.54736842 0.55026455 0.55026455 0.55026455] \n",
      "\n",
      "0.5495405179615706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on RandomUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[98 27]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.784\n",
      "Precision: 0.7777777777777778\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7808764940239045\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.78      0.78       125\n",
      "         1.0       0.45      0.44      0.44        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.61      0.61      0.61       175\n",
      "weighted avg       0.68      0.69      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on RandomUnderSampled PCA dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83157895 0.82010582 0.82539683 0.73015873] \n",
      "\n",
      "0.8018100807574492\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[98 27]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.784\n",
      "Precision: 0.7777777777777778\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7808764940239045\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.78      0.78       125\n",
      "         1.0       0.45      0.44      0.44        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.61      0.61      0.61       175\n",
      "weighted avg       0.68      0.69      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.83157895 0.82010582 0.82539683 0.73015873] \n",
      "\n",
      "0.8018100807574492\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8695652173913043\n",
      "Specificity : 0.76\n",
      "F-Score : 0.7373271889400922\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.64      0.74       125\n",
      "         1.0       0.46      0.76      0.57        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.66      0.70      0.65       175\n",
      "weighted avg       0.75      0.67      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.66842105 0.65608466 0.63492063 0.66666667] \n",
      "\n",
      "0.6565232525758841\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [23 27]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.7766990291262136\n",
      "Specificity : 0.54\n",
      "F-Score : 0.7017543859649122\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.64      0.70       125\n",
      "         1.0       0.38      0.54      0.44        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.58      0.59      0.57       175\n",
      "weighted avg       0.66      0.61      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.60526316 0.73015873 0.67724868 0.68783069] \n",
      "\n",
      "0.675125313283208\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.8481012658227848\n",
      "Specificity : 0.76\n",
      "F-Score : 0.6568627450980392\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.54      0.66       125\n",
      "         1.0       0.40      0.76      0.52        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.62      0.65      0.59       175\n",
      "weighted avg       0.72      0.60      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.61052632 0.65608466 0.65608466 0.71428571] \n",
      "\n",
      "0.659245335561125\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[95 30]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.76\n",
      "Precision: 0.7723577235772358\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7661290322580646\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.76      0.77       125\n",
      "         1.0       0.42      0.44      0.43        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.60      0.60      0.60       175\n",
      "weighted avg       0.67      0.67      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.81052632 0.80952381 0.77777778 0.70899471] \n",
      "\n",
      "0.7767056530214425\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On RandomUnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8809523809523809\n",
      "Specificity : 0.8\n",
      "F-Score : 0.708133971291866\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.59      0.71       125\n",
      "         1.0       0.44      0.80      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.70      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On RandomUnderSampled PCA Dataset\n",
      "[0.62631579 0.62433862 0.58201058 0.69312169] \n",
      "\n",
      "0.6314466722361458\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on RandomUnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.5257142857142857\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.7916666666666666\n",
      "Specificity : 0.7\n",
      "F-Score : 0.5786802030456852\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.46      0.58       125\n",
      "         1.0       0.34      0.70      0.46        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.57      0.58      0.52       175\n",
      "weighted avg       0.66      0.53      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on RandomUnderSampled PCA dataset :\n",
      "[0.53157895 0.55026455 0.61904762 0.56084656] \n",
      "\n",
      "0.5654344193817878\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Random OverSampled PCA Training dataset\n",
    "print(\"Naive Bayes on Random OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Random OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Naive Bayes on Random OverSampled PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On Random OverSampled PCA Training dataset\n",
    "print(\"SVM Classifier on Random OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Random OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of SVM Classifier on Random OverSampled PCA Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On Random OverSampled PCA Training dataset\n",
    "print(\"Logistic Regression Classifier on Random OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Random OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Random OverSampled PCA Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On Random OverSampled PCA Training dataset\n",
    "print(\"KNN Classifier on Random OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Random OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on Random OverSampled PCA Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On Random OverSampled PCA Training dataset\n",
    "print(\"Random Forest Classifier on Random OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Random OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Random OverSampled PCA Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Random OverSampled PCA Training dataset\n",
    "print(\"Voting Classifier on Random OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Random OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Voting Classifier on Random OverSampled PCA Training dataset:\")\n",
    "crossValidation(vclf, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Random Oversampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Random Oversampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_ros, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Random Oversampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Random Oversampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_ros, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Random Oversampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_ros, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Random Oversampled PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Random Oversampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_ros, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Random Oversampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier on the Random Oversampled PCA Training dataset:\")\n",
    "clfFitPredict(gbc_ros, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Random Oversampled PCA Training dataset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Random Oversampled PCA Training dataset:\")\n",
    "crossValidation(gbc_ros, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Random Oversampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nXGBClassifier on the Random Oversampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_ros, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Random Oversampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Random Oversampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_ros, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Bagging Classifier On the RandomUnderSampled PCA Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on RandomUnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on RandomUnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on RandomUnderSampled PCA dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On RandomUnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On RandomUnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_ros1, y_ros, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The RandomUnderSampled PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on RandomUnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on RandomUnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Perceptron on RandomUnderSampled PCA dataset :\")\n",
    "crossValidation(clf_percept, X_pca_ros1, y_ros, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_ros.pkl']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC\n",
    "random_svc_ros = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_ros.fit(X_train_ros, y_train_ros.values.ravel())\n",
    "joblib.dump(random_svc_ros, \"RSCV_SVC_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with RandomOverSampled Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score : 0.6854763296317942\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with RandomOverSampled Dataset\")\n",
    "RSCV_SVC_ros_loaded  = joblib.load(\"RSCV_SVC_ros.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_ros_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_ros_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_ros_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_pca_ros.pkl']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_svc_pca_ros = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_pca_ros.fit(X_pca_train_ros1, y_train_ros.values.ravel())\n",
    "joblib.dump(random_svc_pca_ros, \"RSCV_SVC_pca_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.005, 'C': 100}\n",
      "\n",
      "Best Score : 0.6855639976621859\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\")\n",
    "RSCV_SVC_pca_ros_loaded = joblib.load(\"RSCV_SVC_pca_ros.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_pca_ros_loaded.best_params_) \n",
    "print(\"\\nBest Score :\",RSCV_SVC_pca_ros_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_pca_ros_loaded.predict(X_pca_test_ros1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_ros.pkl']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression with ROS Dataset\n",
    "\n",
    "random_logreg_ros = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_ros.fit(X_train_ros, y_train_ros.values.ravel())\n",
    "joblib.dump(random_logreg_ros, \"RSCV_LR_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 1500}\n",
      "\n",
      "Best Score : 0.7440677966101694\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\")\n",
    "RSCV_LR_ros_loaded  = joblib.load(\"RSCV_LR_ros.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_ros_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_ros_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_ros_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_ros.pkl']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for LR on ROS PCA Dataset\n",
    "random_logreg_pca_ros = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_ros.fit(X_pca_train_ros1, y_train_ros.values.ravel())\n",
    "joblib.dump(random_logreg_pca_ros, \"RSCV_LR_pca_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.6872881355932203\n",
      "\n",
      "Accuracy Score : 0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\")\n",
    "RSCV_LR_pca_ros_loaded  = joblib.load(\"RSCV_LR_pca_ros.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_ros_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_ros_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_ros_loaded.predict(X_pca_test_ros1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_ros.pkl']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest \n",
    "\n",
    "random_rf_ros = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_ros.fit(X_train_ros, y_train_ros.values.ravel())\n",
    "joblib.dump(random_rf_ros, \"RSCV_RF_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7166569257744009\n",
      "\n",
      "Accuracy Score : 0.6514285714285715\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with RandomOverSampled PCA Dataset\")\n",
    "RSCV_RF_ros_loaded  = joblib.load(\"RSCV_RF_ros.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_ros_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_ros_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_ros_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_ros_pca.pkl']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RF on ROS PCA Dataset\n",
    "random_rf_pca_ros = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_ros.fit(X_pca_train_ros1, y_train_ros.values.ravel())\n",
    "joblib.dump(random_rf_pca_ros, \"RSCV_RF_ros_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.6908240794856809\n",
      "\n",
      "Accuracy Score : 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with RandomOverSampled PCA Dataset\")\n",
    "RSCV_RF_ros_pca_loaded  = joblib.load(\"RSCV_RF_ros_pca.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_ros_pca_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_ros_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_ros_pca_loaded.predict(X_pca_test_ros1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_ros.pkl']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier on ROS Dataset\n",
    "clf_gbc_ros = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_ros.fit(X_train_ros, y_train_ros.values.ravel())\n",
    "joblib.dump(clf_gbc_ros,'RSCV_GBC_ros.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.819666861484512\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with RandomOverSampled PCA Dataset\")\n",
    "RSCV_GBC_ros_loaded  = joblib.load(\"RSCV_GBC_ros.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_ros_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\",RSCV_GBC_ros_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_ros_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_ros.pkl']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GBC on ROS PCA Dataset\n",
    "clf_gbc_pca_ros = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_ros.fit(X_pca_train_ros1, y_train_ros.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_ros,'RSCV_GBC_pca_ros.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.8266218585622441\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 0.6, 'min_samples_leaf': 0.2, 'max_depth': 30.0, 'learning_rate': 0.25}\n",
      "\n",
      "Accuracy Score : 0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with RandomOverSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_ros_loaded  = joblib.load(\"RSCV_GBC_pca_ros.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_pca_ros_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_ros_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_ros_loaded.predict(X_pca_test_ros1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_ros.pkl']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier on ROS Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_ros = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_ros.fit(X_train_ros, y_train_ros.values.ravel())\n",
    "joblib.dump(random_adaboost_ros, \"RSCV_ADC_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with DT as base Estimator on RandomOverSampled Dataset\n",
      "\n",
      "Best Score - 0.5258912916423144\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      "Accuracy Score - 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with DT as base Estimator on RandomOverSampled Dataset\")\n",
    "RSCV_ADC_ros_loaded  = joblib.load(\"RSCV_ADC_ros.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_ros_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_ros_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_ADC_ros_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_pca_ros.pkl']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on ROS PCA Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_pca_ros = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_pca_ros.fit(X_pca_train_ros1, y_train_ros.values.ravel())\n",
    "joblib.dump(random_adaboost_pca_ros, \"RSCV_ADC_pca_ros.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with Decision Tree as base Classifier on RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.617270601987142\n",
      "\n",
      "Best Parameters - {'n_estimators': 64, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with Decision Tree as base Classifier on RandomOverSampled PCA Dataset\")\n",
    "RSCV_ADC_pca_ros_loaded  = joblib.load(\"RSCV_ADC_pca_ros.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_pca_ros_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_pca_ros_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_pca_ros_loaded.predict(X_pca_test_ros1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_ros.pkl']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostClassifier with SVC as base estimator on ROS Dataset\n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_ros = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "#X_train_ros, X_test, y_train_ros, y_test\n",
    "#X_pca_train_ros1, X_pca_test_ros1, y_train_ros, y_test\n",
    "random_adaboost_svc_ros.fit(X_train_ros, y_train_ros.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_ros, \"RSCV_ADC_svc_ros.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on RandomOverSampled Dataset\n",
      "\n",
      "Best Score : 0.6258912916423144\n",
      "\n",
      "Best Parameter : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on RandomOverSampled Dataset\")\n",
    "RSCV_ADC_svc_ros_loaded  = joblib.load(\"RSCV_ADC_svc_ros.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_ros_loaded.best_score_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_ros_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_ros_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_pca_ros.pkl']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoostClassifier with SVC as base estimator on ROS PCA Dataset\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_ros = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_ros.fit(X_pca_train_ros1, y_train_ros.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_ros, \"RSCV_ADC_svc_pca_ros.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on RandomOverSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.6224430157802454\n",
      "\n",
      "Best Parameter : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on RandomOverSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_ros_loaded  = joblib.load(\"RSCV_ADC_svc_pca_ros.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_ros_loaded.best_score_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_ros_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_pca_ros_loaded.predict(X_pca_test_ros1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tomek\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Original Training Dataset Distribution \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After TomekLinks UnderSampling\n",
      "\n",
      "0.0    256\n",
      "1.0    117\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#TomekLinks UnderSampling on Training Datasets\n",
    "tl1 = TomekLinks()\n",
    "X_train_tl1, y_train_tl1 = tl1.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution \\n\")\n",
    "print(y_train[\"is_patient\"].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After TomekLinks UnderSampling\\n\")\n",
    "print(pd.Series(y_train_tl1).value_counts())\n",
    "X_train_tl1 = pd.DataFrame(X_train_tl1)\n",
    "y_train_tl1 = pd.DataFrame(y_train_tl1)\n",
    "y_train_tl1 = y_train_tl1.rename(columns={0:\"is_patient\"})\n",
    "\n",
    "X_temp_tl1 = pd.concat([X_train_tl1, y_train_tl1], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_tl1 = X_temp_tl1.sample(frac=1, random_state=1)\n",
    "X_train_tl1  = X_temp_tl1.drop([\"is_patient\"], axis=1)\n",
    "y_train_tl1  = X_temp_tl1[[\"is_patient\"]]\n",
    "\n",
    "X_tl1 = pd.concat([X_train_tl1, X_test], axis=0)\n",
    "y_tl1 = pd.concat([y_train_tl1, y_test], axis=0)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51565892 0.68697132]\n",
      "0.0    256\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for Tomeklinks Under Sampled Dataset\n",
    "pca_tl1 = PCA(n_components=2)\n",
    "X_pca_tl1 = pca_tl1.fit_transform(X_train_tl1)\n",
    "print(pca_tl1.explained_variance_ratio_.cumsum())\n",
    "y_temp_tl1 = y_train_tl1\n",
    "y_temp_tl1[\"PC1\"] = X_pca_tl1[:,0]\n",
    "y_temp_tl1[\"PC2\"] = X_pca_tl1[:,1]\n",
    "sns.scatterplot(data=y_temp_tl1, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_tl1[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "67          0.0 -0.319569  0.185185\n",
      "346         0.0  0.774251 -0.248358\n",
      "341         1.0 -0.211980 -0.396700\n",
      "293         1.0 -0.212516 -0.397253\n",
      "90          1.0 -0.257593 -0.017164\n",
      "     is_patient\n",
      "67          0.0\n",
      "346         0.0\n",
      "341         1.0\n",
      "293         1.0\n",
      "90          1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_tl1.head())\n",
    "y_train_tl1 = y_train_tl1.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_tl1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sixth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on TomekLinks Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9411764705882353\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5454545454545454\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.38      0.55       125\n",
      "         1.0       0.38      0.94      0.54        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.66      0.66      0.54       175\n",
      "weighted avg       0.78      0.54      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Random Under sampled Training dataset:\n",
      "[0.61313869 0.58394161 0.59854015 0.54744526] \n",
      "\n",
      "0.5857664233576642\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1.1 Naive Bayes On TomekLinks Under Sampled Training dataset\n",
    "print(\"Naive Bayes on TomekLinks Under sampled Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Random Under sampled Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Random Under sampled Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on TomekLinks Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[119   6]\n",
      " [ 43   7]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.952\n",
      "Precision: 0.7345679012345679\n",
      "Specificity : 0.14\n",
      "F-Score : 0.8292682926829268\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83       125\n",
      "         1.0       0.54      0.14      0.22        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.64      0.55      0.53       175\n",
      "weighted avg       0.68      0.72      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on TomekLinks Undersample dataset:\n",
      "[0.7080292  0.70072993 0.68613139 0.72262774] \n",
      "\n",
      "0.7043795620437956\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On TomekLinks UnderSampled Training dataset\n",
    "print(\"SVM Classifier on TomekLinks Undersample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on TomekLinks Under sampled datset\n",
    "print(\"\\nCross Validation of SVM Classifier on TomekLinks Undersample dataset:\")\n",
    "crossValidation(LinearSVC(), X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on TomekLinks Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 48   2]]\n",
      "\n",
      "Accuracy : 0.7257142857142858\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7225433526011561\n",
      "Specificity : 0.04\n",
      "F-Score : 0.8389261744966443\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.84       125\n",
      "         1.0       1.00      0.04      0.08        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.86      0.52      0.46       175\n",
      "weighted avg       0.80      0.73      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on TomekLinks Under sample Training dataset:\n",
      "[0.69343066 0.67153285 0.70072993 0.69343066] \n",
      "\n",
      "0.6897810218978103\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3 Logistic Regression Classifier On TomekLinks Undersampled Training dataset\n",
    "print(\"Logistic Regression Classifier on TomekLinks Undersample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on TomekLinks Under Sampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on TomekLinks Under sample Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on TomekLinks Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[109  16]\n",
      " [ 39  11]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.872\n",
      "Precision: 0.7364864864864865\n",
      "Specificity : 0.22\n",
      "F-Score : 0.7985347985347986\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.87      0.80       125\n",
      "         1.0       0.41      0.22      0.29        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.57      0.55      0.54       175\n",
      "weighted avg       0.64      0.69      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on TomekLinks Undersample Training dataset:\n",
      "[0.69343066 0.67153285 0.72992701 0.70072993] \n",
      "\n",
      "0.698905109489051\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On TomekLinks Under sample Training dataset\n",
    "print(\"KNN Classifier on TomekLinks Undersample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on TomekLinks Under sampled Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on TomekLinks Undersample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on TomekLinks Undersample dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[97 28]\n",
      " [27 23]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.776\n",
      "Precision: 0.782258064516129\n",
      "Specificity : 0.46\n",
      "F-Score : 0.7791164658634537\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.78      0.78       125\n",
      "         1.0       0.45      0.46      0.46        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.62      0.62      0.62       175\n",
      "weighted avg       0.69      0.69      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on TomekLinks Undersample Training dataset:\n",
      "[0.68613139 0.70072993 0.74452555 0.69343066] \n",
      "\n",
      "0.7062043795620438\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On TomekLinks Under sample Training dataset\n",
    "print(\"Random Forest Classifier on TomekLinks Undersample dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on TomekLinks under sampled Training dataset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on TomekLinks Undersample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on TomekLinks Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[121   4]\n",
      " [ 43   7]]\n",
      "\n",
      "Accuracy : 0.7314285714285714\n",
      "Sensitivity : 0.968\n",
      "Precision: 0.7378048780487805\n",
      "Specificity : 0.14\n",
      "F-Score : 0.8373702422145328\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84       125\n",
      "         1.0       0.64      0.14      0.23        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.69      0.55      0.53       175\n",
      "weighted avg       0.71      0.73      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on TomekLinks under sampled Training dataset:\n",
      "[0.70072993 0.68613139 0.7080292  0.72262774] \n",
      "\n",
      "0.7043795620437957\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6.1 Voting Classifier for TomekLinks UnderSampled Training Dataset\n",
    "print(\"Voting Classifier on TomekLinks Under sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on TomekLinks UnderSampled Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on TomekLinks under sampled Training dataset:\")\n",
    "crossValidation(vclf, X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on TomekLink Undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[118   7]\n",
      " [ 39  11]]\n",
      "\n",
      "Accuracy : 0.7371428571428571\n",
      "Sensitivity : 0.944\n",
      "Precision: 0.7515923566878981\n",
      "Specificity : 0.22\n",
      "F-Score : 0.8368794326241135\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.94      0.84       125\n",
      "         1.0       0.61      0.22      0.32        50\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.68      0.58      0.58       175\n",
      "weighted avg       0.71      0.74      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on TomekLink Undersampled dataset:\n",
      "[0.69343066 0.7080292  0.70072993 0.69343066] \n",
      "\n",
      "0.6989051094890512\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on TomekLink Undersampled Dataset\n",
    "\n",
    "dt_tl1 = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_tl1 = AdaBoostClassifier(base_estimator=dt_tl1, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on TomekLink Undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_tl1, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on TomekLink Undersampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on TomekLink Undersampled dataset:\")\n",
    "crossValidation(adb_clf_tl1, X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier with SVC as base estimator on TomekLink Undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on TomekLink Undersampled dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70072993 0.69343066 0.69343066 0.69343066] \n",
      "\n",
      "0.6952554744525549\n"
     ]
    }
   ],
   "source": [
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_tl1 = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_tl1 = AdaBoostClassifier(base_estimator=svc_adb_tl1, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on TomekLink Undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_tl1, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on TomekLink Undersampled dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on TomekLink Undersampled dataset:\")\n",
    "crossValidation(adb_clf_svc_tl1, X_tl1, y_tl1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the TomekLink Undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[100  25]\n",
      " [ 27  23]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.8\n",
      "Precision: 0.7874015748031497\n",
      "Specificity : 0.46\n",
      "F-Score : 0.7936507936507937\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.80      0.79       125\n",
      "         1.0       0.48      0.46      0.47        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.63      0.63      0.63       175\n",
      "weighted avg       0.70      0.70      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on TomekLink Undersampled dataset:\n",
      "[0.69343066 0.68613139 0.71532847 0.73722628] \n",
      "\n",
      "0.7080291970802919\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On TomekLink Undersampled Dataset\n",
    "\n",
    "gbc_tl1 = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the TomekLink Undersampled dataset:\")\n",
    "clfFitPredict(gbc_tl1, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on TomekLink Undersampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on TomekLink Undersampled dataset:\")\n",
    "crossValidation(gbc_tl1, X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the TomekLink Undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on TomekLink Undersampled dataset:\n",
      "[0.70072993 0.69343066 0.69343066 0.69343066] \n",
      "\n",
      "0.6952554744525549\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the TomekLink Undersampled Dataset\n",
    "\n",
    "xgb_clf_tl1 = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the TomekLink Undersampled dataset:\")\n",
    "clfFitPredict(xgb_clf_tl1, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on TomekLink Undersampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on TomekLink Undersampled dataset:\")\n",
    "crossValidation(xgb_clf_tl1, X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on TomekLinksUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[104  21]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.832\n",
      "Precision: 0.7703703703703704\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7999999999999999\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.83      0.80       125\n",
      "         1.0       0.47      0.38      0.42        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.62      0.61      0.61       175\n",
      "weighted avg       0.69      0.70      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on TomekLinksUnderSampled dataset :\n",
      "[0.73722628 0.70072993 0.68613139 0.65693431] \n",
      "\n",
      "0.6952554744525548\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On TomekLinksUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[104  21]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.832\n",
      "Precision: 0.7703703703703704\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7999999999999999\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.83      0.80       125\n",
      "         1.0       0.47      0.38      0.42        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.62      0.61      0.61       175\n",
      "weighted avg       0.69      0.70      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On TomekLinksUnderSampled Dataset\n",
      "[0.73722628 0.70072993 0.68613139 0.65693431] \n",
      "\n",
      "0.6952554744525548\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On TomekLinksUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[124   1]\n",
      " [ 44   6]]\n",
      "\n",
      "Accuracy : 0.7428571428571429\n",
      "Sensitivity : 0.992\n",
      "Precision: 0.7380952380952381\n",
      "Specificity : 0.12\n",
      "F-Score : 0.8464163822525598\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.99      0.85       125\n",
      "         1.0       0.86      0.12      0.21        50\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.80      0.56      0.53       175\n",
      "weighted avg       0.77      0.74      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On TomekLinksUnderSampled Dataset\n",
      "[0.69343066 0.65693431 0.72992701 0.69343066] \n",
      "\n",
      "0.6934306569343066\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On TomekLinksUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[95 30]\n",
      " [30 20]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.76\n",
      "Precision: 0.76\n",
      "Specificity : 0.4\n",
      "F-Score : 0.76\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.76      0.76       125\n",
      "         1.0       0.40      0.40      0.40        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.58      0.58      0.58       175\n",
      "weighted avg       0.66      0.66      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On TomekLinksUnderSampled Dataset\n",
      "[0.71532847 0.67153285 0.64233577 0.62773723] \n",
      "\n",
      "0.6642335766423357\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On TomekLinksUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[122   3]\n",
      " [ 46   4]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.976\n",
      "Precision: 0.7261904761904762\n",
      "Specificity : 0.08\n",
      "F-Score : 0.8327645051194539\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.98      0.83       125\n",
      "         1.0       0.57      0.08      0.14        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.65      0.53      0.49       175\n",
      "weighted avg       0.68      0.72      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On TomekLinksUnderSampled Dataset\n",
      "[0.70072993 0.69343066 0.69343066 0.70072993] \n",
      "\n",
      "0.697080291970803\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On TomekLinksUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[98 27]\n",
      " [32 18]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.784\n",
      "Precision: 0.7538461538461538\n",
      "Specificity : 0.36\n",
      "F-Score : 0.7686274509803921\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.77       125\n",
      "         1.0       0.40      0.36      0.38        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.58      0.57      0.57       175\n",
      "weighted avg       0.65      0.66      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On TomekLinksUnderSampled Dataset\n",
      "[0.70072993 0.72262774 0.73722628 0.65693431] \n",
      "\n",
      "0.7043795620437956\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On TomekLinksUnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[121   4]\n",
      " [ 45   5]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 0.968\n",
      "Precision: 0.7289156626506024\n",
      "Specificity : 0.1\n",
      "F-Score : 0.831615120274914\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.97      0.83       125\n",
      "         1.0       0.56      0.10      0.17        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.64      0.53      0.50       175\n",
      "weighted avg       0.68      0.72      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On TomekLinksUnderSampled Dataset\n",
      "[0.69343066 0.67883212 0.68613139 0.71532847] \n",
      "\n",
      "0.6934306569343065\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the TomeklinkUnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on TomekLinksUnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on TomekLinksUnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on TomekLinksUnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On TomekLinksUnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On TomekLinksUnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_tl1, y_tl1, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on TomekLinksUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[38 87]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.49714285714285716\n",
      "Sensitivity : 0.304\n",
      "Precision: 0.9743589743589743\n",
      "Specificity : 0.98\n",
      "F-Score : 0.46341463414634143\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.30      0.46       125\n",
      "         1.0       0.36      0.98      0.53        50\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.67      0.64      0.50       175\n",
      "weighted avg       0.80      0.50      0.48       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on TomekLinksUnderSampled dataset :\n",
      "[0.64233577 0.65693431 0.68613139 0.7080292 ] \n",
      "\n",
      "0.6733576642335767\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The TomekLinksUnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on TomekLinksUnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_tl1, X_test, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on TomekLinksUnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on TomekLinksUnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51565892 0.68697132 0.80299322 0.88726991 0.93085351 0.96453576\n",
      " 0.99350083 0.99716251 0.99908119 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With TomekLinks Under sampled PCA Training dataset\n",
    "\n",
    "pca_tl_1 = PCA()\n",
    "X_pca_tl_1 = pca_tl_1.fit_transform(X_train_tl1)\n",
    "print(pca_tl_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_tl1 = PCA(n_components=6)\n",
    "X_pca_train_tl1 = pd.DataFrame(pca_tl1.fit_transform(X_train_tl1))\n",
    "X_pca_test_tl1 = pd.DataFrame(pca_tl1.transform(X_test))\n",
    "\n",
    "X_pca_tl1 = pd.concat([X_pca_train_tl1, X_pca_test_tl1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on TomekLinks Under sampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8222222222222222\n",
      "Specificity : 0.68\n",
      "F-Score : 0.6883720930232559\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.59      0.69       125\n",
      "         1.0       0.40      0.68      0.50        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.61      0.64      0.60       175\n",
      "weighted avg       0.70      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on TomekLinks Under sampled PCA Training dataset:\n",
      "[0.60583942 0.59124088 0.64233577 0.61313869] \n",
      "\n",
      "0.6131386861313869\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[120   5]\n",
      " [ 46   4]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.96\n",
      "Precision: 0.7228915662650602\n",
      "Specificity : 0.08\n",
      "F-Score : 0.8247422680412371\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82       125\n",
      "         1.0       0.44      0.08      0.14        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.58      0.52      0.48       175\n",
      "weighted avg       0.64      0.71      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "[0.69343066 0.68613139 0.69343066 0.68613139] \n",
      "\n",
      "0.6897810218978102\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 49   1]]\n",
      "\n",
      "Accuracy : 0.72\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7183908045977011\n",
      "Specificity : 0.02\n",
      "F-Score : 0.8361204013377925\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.84       125\n",
      "         1.0       1.00      0.02      0.04        50\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.86      0.51      0.44       175\n",
      "weighted avg       0.80      0.72      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "[0.67883212 0.70072993 0.70072993 0.69343066] \n",
      "\n",
      "0.6934306569343066\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[109  16]\n",
      " [ 40  10]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.872\n",
      "Precision: 0.7315436241610739\n",
      "Specificity : 0.2\n",
      "F-Score : 0.7956204379562044\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.87      0.80       125\n",
      "         1.0       0.38      0.20      0.26        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.56      0.54      0.53       175\n",
      "weighted avg       0.63      0.68      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "[0.70072993 0.69343066 0.73722628 0.70072993] \n",
      "\n",
      "0.708029197080292\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[112  13]\n",
      " [ 42   8]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.896\n",
      "Precision: 0.7272727272727273\n",
      "Specificity : 0.16\n",
      "F-Score : 0.8028673835125448\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80       125\n",
      "         1.0       0.38      0.16      0.23        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.55      0.53      0.51       175\n",
      "weighted avg       0.63      0.69      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "[0.69343066 0.70072993 0.7080292  0.69343066] \n",
      "\n",
      "0.6989051094890512\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[123   2]\n",
      " [ 48   2]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 0.984\n",
      "Precision: 0.7192982456140351\n",
      "Specificity : 0.04\n",
      "F-Score : 0.831081081081081\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.98      0.83       125\n",
      "         1.0       0.50      0.04      0.07        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.61      0.51      0.45       175\n",
      "weighted avg       0.66      0.71      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on TomekLinks Under sampled PCA Training dataset:\n",
      "[0.69343066 0.69343066 0.70072993 0.69343066] \n",
      "\n",
      "0.6952554744525549\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on TomekLink Undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on TomekLink Undersampled PCA Training dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69343066 0.70072993 0.69343066 0.69343066] \n",
      "\n",
      "0.6952554744525549\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on TomekLink Undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on TomekLink Undersampled PCA Training dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70072993 0.69343066 0.69343066 0.69343066] \n",
      "\n",
      "0.6952554744525549\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the TomekLink Undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[97 28]\n",
      " [35 15]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.776\n",
      "Precision: 0.7348484848484849\n",
      "Specificity : 0.3\n",
      "F-Score : 0.754863813229572\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.78      0.75       125\n",
      "         1.0       0.35      0.30      0.32        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.54      0.54      0.54       175\n",
      "weighted avg       0.62      0.64      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on TomekLink Undersampled PCA Training dataset:\n",
      "[0.72262774 0.67883212 0.72262774 0.64233577] \n",
      "\n",
      "0.6916058394160585\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the TomekLink Undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[125   0]\n",
      " [ 50   0]]\n",
      "\n",
      "Accuracy : 0.7142857142857143\n",
      "Sensitivity : 1.0\n",
      "Precision: 0.7142857142857143\n",
      "Specificity : 0.0\n",
      "F-Score : 0.8333333333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       125\n",
      "         1.0       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.50      0.42       175\n",
      "weighted avg       0.51      0.71      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on TomekLink Undersampled PCA Training dataset:\n",
      "[0.70072993 0.69343066 0.69343066 0.69343066] \n",
      "\n",
      "0.6952554744525549\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on TomekLink UnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[104  21]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.832\n",
      "Precision: 0.7703703703703704\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7999999999999999\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.83      0.80       125\n",
      "         1.0       0.47      0.38      0.42        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.62      0.61      0.61       175\n",
      "weighted avg       0.69      0.70      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on TomekLink UnderSampled PCA dataset :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75182482 0.75182482 0.69343066 0.67883212] \n",
      "\n",
      "0.718978102189781\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[104  21]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.832\n",
      "Precision: 0.7703703703703704\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7999999999999999\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.83      0.80       125\n",
      "         1.0       0.47      0.38      0.42        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.62      0.61      0.61       175\n",
      "weighted avg       0.69      0.70      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "[0.75182482 0.75182482 0.69343066 0.67883212] \n",
      "\n",
      "0.718978102189781\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[123   2]\n",
      " [ 44   6]]\n",
      "\n",
      "Accuracy : 0.7371428571428571\n",
      "Sensitivity : 0.984\n",
      "Precision: 0.7365269461077845\n",
      "Specificity : 0.12\n",
      "F-Score : 0.8424657534246576\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.98      0.84       125\n",
      "         1.0       0.75      0.12      0.21        50\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.74      0.55      0.52       175\n",
      "weighted avg       0.74      0.74      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "[0.66423358 0.67883212 0.69343066 0.69343066] \n",
      "\n",
      "0.6824817518248175\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[96 29]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.768\n",
      "Precision: 0.7741935483870968\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7710843373493975\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77       125\n",
      "         1.0       0.43      0.44      0.44        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.60      0.60      0.60       175\n",
      "weighted avg       0.68      0.67      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "[0.72262774 0.67153285 0.66423358 0.65693431] \n",
      "\n",
      "0.6788321167883211\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[117   8]\n",
      " [ 43   7]]\n",
      "\n",
      "Accuracy : 0.7085714285714285\n",
      "Sensitivity : 0.936\n",
      "Precision: 0.73125\n",
      "Specificity : 0.14\n",
      "F-Score : 0.8210526315789474\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.94      0.82       125\n",
      "         1.0       0.47      0.14      0.22        50\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.60      0.54      0.52       175\n",
      "weighted avg       0.66      0.71      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "[0.70072993 0.71532847 0.69343066 0.7080292 ] \n",
      "\n",
      "0.7043795620437956\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[107  18]\n",
      " [ 34  16]]\n",
      "\n",
      "Accuracy : 0.7028571428571428\n",
      "Sensitivity : 0.856\n",
      "Precision: 0.7588652482269503\n",
      "Specificity : 0.32\n",
      "F-Score : 0.8045112781954887\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.86      0.80       125\n",
      "         1.0       0.47      0.32      0.38        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.61      0.59      0.59       175\n",
      "weighted avg       0.68      0.70      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "[0.75182482 0.74452555 0.75182482 0.68613139] \n",
      "\n",
      "0.7335766423357664\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[122   3]\n",
      " [ 45   5]]\n",
      "\n",
      "Accuracy : 0.7257142857142858\n",
      "Sensitivity : 0.976\n",
      "Precision: 0.7305389221556886\n",
      "Specificity : 0.1\n",
      "F-Score : 0.8356164383561644\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.98      0.84       125\n",
      "         1.0       0.62      0.10      0.17        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.68      0.54      0.50       175\n",
      "weighted avg       0.70      0.73      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On TomekLink UnderSampled PCA Dataset\n",
      "[0.69343066 0.69343066 0.68613139 0.7080292 ] \n",
      "\n",
      "0.6952554744525548\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on TomekLink UnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9454545454545454\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5777777777777777\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.42      0.58       125\n",
      "         1.0       0.39      0.94      0.55        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.67      0.68      0.57       175\n",
      "weighted avg       0.79      0.57      0.57       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on TomekLink UnderSampled PCA dataset :\n",
      "[0.68613139 0.64233577 0.60583942 0.68613139] \n",
      "\n",
      "0.6551094890510949\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On TomekLinks Under sampled PCA Training dataset\n",
    "print(\"Naive Bayes on TomekLinks Under sampled PCA Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on TomekLinks Under sampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Naive Bayes on TomekLinks Under sampled PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On TomekLinks Under sampled PCA Training dataset\n",
    "print(\"SVM Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on TomekLinks Under sampled PCA Training dataset\n",
    "print(\"\\nCross Validation of SVM Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On TomekLinks Under sampled PCA Training dataset\n",
    "print(\"Logistic Regression Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on TomekLinks Under sampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On TomekLinks Under sampled PCA Training dataset\n",
    "print(\"KNN Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on TomekLinks Under sampled PCA Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On TomekLinks Under sampled PCA Training dataset\n",
    "print(\"Random Forest Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on TomekLinks Under sampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for TomekLinks Under sampled PCA Training dataset\n",
    "print(\"Voting Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on TomekLinks Under sampled PCA Training dataset\n",
    "print(\"\\nCross Validation of Voting Classifier on TomekLinks Under sampled PCA Training dataset:\")\n",
    "crossValidation(vclf, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on TomekLink Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on TomekLink Undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_tl1, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on TomekLink Undersampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on TomekLink Undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_tl1, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on TomekLink Undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_tl1, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on TomekLink Undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on TomekLink Undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_tl1, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On TomekLink Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier on the TomekLink Undersampled PCA Training dataset:\")\n",
    "clfFitPredict(gbc_tl1, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on TomekLink Undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on TomekLink Undersampled PCA Training dataset:\")\n",
    "crossValidation(gbc_tl1, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the TomekLink Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nXGBClassifier on the TomekLink Undersampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_tl1, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on TomekLink Undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on TomekLink Undersampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_tl1, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#11 Bagging Classifier On the TomekLink UnderSampled PCA Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on TomekLink UnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on TomekLink UnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on TomekLink UnderSampled PCA dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On TomekLink UnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On TomekLink UnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_tl1, y_tl1, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The TomekLink UnderSampled PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on TomekLink UnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on TomekLink UnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Perceptron on TomekLink UnderSampled PCA dataset :\")\n",
    "crossValidation(clf_percept, X_pca_tl1, y_tl1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_tus.pkl']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on TomekLinks UnderSampled Dataset\n",
    "random_svc_tus = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_svc_tus, \"RSCV_SVC_tus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with TomekLinks UnderSampled Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'rbf', 'gamma': 0.0001, 'C': 50}\n",
      "\n",
      "Best Score : 0.6863442389758179\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled Dataset\")\n",
    "RSCV_SVC_tus_loaded  = joblib.load(\"RSCV_SVC_tus.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_tus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_tus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_tus_pca.pkl']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on TUS PCA Dataset\n",
    "random_svc_tus_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_tus_pca.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_svc_tus_pca, \"RSCV_SVC_tus_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'rbf', 'gamma': 0.0001, 'C': 50}\n",
      "\n",
      "Best Score : 0.6863442389758179\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_SVC_tus_pca_loaded  = joblib.load(\"RSCV_SVC_tus_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_tus_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_tus_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_tus_pca_loaded.predict(X_pca_test_tl1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_tus.pkl']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On TomekLinks Dataset\n",
    "\n",
    "random_logreg_tus = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_logreg_tus, \"RSCV_LR_tus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with RandomOverSampled Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 100}\n",
      "\n",
      "Best Score : 0.7157183499288762\n",
      "\n",
      "Accuracy Score : 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with RandomOverSampled Dataset\")\n",
    "RSCV_LR_tus_loaded  = joblib.load(\"RSCV_LR_tus.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_tus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_tus_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_tus.pkl']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for LR on TUS PCA Dataset\n",
    "random_logreg_pca_tus = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_logreg_pca_tus, \"RSCV_LR_pca_tus.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 1}\n",
      "\n",
      "Best Score : 0.6918207681365576\n",
      "\n",
      "Accuracy Score : 0.72\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with TomekLink UnderSampled PCA Dataset\")\n",
    "RSCV_LR_pca_tus_loaded  = joblib.load(\"RSCV_LR_pca_tus.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_tus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_tus_loaded.predict(X_pca_test_tl1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_tus.pkl']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On TomekLink UnderSampled Dataset\n",
    "\n",
    "random_rf_tus = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_rf_tus, \"RSCV_RF_tus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with RandomOverSampled Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.6891180654338549\n",
      "\n",
      "Accuracy Score : 0.7314285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with RandomOverSampled Dataset\")\n",
    "RSCV_RF_tus_loaded  = joblib.load(\"RSCV_RF_tus.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_tus_loaded .best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_tus_loaded .best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_tus_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   21.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_tus.pkl']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning on RF with TUS PCA Dataset\n",
    "random_rf_pca_tus = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_rf_pca_tus, \"RSCV_RF_pca_tus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on TomekLink UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 26.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7023470839260313\n",
      "\n",
      "Accuracy Score : 0.6971428571428572\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on TomekLink UnderSampled PCA Dataset\")\n",
    "RSCV_RF_pca_tus_loaded  = joblib.load(\"RSCV_RF_pca_tus.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_tus_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_tus_loaded.predict(X_pca_test_tl1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_tus.pkl']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On TUS Dataset\n",
    "\n",
    "clf_gbc_tus = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(clf_gbc_tus,'RSCV_GBC_tus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with TomekLinks UnderSampled Dataset\n",
      "\n",
      "Best Score : 0.7131578947368421\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.6, 'min_samples_leaf': 0.4, 'max_depth': 24.0, 'learning_rate': 0.05}\n",
      "\n",
      "Accuracy Score : 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with TomekLinks UnderSampled Dataset\")\n",
    "RSCV_GBC_tus_loaded  = joblib.load(\"RSCV_GBC_tus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_tus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_tus_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_tus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_tus.pkl']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GBC on TUS PCA Dataset\n",
    "clf_gbc_pca_tus = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_tus,'RSCV_GBC_pca_tus.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with TomekLinks UnderSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.7211237553342816\n",
      "\n",
      "Best Parameters : {'n_estimators': 32, 'min_samples_split': 0.5, 'min_samples_leaf': 0.2, 'max_depth': 27.0, 'learning_rate': 0.1}\n",
      "\n",
      "Accuracy Score : 0.6971428571428572\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_tus_loaded  = joblib.load(\"RSCV_GBC_pca_tus.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_tus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_tus_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_tus_loaded.predict(X_pca_test_tl1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_tus.pkl']"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier On TUS Dataset\n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "random_adaboost_tus = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_tus, \"RSCV_ADC_tus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with TomekLinks UnderSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.6863442389758179\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_tus_loaded  = joblib.load(\"RSCV_ADC_tus.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_tus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_tus_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_tus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_tus_pca.pkl']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA TUS Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_tus_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_tus_pca.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_tus_pca, \"RSCV_ADC_tus_pca.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.6863442389758179\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_tus_pca_loaded  = joblib.load(\"RSCV_ADC_tus_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_tus_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_tus_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_tus_pca_loaded.predict(X_pca_test_tl1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_tus.pkl']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_tus = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_tus, \"RSCV_ADC_svc_tus.pkl\")\n",
    "#X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test\n",
    "#X_train_tl1, X_test, y_train_tl1, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on TomekLinks UnderSampled Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.6863442389758179\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on TomekLinks UnderSampled Dataset\")\n",
    "RSCV_ADC_svc_tus_loaded  = joblib.load(\"RSCV_ADC_svc_tus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_tus_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_tus_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_pca_tus.pkl']"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for AdaBoostClassifier with SVC as base estimator on TUS PCA Dataset\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_tus = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_tus, \"RSCV_ADC_svc_pca_tus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.6863442389758179\n",
      "\n",
      "Accuracy Score : 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_tus_loaded  = joblib.load(\"RSCV_ADC_svc_pca_tus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_tus_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_tus_loaded.predict(X_pca_test_tl1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOT TO be run \n",
    "#Hyperparameter Tuning for SVC on TomekLinks UnderSampled Dataset\n",
    "random_svc_tus = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_svc_tus, \"RSCV_SVC_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled Dataset\")\n",
    "RSCV_SVC_tus_loaded  = joblib.load(\"RSCV_SVC_tus.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_tus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_tus_loaded.predict(X_test)))\n",
    "\n",
    "\n",
    "random_svc_tus_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_tus_pca.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_svc_tus_pca, \"RSCV_SVC_tus_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_SVC_tus_pca_loaded  = joblib.load(\"RSCV_SVC_tus_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_tus_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_tus_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_tus_pca_loaded.predict(X_pca_test_tl1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On TomekLinks Dataset\n",
    "\n",
    "random_logreg_tus = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_logreg_tus, \"RSCV_LR_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with RandomOverSampled Dataset\")\n",
    "RSCV_LR_tus_loaded  = joblib.load(\"RSCV_LR_tus.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_tus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_tus_loaded.predict(X_test)))\n",
    "\n",
    "\n",
    "random_logreg_pca_tus = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_logreg_pca_tus, \"RSCV_LR_pca_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with TomekLink UnderSampled PCA Dataset\")\n",
    "RSCV_LR_pca_tus_loaded  = joblib.load(\"RSCV_LR_pca_tus.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_tus_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_tus_loaded.predict(X_pca_test_tl1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for RandomForest On TomekLink UnderSampled Dataset\n",
    "\n",
    "random_rf_tus = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_rf_tus, \"RSCV_RF_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF with RandomOverSampled Dataset\")\n",
    "RSCV_RF_tus_loaded  = joblib.load(\"RSCV_RF_tus.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_tus_loaded .best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_tus_loaded .best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_tus_loaded.predict(X_test)))\n",
    "\n",
    "\n",
    "random_rf_pca_tus = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_rf_pca_tus, \"RSCV_RF_pca_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF on TomekLink UnderSampled PCA Dataset\")\n",
    "RSCV_RF_pca_tus_loaded  = joblib.load(\"RSCV_RF_pca_tus.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_tus_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_tus_loaded.predict(X_pca_test_tl1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for GradientBoostingClassifier On TUS Dataset\n",
    "\n",
    "clf_gbc_tus = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(clf_gbc_tus,'RSCV_GBC_tus.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with TomekLinks UnderSampled Dataset\")\n",
    "RSCV_GBC_tus_loaded  = joblib.load(\"RSCV_GBC_tus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_tus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_tus_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_tus_loaded.predict(X_test)))\n",
    "\n",
    "clf_gbc_pca_tus = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_tus,'RSCV_GBC_pca_tus.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_tus_loaded  = joblib.load(\"RSCV_GBC_pca_tus.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_tus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_tus_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_tus_loaded.predict(X_pca_test_tl1)))\n",
    "\n",
    "\n",
    "#Hyperparameter for AdaBoost Classifier On TUS Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_tus = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_tus, \"RSCV_ADC_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_tus_loaded  = joblib.load(\"RSCV_ADC_tus.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_tus_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_tus_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_tus_loaded.predict(X_test)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA TUS Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_tus_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_tus_pca.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_tus_pca, \"RSCV_ADC_tus_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_tus_pca_loaded  = joblib.load(\"RSCV_ADC_tus_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_tus_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_tus_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_tus_pca_loaded.predict(X_pca_test_tl1)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_tus = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_tus.fit(X_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_tus, \"RSCV_ADC_svc_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SVC on TomekLinks UnderSampled Dataset\")\n",
    "RSCV_ADC_svc_tus_loaded  = joblib.load(\"RSCV_ADC_svc_tus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_tus_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_tus_loaded.predict(X_test)))\n",
    "\n",
    "#X_pca_train_tl1, X_pca_test_tl1, y_train_tl1, y_test\n",
    "#X_train_tl1, X_test, y_train_tl1, y_test\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_tus = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_tus.fit(X_pca_train_tl1, y_train_tl1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_tus, \"RSCV_ADC_svc_pca_tus.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with TomekLinks UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_tus_loaded  = joblib.load(\"RSCV_ADC_svc_pca_tus.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_tus_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_tus_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_tus_loaded.predict(X_pca_test_tl1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Original Distribution of Training Dataset \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After ClusterCentroid Under Sampling\n",
      "\n",
      "1.0    117\n",
      "0.0    117\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#ClusterCentroidsUnderSampling For Training Dataset\n",
    "cc1 = ClusterCentroids(random_state=42, sampling_strategy = 'majority')\n",
    "X_train_cc1, y_train_cc1 = cc1.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Distribution of Training Dataset \\n\")\n",
    "print(y_train[\"is_patient\"].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After ClusterCentroid Under Sampling\\n\")\n",
    "print(pd.Series(y_train_cc1).value_counts())\n",
    "X_train_cc1 = pd.DataFrame(X_train_cc1)\n",
    "y_train_cc1 = pd.DataFrame(y_train_cc1)\n",
    "y_train_cc1 = y_train_cc1.rename(columns={0:\"is_patient\"})\n",
    "\n",
    "\n",
    "X_temp_cc1 = pd.concat([X_train_cc1, y_train_cc1], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_cc1 = X_temp_cc1.sample(frac=1, random_state=1)\n",
    "X_train_cc1  = X_temp_cc1.drop([\"is_patient\"], axis=1)\n",
    "y_train_cc1  = X_temp_cc1[[\"is_patient\"]]\n",
    "\n",
    "X_cc1 = pd.concat([X_train_cc1, X_test])\n",
    "y_cc1 = pd.concat([y_train_cc1, y_test])\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48968788 0.66782164]\n",
      "0.0    117\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for ClusterCentroid Under Sampled Dataset\n",
    "pca_cc1 = PCA(n_components=2)\n",
    "X_pca_cc1 = pca_cc1.fit_transform(X_train_cc1)\n",
    "print(pca_cc1.explained_variance_ratio_.cumsum())\n",
    "y_temp_cc1 = y_train_cc1\n",
    "y_temp_cc1[\"PC1\"] = X_pca_cc1[:,0]\n",
    "y_temp_cc1[\"PC2\"] = X_pca_cc1[:,1]\n",
    "sns.scatterplot(data=y_temp_cc1, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_cc1[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "199         1.0  0.695138  0.242472\n",
      "69          0.0 -0.322454  0.141662\n",
      "233         1.0  0.714739 -0.190198\n",
      "39          0.0 -0.319147 -0.101768\n",
      "138         1.0 -0.287339  0.004185\n",
      "     is_patient\n",
      "199         1.0\n",
      "69          0.0\n",
      "233         1.0\n",
      "39          0.0\n",
      "138         1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_cc1.head())\n",
    "y_train_cc1 = y_train_cc1.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_cc1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seventh\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Cluster Centroid Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[44 81]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.52\n",
      "Sensitivity : 0.352\n",
      "Precision: 0.9361702127659575\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5116279069767442\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.35      0.51       125\n",
      "         1.0       0.37      0.94      0.53        50\n",
      "\n",
      "    accuracy                           0.52       175\n",
      "   macro avg       0.65      0.65      0.52       175\n",
      "weighted avg       0.77      0.52      0.52       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Cluster Centroid Under sampled Training dataset:\n",
      "[0.72815534 0.65686275 0.59803922 0.60784314] \n",
      "\n",
      "0.6477251094612603\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Cluster Centroid Under sampled Training dataset\n",
    "print(\"Naive Bayes on Cluster Centroid Under sampled Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Cluster Centroid Under sampled Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on Cluster Centroid Under sampled Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Cluster Centroids Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[54 71]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5771428571428572\n",
      "Sensitivity : 0.432\n",
      "Precision: 0.9473684210526315\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5934065934065934\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.43      0.59       125\n",
      "         1.0       0.40      0.94      0.56        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.67      0.69      0.58       175\n",
      "weighted avg       0.79      0.58      0.58       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Cluster Centroids Undersample Training dataset:\n",
      "[0.73786408 0.70588235 0.66666667 0.64705882] \n",
      "\n",
      "0.6893679802017895\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On Cluster Centroids UnderSampled Training dataset\n",
    "print(\"SVM Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Cluster Centroids Under sampled Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Cluster Centroids Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9122807017543859\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5714285714285714\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.42      0.57       125\n",
      "         1.0       0.38      0.90      0.54        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.65      0.66      0.55       175\n",
      "weighted avg       0.76      0.55      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Cluster Centroids Undersample Training dataset:\n",
      "[0.72815534 0.68627451 0.6372549  0.67647059] \n",
      "\n",
      "0.6820388349514563\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On Cluster Centroids Undersampled Training dataset\n",
    "print(\"Logistic Regression Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Cluster Centroids Undersampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Cluster Centroids Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[89 36]\n",
      " [32 18]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.712\n",
      "Precision: 0.7355371900826446\n",
      "Specificity : 0.36\n",
      "F-Score : 0.7235772357723577\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.71      0.72       125\n",
      "         1.0       0.33      0.36      0.35        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.53      0.54      0.53       175\n",
      "weighted avg       0.62      0.61      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Cluster Centroids Undersample Training dataset:\n",
      "[0.61165049 0.55882353 0.65686275 0.60784314] \n",
      "\n",
      "0.6087949743003997\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On Cluster Centroids Undersample Training dataset\n",
    "print(\"KNN Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Cluster Centroids Undersampled Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Cluster Centroids Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[70 55]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.56\n",
      "Precision: 0.875\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6829268292682927\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.56      0.68       125\n",
      "         1.0       0.42      0.80      0.55        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.65      0.68      0.62       175\n",
      "weighted avg       0.75      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Cluster Centroids Undersample Training dataset:\n",
      "[0.82524272 0.73529412 0.65686275 0.58823529] \n",
      "\n",
      "0.7014087188273368\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On Cluster Centroids UnderSampled Training dataset\n",
    "print(\"Random Forest Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Cluster Centroids under sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Cluster Centroids Undersample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Cluster Centroids Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.9193548387096774\n",
      "Specificity : 0.9\n",
      "F-Score : 0.6096256684491979\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.46      0.61       125\n",
      "         1.0       0.40      0.90      0.55        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.66      0.68      0.58       175\n",
      "weighted avg       0.77      0.58      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Cluster Centroids under sampled Training dataset:\n",
      "[0.74757282 0.7254902  0.67647059 0.62745098] \n",
      "\n",
      "0.6942461450599657\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Cluster Centroids UnderSampled Training Dataset\n",
    "print(\"Voting Classifier on Cluster Centroids Under sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Cluster Centroids UnderSampled Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on Cluster Centroids under sampled Training dataset:\")\n",
    "crossValidation(vclf, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Cluster Centroids Undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8947368421052632\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6766169154228855\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.54      0.68       125\n",
      "         1.0       0.42      0.84      0.56        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.66      0.69      0.62       175\n",
      "weighted avg       0.76      0.63      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Cluster Centroids Undersampled dataset:\n",
      "[0.7961165  0.7254902  0.66666667 0.58823529] \n",
      "\n",
      "0.6941271654292785\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Cluster Centroids Undersampled Dataset\n",
    "\n",
    "dt_cc1 = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_cc1 = AdaBoostClassifier(base_estimator=dt_cc1, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Cluster Centroids Undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_cc1, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Cluster Centroids Undersampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Cluster Centroids Undersampled dataset:\")\n",
    "crossValidation(adb_clf_cc1, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Cluster Centroids Undersampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[45 80]\n",
      " [ 2 48]]\n",
      "\n",
      "Accuracy : 0.5314285714285715\n",
      "Sensitivity : 0.36\n",
      "Precision: 0.9574468085106383\n",
      "Specificity : 0.96\n",
      "F-Score : 0.5232558139534883\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.36      0.52       125\n",
      "         1.0       0.38      0.96      0.54        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.67      0.66      0.53       175\n",
      "weighted avg       0.79      0.53      0.53       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Cluster Centroids Undersampled dataset:\n",
      "[0.65048544 0.62745098 0.6372549  0.66666667] \n",
      "\n",
      "0.6454644964782029\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_cc1 = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_cc1 = AdaBoostClassifier(base_estimator=svc_adb_cc1, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Cluster Centroids Undersampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_cc1, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Cluster Centroids Undersampled dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Cluster Centroids Undersampled dataset:\")\n",
    "crossValidation(adb_clf_svc_cc1, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Cluster Centroids Undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.881578947368421\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6666666666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.41      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Cluster Centroids Undersampled dataset:\n",
      "[0.77669903 0.69607843 0.65686275 0.59803922] \n",
      "\n",
      "0.681919855320769\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Cluster Centroids Undersampled Dataset\n",
    "\n",
    "gbc_cc1 = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the Cluster Centroids Undersampled dataset:\")\n",
    "clfFitPredict(gbc_cc1, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Cluster Centroids Undersampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Cluster Centroids Undersampled dataset:\")\n",
    "crossValidation(gbc_cc1, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Cluster Centroids Undersampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[51 74]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5485714285714286\n",
      "Sensitivity : 0.408\n",
      "Precision: 0.9107142857142857\n",
      "Specificity : 0.9\n",
      "F-Score : 0.56353591160221\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.41      0.56       125\n",
      "         1.0       0.38      0.90      0.53        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.64      0.65      0.55       175\n",
      "weighted avg       0.76      0.55      0.55       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Cluster Centroids Undersampled dataset:\n",
      "[0.59223301 0.58823529 0.58823529 0.59803922] \n",
      "\n",
      "0.5916857034075766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Cluster Centroids Undersampled Dataset\n",
    "\n",
    "xgb_clf_cc1 = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the Cluster Centroids Undersampled dataset:\")\n",
    "clfFitPredict(xgb_clf_cc1, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Cluster Centroids Undersampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Cluster Centroids Undersampled dataset:\")\n",
    "crossValidation(xgb_clf_cc1, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on Cluster CentroidsUnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.8369565217391305\n",
      "Specificity : 0.7\n",
      "F-Score : 0.7096774193548386\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.62      0.71       125\n",
      "         1.0       0.42      0.70      0.53        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.63      0.66      0.62       175\n",
      "weighted avg       0.72      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on Cluster Centroids UnderSampled dataset :\n",
      "[0.77669903 0.71568627 0.64705882 0.62745098] \n",
      "\n",
      "0.6917237768893966\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.8369565217391305\n",
      "Specificity : 0.7\n",
      "F-Score : 0.7096774193548386\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.62      0.71       125\n",
      "         1.0       0.42      0.70      0.53        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.63      0.66      0.62       175\n",
      "weighted avg       0.72      0.64      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.77669903 0.71568627 0.64705882 0.62745098] \n",
      "\n",
      "0.6917237768893966\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[53 72]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.424\n",
      "Precision: 0.8983050847457628\n",
      "Specificity : 0.88\n",
      "F-Score : 0.5760869565217391\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.42      0.58       125\n",
      "         1.0       0.38      0.88      0.53        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.64      0.65      0.55       175\n",
      "weighted avg       0.75      0.55      0.56       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.72815534 0.7254902  0.64705882 0.6372549 ] \n",
      "\n",
      "0.6844898153436132\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[51 74]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.52\n",
      "Sensitivity : 0.408\n",
      "Precision: 0.8360655737704918\n",
      "Specificity : 0.8\n",
      "F-Score : 0.5483870967741936\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.41      0.55       125\n",
      "         1.0       0.35      0.80      0.49        50\n",
      "\n",
      "    accuracy                           0.52       175\n",
      "   macro avg       0.59      0.60      0.52       175\n",
      "weighted avg       0.70      0.52      0.53       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.65048544 0.61764706 0.60784314 0.65686275] \n",
      "\n",
      "0.6332095945174187\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.5257142857142857\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.8620689655172413\n",
      "Specificity : 0.84\n",
      "F-Score : 0.546448087431694\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.40      0.55       125\n",
      "         1.0       0.36      0.84      0.50        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.61      0.62      0.52       175\n",
      "weighted avg       0.72      0.53      0.53       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.7184466  0.66666667 0.62745098 0.69607843] \n",
      "\n",
      "0.67716067009328\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.8589743589743589\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6600985221674877\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.54      0.66       125\n",
      "         1.0       0.40      0.78      0.53        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.63      0.66      0.60       175\n",
      "weighted avg       0.73      0.61      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.80582524 0.74509804 0.66666667 0.60784314] \n",
      "\n",
      "0.7063582714639254\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.9076923076923077\n",
      "Specificity : 0.88\n",
      "F-Score : 0.6210526315789474\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.47      0.62       125\n",
      "         1.0       0.40      0.88      0.55        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.65      0.68      0.59       175\n",
      "weighted avg       0.76      0.59      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.69902913 0.67647059 0.65686275 0.68627451] \n",
      "\n",
      "0.6796592423377117\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the Cluster Centroids UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on Cluster CentroidsUnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on Cluster Centroids UnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on Cluster Centroids UnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On Cluster Centroids UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On Cluster Centroids UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_cc1, y_cc1, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on Cluster Centroids UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[35 90]\n",
      " [ 2 48]]\n",
      "\n",
      "Accuracy : 0.4742857142857143\n",
      "Sensitivity : 0.28\n",
      "Precision: 0.9459459459459459\n",
      "Specificity : 0.96\n",
      "F-Score : 0.4320987654320988\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.28      0.43       125\n",
      "         1.0       0.35      0.96      0.51        50\n",
      "\n",
      "    accuracy                           0.47       175\n",
      "   macro avg       0.65      0.62      0.47       175\n",
      "weighted avg       0.78      0.47      0.45       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on Cluster Centroids UnderSampled dataset :\n",
      "[0.62135922 0.71568627 0.6372549  0.68627451] \n",
      "\n",
      "0.6651437273938701\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The Cluster Centroids UnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on Cluster Centroids UnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_cc1, X_test, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on Cluster Centroids UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on Cluster Centroids UnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48968788 0.66782164 0.79537781 0.87413913 0.92220788 0.96152161\n",
      " 0.99254253 0.99685271 0.99897522 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With Cluster Centroids Under Sampling PCA Training Dataset\n",
    "\n",
    "pca_cc_1 = PCA()\n",
    "X_pca_cc_1 = pca_cc_1.fit_transform(X_train_cc1)\n",
    "print(pca_cc_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "\n",
    "pca_cc1 = PCA(n_components=6)\n",
    "X_pca_train_cc1 = pd.DataFrame(pca_cc1.fit_transform(X_train_cc1))\n",
    "X_pca_test_cc1 = pd.DataFrame(pca_cc1.transform(X_test))\n",
    "\n",
    "X_pca_cc1 = pd.concat([X_pca_train_cc1, X_pca_test_cc1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[45 80]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.49142857142857144\n",
      "Sensitivity : 0.36\n",
      "Precision: 0.8333333333333334\n",
      "Specificity : 0.82\n",
      "F-Score : 0.5027932960893855\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.36      0.50       125\n",
      "         1.0       0.34      0.82      0.48        50\n",
      "\n",
      "    accuracy                           0.49       175\n",
      "   macro avg       0.59      0.59      0.49       175\n",
      "weighted avg       0.69      0.49      0.50       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "[0.75728155 0.73529412 0.54901961 0.54901961] \n",
      "\n",
      "0.647653721682848\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[53 72]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.424\n",
      "Precision: 0.9464285714285714\n",
      "Specificity : 0.94\n",
      "F-Score : 0.585635359116022\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.42      0.59       125\n",
      "         1.0       0.39      0.94      0.56        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.67      0.68      0.57       175\n",
      "weighted avg       0.79      0.57      0.58       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "[0.73786408 0.70588235 0.65686275 0.6372549 ] \n",
      "\n",
      "0.6844660194174758\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9122807017543859\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5714285714285714\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.42      0.57       125\n",
      "         1.0       0.38      0.90      0.54        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.65      0.66      0.55       175\n",
      "weighted avg       0.76      0.55      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "[0.69902913 0.69607843 0.6372549  0.69607843] \n",
      "\n",
      "0.6821102227298685\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[83 42]\n",
      " [30 20]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.664\n",
      "Precision: 0.7345132743362832\n",
      "Specificity : 0.4\n",
      "F-Score : 0.6974789915966386\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.66      0.70       125\n",
      "         1.0       0.32      0.40      0.36        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.53      0.53      0.53       175\n",
      "weighted avg       0.62      0.59      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "[0.60194175 0.57843137 0.57843137 0.60784314] \n",
      "\n",
      "0.5916619074814392\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.8333333333333334\n",
      "Specificity : 0.76\n",
      "F-Score : 0.6091370558375634\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.48      0.61       125\n",
      "         1.0       0.37      0.76      0.50        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.60      0.62      0.55       175\n",
      "weighted avg       0.70      0.56      0.58       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "[0.78640777 0.74509804 0.61764706 0.64705882] \n",
      "\n",
      "0.6990529221397297\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[56 69]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.448\n",
      "Precision: 0.875\n",
      "Specificity : 0.84\n",
      "F-Score : 0.5925925925925927\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.45      0.59       125\n",
      "         1.0       0.38      0.84      0.52        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.63      0.64      0.56       175\n",
      "weighted avg       0.73      0.56      0.57       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\n",
      "[0.73786408 0.76470588 0.64705882 0.65686275] \n",
      "\n",
      "0.7016228821625737\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on Cluster Centroids Undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.5142857142857142\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.8333333333333334\n",
      "Specificity : 0.8\n",
      "F-Score : 0.5405405405405406\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.40      0.54       125\n",
      "         1.0       0.35      0.80      0.48        50\n",
      "\n",
      "    accuracy                           0.51       175\n",
      "   macro avg       0.59      0.60      0.51       175\n",
      "weighted avg       0.69      0.51      0.52       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on Cluster Centroids Undersampled PCA Training dataset:\n",
      "[0.73786408 0.73529412 0.57843137 0.6372549 ] \n",
      "\n",
      "0.6722111174566915\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Cluster Centroids Undersampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.9365079365079365\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6276595744680851\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.47      0.63       125\n",
      "         1.0       0.41      0.92      0.57        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.67      0.70      0.60       175\n",
      "weighted avg       0.79      0.60      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on Cluster Centroids Undersampled PCA Training dataset:\n",
      "[0.63106796 0.6372549  0.6372549  0.68627451] \n",
      "\n",
      "0.6479630687226348\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the Cluster Centroids Undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[54 71]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.5257142857142857\n",
      "Sensitivity : 0.432\n",
      "Precision: 0.8181818181818182\n",
      "Specificity : 0.76\n",
      "F-Score : 0.5654450261780104\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.43      0.57       125\n",
      "         1.0       0.35      0.76      0.48        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.58      0.60      0.52       175\n",
      "weighted avg       0.68      0.53      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on Cluster Centroids Undersampled PCA Training dataset:\n",
      "[0.75728155 0.7254902  0.61764706 0.62745098] \n",
      "\n",
      "0.681967447173044\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the Cluster Centroids Undersampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8554216867469879\n",
      "Specificity : 0.76\n",
      "F-Score : 0.6826923076923076\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.57      0.68       125\n",
      "         1.0       0.41      0.76      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.63      0.66      0.61       175\n",
      "weighted avg       0.73      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on Cluster Centroids Undersampled PCA Training dataset:\n",
      "[0.59223301 0.58823529 0.58823529 0.59803922] \n",
      "\n",
      "0.5916857034075766\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on Cluster Centroids UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8131868131868132\n",
      "Specificity : 0.66\n",
      "F-Score : 0.6851851851851852\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.59      0.69       125\n",
      "         1.0       0.39      0.66      0.49        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.60      0.63      0.59       175\n",
      "weighted avg       0.69      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on Cluster Centroids UnderSampled dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81553398 0.68627451 0.62745098 0.62745098] \n",
      "\n",
      "0.6891776127926899\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8131868131868132\n",
      "Specificity : 0.66\n",
      "F-Score : 0.6851851851851852\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.59      0.69       125\n",
      "         1.0       0.39      0.66      0.49        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.60      0.63      0.59       175\n",
      "weighted avg       0.69      0.61      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.81553398 0.68627451 0.62745098 0.62745098] \n",
      "\n",
      "0.6891776127926899\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[89 36]\n",
      " [20 30]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.712\n",
      "Precision: 0.8165137614678899\n",
      "Specificity : 0.6\n",
      "F-Score : 0.7606837606837606\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.71      0.76       125\n",
      "         1.0       0.45      0.60      0.52        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.64      0.66      0.64       175\n",
      "weighted avg       0.71      0.68      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.82524272 0.69607843 0.66666667 0.64705882] \n",
      "\n",
      "0.7087616600038072\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.8666666666666667\n",
      "Specificity : 0.84\n",
      "F-Score : 0.5621621621621622\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.42      0.56       125\n",
      "         1.0       0.37      0.84      0.51        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.62      0.63      0.54       175\n",
      "weighted avg       0.72      0.54      0.55       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.7184466  0.6372549  0.58823529 0.67647059] \n",
      "\n",
      "0.6551018465638683\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[53 72]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.424\n",
      "Precision: 0.8548387096774194\n",
      "Specificity : 0.82\n",
      "F-Score : 0.5668449197860962\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.42      0.57       125\n",
      "         1.0       0.36      0.82      0.50        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.61      0.62      0.53       175\n",
      "weighted avg       0.71      0.54      0.55       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.73786408 0.66666667 0.62745098 0.69607843] \n",
      "\n",
      "0.6820150390253188\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.8205128205128205\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6305418719211823\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.51      0.63       125\n",
      "         1.0       0.37      0.72      0.49        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.60      0.62      0.56       175\n",
      "weighted avg       0.69      0.57      0.59       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.73786408 0.73529412 0.64705882 0.67647059] \n",
      "\n",
      "0.699171901770417\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.921875\n",
      "Specificity : 0.9\n",
      "F-Score : 0.6243386243386243\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.47      0.62       125\n",
      "         1.0       0.41      0.90      0.56        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.66      0.69      0.59       175\n",
      "weighted avg       0.77      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On Cluster Centroids UnderSampled Dataset\n",
      "[0.72815534 0.67647059 0.66666667 0.67647059] \n",
      "\n",
      "0.68694079573577\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on Cluster Centroids UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[51 74]\n",
      " [13 37]]\n",
      "\n",
      "Accuracy : 0.5028571428571429\n",
      "Sensitivity : 0.408\n",
      "Precision: 0.796875\n",
      "Specificity : 0.74\n",
      "F-Score : 0.5396825396825398\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.41      0.54       125\n",
      "         1.0       0.33      0.74      0.46        50\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.57      0.57      0.50       175\n",
      "weighted avg       0.66      0.50      0.52       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on Cluster Centroids UnderSampled dataset :\n",
      "[0.65048544 0.67647059 0.61764706 0.61764706] \n",
      "\n",
      "0.6405625356938892\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"Naive Bayes on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"\\nCross Validation of Naive Bayes on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"SVM Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"\\nCross Validation of SVM Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"Logistic Regression Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "#4.1 KNN Classifier On Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"KNN Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"Random Forest Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"Voting Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on Cluster Centroids Under Sampling PCA Training Dataset\n",
    "print(\"\\nCross Validation of Voting Classifier on Cluster Centroids Under Sampling PCA Training Dataset:\")\n",
    "crossValidation(vclf, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on Cluster Centroids Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on Cluster Centroids Undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_cc1, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on Cluster Centroids Undersampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on Cluster Centroids Undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_cc1, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Cluster Centroids Undersampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_cc1, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on Cluster Centroids Undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on Cluster Centroids Undersampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_cc1, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On Cluster Centroids Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier on the Cluster Centroids Undersampled PCA Training dataset:\")\n",
    "clfFitPredict(gbc_cc1, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on Cluster Centroids Undersampled PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on Cluster Centroids Undersampled PCA Training dataset:\")\n",
    "crossValidation(gbc_cc1, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the Cluster Centroids Undersampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nXGBClassifier on the Cluster Centroids Undersampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_cc1, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on Cluster Centroids Undersampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on Cluster Centroids Undersampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_cc1, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Bagging Classifier On the Cluster Centroids UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on Cluster Centroids UnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on Cluster Centroids UnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on Cluster Centroids UnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On Cluster Centroids UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On Cluster Centroids UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_cc1, y_cc1, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The Cluster Centroids UnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on Cluster Centroids UnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on Cluster Centroids UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on Cluster Centroids UnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_pca_cc1, y_cc1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_cc.pkl']"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on Cluster Centroids UnderSampled Dataset\n",
    "random_svc_cc = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_svc_cc, \"RSCV_SVC_cc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 'auto', 'C': 100}\n",
      "\n",
      "Best Score : 0.7690217391304348\n",
      "\n",
      "Accuracy Score : 0.5542857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_SVC_cc_loaded  = joblib.load(\"RSCV_SVC_cc.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_cc_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_cc_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_cc_pca.pkl']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC with Cluster Centroids UnderSampled Dataset\n",
    "random_svc_cc_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_cc_pca.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_svc_cc_pca, \"RSCV_SVC_cc_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with Cluster Centroids UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score : 0.7858695652173913\n",
      "\n",
      "Accuracy Score : 0.56\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_SVC_cc_pca_loaded  = joblib.load(\"RSCV_SVC_cc_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_cc_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_cc_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_cc_pca_loaded.predict(X_pca_test_cc1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    4.8s finished\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_cc.pkl']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On Cluster Centroids Dataset\n",
    "random_logreg_cc = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_logreg_cc, \"RSCV_LR_cc.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l2', 'C': 100}\n",
      "\n",
      "Best Score : 0.7858695652173913\n",
      "\n",
      "Accuracy Score : 0.5771428571428572\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_LR_cc_loaded  = joblib.load(\"RSCV_LR_cc.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_cc_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_cc_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_cc.pkl']"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for LR on Cluster Centroids Dataset\n",
    "random_logreg_pca_cc = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_logreg_pca_cc, \"RSCV_LR_pca_cc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with Cluster Centroids UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.7733695652173913\n",
      "\n",
      "Accuracy Score : 0.5657142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_LR_pca_cc_loaded  = joblib.load(\"RSCV_LR_pca_cc.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_cc_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_cc_loaded.predict(X_pca_test_cc1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_cc.pkl']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On Cluster Centroid UnderSampled Dataset\n",
    "\n",
    "random_rf_cc = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_rf_cc, \"RSCV_RF_cc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.30000000000000004, 'max_features': 'auto', 'max_depth': 22.0, 'bootstrap': True}\n",
      "\n",
      "Best Score : 0.7646739130434782\n",
      "\n",
      "Accuracy Score : 0.6514285714285715\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_RF_cc_loaded  = joblib.load(\"RSCV_RF_cc.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_cc_loaded .best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_cc_loaded .best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_cc_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   26.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_cc.pkl']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning with RF on CC Dataset\n",
    "random_rf_pca_cc = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_rf_pca_cc, \"RSCV_RF_pca_cc.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on Cluster Centroids UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 26.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7340579710144928\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_RF_pca_cc_loaded  = joblib.load(\"RSCV_RF_pca_cc.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_cc_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_cc_loaded.predict(X_pca_test_cc1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_cc.pkl']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On Cluster Centroids Dataset\n",
    "\n",
    "clf_gbc_cc = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(clf_gbc_cc,'RSCV_GBC_cc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Best Score : 0.7860507246376811\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 0.6, 'min_samples_leaf': 0.2, 'max_depth': 30.0, 'learning_rate': 0.25}\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_GBC_cc_loaded  = joblib.load(\"RSCV_GBC_cc.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_cc_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_cc_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_cc_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_cc.pkl']"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GBC on CC Dataset\n",
    "clf_gbc_pca_cc = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_cc,'RSCV_GBC_pca_cc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with Cluster Centroids UnderSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.7471014492753623\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 1.0, 'min_samples_leaf': 0.1, 'max_depth': 22.0, 'learning_rate': 0.005}\n",
      "\n",
      "Accuracy Score : 0.5371428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_cc_loaded  = joblib.load(\"RSCV_GBC_pca_cc.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_cc_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_cc_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_cc_loaded.predict(X_pca_test_cc1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_cc.pkl']"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier On CC Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_cc = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_cc, \"RSCV_ADC_cc.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with Cluster Centroid UnderSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.5661231884057971\n",
      "\n",
      "Best Parameters - {'n_estimators': 500, 'learning_rate': 1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.6742857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with Cluster Centroid UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_cc_loaded  = joblib.load(\"RSCV_ADC_cc.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_cc_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_cc_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_cc_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_cc_pca.pkl']"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA CC Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_cc_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_cc_pca.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_cc_pca, \"RSCV_ADC_cc_pca.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with Cluster Centroids UnderSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.5911231884057973\n",
      "\n",
      "Best Parameters - {'n_estimators': 64, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_cc_pca_loaded  = joblib.load(\"RSCV_ADC_cc_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_cc_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_cc_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_cc_pca_loaded.predict(X_pca_test_cc1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_cc.pkl']"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_cc = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_cc, \"RSCV_ADC_svc_cc.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on Cluster Centroids UnderSampled Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5327898550724639\n",
      "\n",
      "Accuracy Score : 0.3942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_ADC_svc_cc_loaded  = joblib.load(\"RSCV_ADC_svc_cc.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_cc_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_cc_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_pca_cc.pkl']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning with ADC with SVC on CC PCA Dataset\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_cc = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_cc, \"RSCV_ADC_svc_pca_cc.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with Cluster Centroid UnderSampled PCA Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5327898550724639\n",
      "\n",
      "Accuracy Score : 0.38857142857142857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroid UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_cc_loaded  = joblib.load(\"RSCV_ADC_svc_pca_cc.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_cc_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_cc_loaded.predict(X_pca_test_cc1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperparameter Tuning for SVC on Cluster Centroids UnderSampled Dataset\n",
    "random_svc_cc = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_svc_cc, \"RSCV_SVC_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_SVC_cc_loaded  = joblib.load(\"RSCV_SVC_cc.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_cc_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_cc_loaded.predict(X_test)))\n",
    "\n",
    "random_svc_cc_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_cc_pca.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_svc_cc_pca, \"RSCV_SVC_cc_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_SVC_cc_pca_loaded  = joblib.load(\"RSCV_SVC_cc_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_cc_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_cc_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_cc_pca_loaded.predict(X_pca_test_cc1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On Cluster Centroids Dataset\n",
    "\n",
    "random_logreg_cc = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_logreg_cc, \"RSCV_LR_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_LR_cc_loaded  = joblib.load(\"RSCV_LR_cc.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_cc_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_cc_loaded.predict(X_test)))\n",
    "\n",
    "random_logreg_pca_cc = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_logreg_pca_cc, \"RSCV_LR_pca_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_LR_pca_cc_loaded  = joblib.load(\"RSCV_LR_pca_cc.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_cc_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_cc_loaded.predict(X_pca_test_cc1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for RandomForest On Cluster Centroid UnderSampled Dataset\n",
    "\n",
    "random_rf_cc = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_rf_cc, \"RSCV_RF_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_RF_cc_loaded  = joblib.load(\"RSCV_RF_cc.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_cc_loaded .best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_cc_loaded .best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_cc_loaded.predict(X_test)))\n",
    "\n",
    "random_rf_pca_cc = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_rf_pca_cc, \"RSCV_RF_pca_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF on Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_RF_pca_cc_loaded  = joblib.load(\"RSCV_RF_pca_cc.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_cc_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_cc_loaded.predict(X_pca_test_cc1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for GradientBoostingClassifier On Cluster Centroids Dataset\n",
    "\n",
    "clf_gbc_cc = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(clf_gbc_cc,'RSCV_GBC_cc.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_GBC_cc_loaded  = joblib.load(\"RSCV_GBC_cc.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_cc_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_cc_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_cc_loaded.predict(X_test)))\n",
    "\n",
    "clf_gbc_pca_cc = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_cc,'RSCV_GBC_pca_cc.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_cc_loaded  = joblib.load(\"RSCV_GBC_pca_cc.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_cc_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_cc_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_cc_loaded.predict(X_pca_test_cc1)))\n",
    "\n",
    "\n",
    "#Hyperparameter for AdaBoost Classifier On CC Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_cc = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_cc, \"RSCV_ADC_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with Cluster Centroid UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_cc_loaded  = joblib.load(\"RSCV_ADC_cc.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_cc_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_cc_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_cc_loaded.predict(X_test)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA CC Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_cc_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_cc_pca.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_cc_pca, \"RSCV_ADC_cc_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroids UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_cc_pca_loaded  = joblib.load(\"RSCV_ADC_cc_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_cc_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_cc_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_cc_pca_loaded.predict(X_pca_test_cc1)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_cc = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_cc.fit(X_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_cc, \"RSCV_ADC_svc_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SVC on Cluster Centroids UnderSampled Dataset\")\n",
    "RSCV_ADC_svc_cc_loaded  = joblib.load(\"RSCV_ADC_svc_cc.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_cc_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_cc_loaded.predict(X_test)))\n",
    "\n",
    "#X_train_cc1, X_test, y_train_cc1, y_test\n",
    "#X_pca_train_cc1, X_pca_test_cc1, y_train_cc1, y_test\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_cc = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_cc.fit(X_pca_train_cc1, y_train_cc1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_cc, \"RSCV_ADC_svc_pca_cc.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with Cluster Centroid UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_cc_loaded  = joblib.load(\"RSCV_ADC_svc_pca_cc.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_cc_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_cc_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_cc_loaded.predict(X_pca_test_cc1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"smote\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Original Training Dataset Distribution \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After SMOTE Over Sampling\n",
      "\n",
      "0.0    291\n",
      "1.0    291\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#SMOTE Over Sampling for Training Dataset\n",
    "sm1 = SMOTE(random_state=42)\n",
    "X_train_sm1, y_train_sm1 = sm1.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution \\n\")\n",
    "print(y_train[\"is_patient\"].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After SMOTE Over Sampling\\n\")\n",
    "print(pd.Series(y_train_sm1).value_counts())\n",
    "X_train_sm1 = pd.DataFrame(X_train_sm1)\n",
    "y_train_sm1 = pd.DataFrame(y_train_sm1)\n",
    "y_train_sm1 = y_train_sm1.rename(columns = {0:'is_patient'})\n",
    "\n",
    "\n",
    "X_temp_sm1 = pd.concat([X_train_sm1, y_train_sm1], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_sm1 = X_temp_sm1.sample(frac=1, random_state=1)\n",
    "X_train_sm1  = X_temp_sm1.drop([\"is_patient\"], axis=1)\n",
    "y_train_sm1  = X_temp_sm1[[\"is_patient\"]]\n",
    "\n",
    "X_sm1 = pd.concat([X_train_sm1, X_test], axis=0)\n",
    "y_sm1 = pd.concat([y_train_sm1, y_test], axis=0)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57289228 0.7420241 ]\n",
      "0.0    291\n",
      "1.0    291\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for SMOTE Over Sampled Dataset\n",
    "pca_sm1 = PCA(n_components=2)\n",
    "X_pca_sm1 = pca_sm1.fit_transform(X_train_sm1)\n",
    "print(pca_sm1.explained_variance_ratio_.cumsum())\n",
    "y_temp_sm1 = y_train_sm1\n",
    "y_temp_sm1[\"PC1\"] = X_pca_sm1[:,0]\n",
    "y_temp_sm1[\"PC2\"] = X_pca_sm1[:,1]\n",
    "sns.scatterplot(data=y_temp_sm1, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_sm1[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "457         1.0 -0.278275 -0.355462\n",
      "225         1.0  0.712903  0.088737\n",
      "162         0.0 -0.290528  0.658835\n",
      "195         0.0 -0.294793  0.041554\n",
      "267         0.0 -0.283704  0.070613\n",
      "     is_patient\n",
      "457         1.0\n",
      "225         1.0\n",
      "162         0.0\n",
      "195         0.0\n",
      "267         0.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_sm1.head())\n",
    "y_train_sm1 = y_train_sm1.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_sm1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eighth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on SMOTE Oversampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[56 69]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.448\n",
      "Precision: 0.9032258064516129\n",
      "Specificity : 0.88\n",
      "F-Score : 0.5989304812834224\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.45      0.60       125\n",
      "         1.0       0.39      0.88      0.54        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.65      0.66      0.57       175\n",
      "weighted avg       0.76      0.57      0.58       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on SMOTE Over sampled Training dataset:\n",
      "[0.67368421 0.65608466 0.68253968 0.67195767] \n",
      "\n",
      "0.6710665552770817\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On SMOTE Oversampled Training dataset\n",
    "print(\"Naive Bayes on SMOTE Oversampled Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTE Over sampled Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTE Over sampled Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on SMOTE Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.88\n",
      "Specificity : 0.82\n",
      "F-Score : 0.66\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.53      0.66       125\n",
      "         1.0       0.41      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.65      0.67      0.60       175\n",
      "weighted avg       0.75      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on SMOTE Oversample Training dataset:\n",
      "[0.71578947 0.67195767 0.68253968 0.70899471] \n",
      "\n",
      "0.6948203842940686\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On SMOTE OverSampled Training dataset\n",
    "print(\"SVM Classifier on SMOTE Oversample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTE Oversampled Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTE Oversample Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on SMOTE Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.872093023255814\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7109004739336493\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.60      0.71       125\n",
      "         1.0       0.44      0.78      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.69      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on SMOTE Oversample Training dataset:\n",
      "[0.68947368 0.66666667 0.60846561 0.7037037 ] \n",
      "\n",
      "0.6670774157616263\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On SMOTE Oversampled Training dataset\n",
    "print(\"Logistic Regression Classifier on SMOTE Oversample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTE Oversampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTE Oversample Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on SMOTE Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[102  23]\n",
      " [ 32  18]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.816\n",
      "Precision: 0.7611940298507462\n",
      "Specificity : 0.36\n",
      "F-Score : 0.7876447876447876\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79       125\n",
      "         1.0       0.44      0.36      0.40        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.60      0.59      0.59       175\n",
      "weighted avg       0.67      0.69      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on SMOTE Oversample Training dataset:\n",
      "[0.73684211 0.74603175 0.77777778 0.69312169] \n",
      "\n",
      "0.7384433305485937\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On SMOTE Oversample Training dataset\n",
    "print(\"KNN Classifier on SMOTE Oversample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTE Oversampled Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTE Oversample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on SMOTE Oversample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.8333333333333334\n",
      "Specificity : 0.7\n",
      "F-Score : 0.6976744186046512\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.60      0.70       125\n",
      "         1.0       0.41      0.70      0.52        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.62      0.65      0.61       175\n",
      "weighted avg       0.71      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on SMOTE Oversample Training dataset:\n",
      "[0.75789474 0.69312169 0.6984127  0.66666667] \n",
      "\n",
      "0.7040239487607908\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On SMOTE OverSampled Training dataset\n",
    "print(\"Random Forest Classifier on SMOTE Oversample Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTE Over sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTE Oversample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on SMOTE Over sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[72 53]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.576\n",
      "Precision: 0.8780487804878049\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6956521739130435\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.58      0.70       125\n",
      "         1.0       0.43      0.80      0.56        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.65      0.69      0.63       175\n",
      "weighted avg       0.75      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on SMOTE Over sampled Training dataset:\n",
      "[0.73157895 0.69312169 0.68253968 0.71957672] \n",
      "\n",
      "0.7067042606516291\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for SMOTE OverSampled Training Dataset\n",
    "print(\"Voting Classifier on SMOTE Over sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTE OverSampled Training dataset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTE Over sampled Training dataset:\")\n",
    "crossValidation(vclf, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on SMOTE OverSampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8658536585365854\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6859903381642511\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.57      0.69       125\n",
      "         1.0       0.42      0.78      0.55        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.64      0.67      0.62       175\n",
      "weighted avg       0.74      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on SMOTE OverSampled dataset:\n",
      "[0.71578947 0.68783069 0.66137566 0.68253968] \n",
      "\n",
      "0.6868838763575607\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTE OverSampled Dataset\n",
    "\n",
    "dt_sm1 = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_sm1 = AdaBoostClassifier(base_estimator=dt_sm1, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTE OverSampled Dataset:\")\n",
    "clfFitPredict(adb_clf_sm1, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on SMOTE OverSampled Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTE OverSampled dataset:\")\n",
    "crossValidation(adb_clf_sm1, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on SMOTE OverSampled Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[83 42]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.664\n",
      "Precision: 0.8469387755102041\n",
      "Specificity : 0.7\n",
      "F-Score : 0.7443946188340808\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.66      0.74       125\n",
      "         1.0       0.45      0.70      0.55        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.65      0.68      0.65       175\n",
      "weighted avg       0.73      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on SMOTE OverSampled dataset:\n",
      "[0.65263158 0.62962963 0.62962963 0.6984127 ] \n",
      "\n",
      "0.6525758841548315\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_sm1 = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_sm1 = AdaBoostClassifier(base_estimator=svc_adb_sm1, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on SMOTE OverSampled Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_sm1, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTE OverSampled dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTE OverSampled dataset:\")\n",
    "crossValidation(adb_clf_svc_sm1, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the SMOTE OverSampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[82 43]\n",
      " [22 28]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.656\n",
      "Precision: 0.7884615384615384\n",
      "Specificity : 0.56\n",
      "F-Score : 0.7161572052401747\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.66      0.72       125\n",
      "         1.0       0.39      0.56      0.46        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.59      0.61      0.59       175\n",
      "weighted avg       0.68      0.63      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on SMOTE OverSampled dataset:\n",
      "[0.76315789 0.71957672 0.71957672 0.67724868] \n",
      "\n",
      "0.7198900027847396\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On SMOTE OverSampled Dataset\n",
    "\n",
    "gbc_sm1 = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTE OverSampled dataset:\")\n",
    "clfFitPredict(gbc_sm1, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTE OverSampled datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTE OverSampled dataset:\")\n",
    "crossValidation(gbc_sm1, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the SMOTE OverSampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.8444444444444444\n",
      "Specificity : 0.72\n",
      "F-Score : 0.7069767441860465\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.61      0.71       125\n",
      "         1.0       0.42      0.72      0.53        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.63      0.66      0.62       175\n",
      "weighted avg       0.72      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on SMOTE OverSampled dataset:\n",
      "[0.54736842 0.55026455 0.55026455 0.55026455] \n",
      "\n",
      "0.5495405179615706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the SMOTE OverSampled Dataset\n",
    "\n",
    "xgb_clf_sm1 = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the SMOTE OverSampled dataset:\")\n",
    "clfFitPredict(xgb_clf_sm1, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTE OverSampled dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTE OverSampled dataset:\")\n",
    "crossValidation(xgb_clf_sm1, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on SMOTE OverSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[96 29]\n",
      " [29 21]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.768\n",
      "Precision: 0.768\n",
      "Specificity : 0.42\n",
      "F-Score : 0.768\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77       125\n",
      "         1.0       0.42      0.42      0.42        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.59      0.59      0.59       175\n",
      "weighted avg       0.67      0.67      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on SMOTE OverSampled dataset :\n",
      "[0.79473684 0.83068783 0.77248677 0.69312169] \n",
      "\n",
      "0.7727582846003899\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On SMOTE OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[96 29]\n",
      " [29 21]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.768\n",
      "Precision: 0.768\n",
      "Specificity : 0.42\n",
      "F-Score : 0.768\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77       125\n",
      "         1.0       0.42      0.42      0.42        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.59      0.59      0.59       175\n",
      "weighted avg       0.67      0.67      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On SMOTE OverSampled Dataset\n",
      "[0.79473684 0.83068783 0.77248677 0.69312169] \n",
      "\n",
      "0.7727582846003899\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On SMOTE OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.8933333333333333\n",
      "Specificity : 0.84\n",
      "F-Score : 0.67\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.54      0.67       125\n",
      "         1.0       0.42      0.84      0.56        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.66      0.69      0.61       175\n",
      "weighted avg       0.76      0.62      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On SMOTE OverSampled Dataset\n",
      "[0.55263158 0.59259259 0.68783069 0.60846561] \n",
      "\n",
      "0.6103801169590644\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On SMOTE OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8255813953488372\n",
      "Specificity : 0.7\n",
      "F-Score : 0.6729857819905213\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.57      0.67       125\n",
      "         1.0       0.39      0.70      0.50        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.61      0.63      0.59       175\n",
      "weighted avg       0.70      0.61      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On SMOTE OverSampled Dataset\n",
      "[0.68421053 0.68253968 0.63492063 0.65608466] \n",
      "\n",
      "0.6644388749651908\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On SMOTE OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.9090909090909091\n",
      "Specificity : 0.88\n",
      "F-Score : 0.6282722513089004\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.48      0.63       125\n",
      "         1.0       0.40      0.88      0.55        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.66      0.68      0.59       175\n",
      "weighted avg       0.76      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On SMOTE OverSampled Dataset\n",
      "[0.68421053 0.68783069 0.67195767 0.70899471] \n",
      "\n",
      "0.6882483987747146\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On SMOTE OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[86 39]\n",
      " [28 22]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.688\n",
      "Precision: 0.7543859649122807\n",
      "Specificity : 0.44\n",
      "F-Score : 0.7196652719665272\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.69      0.72       125\n",
      "         1.0       0.36      0.44      0.40        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.56      0.56      0.56       175\n",
      "weighted avg       0.64      0.62      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On SMOTE OverSampled Dataset\n",
      "[0.82631579 0.79365079 0.7989418  0.68253968] \n",
      "\n",
      "0.7753620161514898\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On SMOTE OverSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8902439024390244\n",
      "Specificity : 0.82\n",
      "F-Score : 0.7053140096618358\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.58      0.71       125\n",
      "         1.0       0.44      0.82      0.57        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.67      0.70      0.64       175\n",
      "weighted avg       0.76      0.65      0.67       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On SMOTE OverSampled Dataset\n",
      "[0.67368421 0.67724868 0.61375661 0.68783069] \n",
      "\n",
      "0.6631300473405736\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the SMOTE OverSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTE OverSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on SMOTE OverSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on SMOTE OverSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTE OverSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTE OverSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_sm1, y_sm1, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on SMOTE OverSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[94 31]\n",
      " [27 23]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.752\n",
      "Precision: 0.7768595041322314\n",
      "Specificity : 0.46\n",
      "F-Score : 0.7642276422764228\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.75      0.76       125\n",
      "         1.0       0.43      0.46      0.44        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.60      0.61      0.60       175\n",
      "weighted avg       0.68      0.67      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on SMOTE OverSampled dataset :\n",
      "[0.65263158 0.67724868 0.6031746  0.67724868] \n",
      "\n",
      "0.6525758841548315\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The SMOTE OverSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTE OverSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_sm1, X_test, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTE OverSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on SMOTE OverSampled dataset :\")\n",
    "crossValidation(clf_percept, X_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57289228 0.16913182 0.09344083 0.079012   0.03618626 0.02434364\n",
      " 0.02034568 0.00268106 0.00133452 0.00063192]\n",
      "[0.57289228 0.7420241  0.83546493 0.91447693 0.95066318 0.97500682\n",
      " 0.9953525  0.99803356 0.99936808 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With PCA on SMOTE Dataset\n",
    "\n",
    "pca_sm_1 = PCA()\n",
    "X_pca_sm_1 = pca_sm_1.fit_transform(X_train_sm1)\n",
    "print(pca_sm_1.explained_variance_ratio_)\n",
    "print(pca_sm_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_sm1 = PCA(n_components=5)\n",
    "X_pca_train_sm1 = pd.DataFrame(pca_sm1.fit_transform(X_train_sm1))\n",
    "X_pca_test_sm1 = pd.DataFrame(pca_sm1.transform(X_test))\n",
    "\n",
    "X_pca_sm1 = pd.concat([X_pca_train_sm1, X_pca_test_sm1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.52\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.7662337662337663\n",
      "Specificity : 0.64\n",
      "F-Score : 0.5841584158415841\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.47      0.58       125\n",
      "         1.0       0.33      0.64      0.43        50\n",
      "\n",
      "    accuracy                           0.52       175\n",
      "   macro avg       0.55      0.56      0.51       175\n",
      "weighted avg       0.64      0.52      0.54       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on SMOTE OverSampled PCA Training Dataset:\n",
      "[0.64210526 0.62962963 0.63492063 0.59259259] \n",
      "\n",
      "0.6248120300751879\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[70 55]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.56\n",
      "Precision: 0.8974358974358975\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6896551724137933\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.56      0.69       125\n",
      "         1.0       0.43      0.84      0.57        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.67      0.70      0.63       175\n",
      "weighted avg       0.76      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "[0.68421053 0.63492063 0.65608466 0.68783069] \n",
      "\n",
      "0.665761626287942\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8604651162790697\n",
      "Specificity : 0.76\n",
      "F-Score : 0.7014218009478673\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.59      0.70       125\n",
      "         1.0       0.43      0.76      0.55        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.64      0.68      0.62       175\n",
      "weighted avg       0.74      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "[0.65263158 0.61375661 0.58730159 0.70899471] \n",
      "\n",
      "0.6406711222500696\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[103  22]\n",
      " [ 33  17]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.824\n",
      "Precision: 0.7573529411764706\n",
      "Specificity : 0.34\n",
      "F-Score : 0.789272030651341\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.82      0.79       125\n",
      "         1.0       0.44      0.34      0.38        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.60      0.58      0.59       175\n",
      "weighted avg       0.67      0.69      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "[0.70526316 0.77248677 0.77248677 0.67724868] \n",
      "\n",
      "0.7318713450292398\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.8048780487804879\n",
      "Specificity : 0.68\n",
      "F-Score : 0.6376811594202899\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.53      0.64       125\n",
      "         1.0       0.37      0.68      0.48        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.59      0.60      0.56       175\n",
      "weighted avg       0.68      0.57      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "[0.68947368 0.66666667 0.67724868 0.67195767] \n",
      "\n",
      "0.6763366750208856\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [13 37]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8488372093023255\n",
      "Specificity : 0.74\n",
      "F-Score : 0.6919431279620853\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.58      0.69       125\n",
      "         1.0       0.42      0.74      0.53        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.63      0.66      0.61       175\n",
      "weighted avg       0.73      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on SMOTE OverSampled PCA Training Dataset:\n",
      "[0.66842105 0.63492063 0.64021164 0.67195767] \n",
      "\n",
      "0.6538777499303815\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[63 62]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.504\n",
      "Precision: 0.863013698630137\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6363636363636364\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.50      0.64       125\n",
      "         1.0       0.39      0.80      0.53        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.63      0.65      0.58       175\n",
      "weighted avg       0.73      0.59      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on SMOTE OverSampled PCA Training dataset:\n",
      "[0.64736842 0.66137566 0.65079365 0.67724868] \n",
      "\n",
      "0.6591966026176552\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on SMOTE OverSampled PCA Training Dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[74 51]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.592\n",
      "Precision: 0.8604651162790697\n",
      "Specificity : 0.76\n",
      "F-Score : 0.7014218009478673\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.59      0.70       125\n",
      "         1.0       0.43      0.76      0.55        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.64      0.68      0.62       175\n",
      "weighted avg       0.74      0.64      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on SMOTE OverSampled PCA Training dataset:\n",
      "[0.64736842 0.62962963 0.5978836  0.65079365] \n",
      "\n",
      "0.6314188248398775\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the SMOTE OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [21 29]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.776595744680851\n",
      "Specificity : 0.58\n",
      "F-Score : 0.6666666666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.58      0.67       125\n",
      "         1.0       0.36      0.58      0.44        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.57      0.58      0.55       175\n",
      "weighted avg       0.66      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on SMOTE OverSampled PCA Training dataset:\n",
      "[0.65263158 0.69312169 0.67724868 0.61375661] \n",
      "\n",
      "0.6591896407685882\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the SMOTE OverSampled PCA Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[98 27]\n",
      " [32 18]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.784\n",
      "Precision: 0.7538461538461538\n",
      "Specificity : 0.36\n",
      "F-Score : 0.7686274509803921\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.77       125\n",
      "         1.0       0.40      0.36      0.38        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.58      0.57      0.57       175\n",
      "weighted avg       0.65      0.66      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on SMOTE OverSampled PCA Training dataset:\n",
      "[0.54736842 0.55026455 0.55026455 0.55026455] \n",
      "\n",
      "0.5495405179615706\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on SMOTE OverSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[93 32]\n",
      " [32 18]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.744\n",
      "Precision: 0.744\n",
      "Specificity : 0.36\n",
      "F-Score : 0.744\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74       125\n",
      "         1.0       0.36      0.36      0.36        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.55      0.55      0.55       175\n",
      "weighted avg       0.63      0.63      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on SMOTE OverSampled PCA Training dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75263158 0.75132275 0.74074074 0.66137566] \n",
      "\n",
      "0.7265176830966305\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[93 32]\n",
      " [32 18]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.744\n",
      "Precision: 0.744\n",
      "Specificity : 0.36\n",
      "F-Score : 0.744\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74       125\n",
      "         1.0       0.36      0.36      0.36        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.55      0.55      0.55       175\n",
      "weighted avg       0.63      0.63      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On SMOTE OverSampled PCA Dataset\n",
      "[0.75263158 0.75132275 0.74074074 0.66137566] \n",
      "\n",
      "0.7265176830966305\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.6628571428571428\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.851063829787234\n",
      "Specificity : 0.72\n",
      "F-Score : 0.730593607305936\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.64      0.73       125\n",
      "         1.0       0.44      0.72      0.55        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.65      0.68      0.64       175\n",
      "weighted avg       0.73      0.66      0.68       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On SMOTE OverSampled PCA Dataset\n",
      "[0.7        0.58730159 0.66137566 0.67724868] \n",
      "\n",
      "0.6564814814814814\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.8064516129032258\n",
      "Specificity : 0.64\n",
      "F-Score : 0.6880733944954128\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.60      0.69       125\n",
      "         1.0       0.39      0.64      0.48        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.60      0.62      0.59       175\n",
      "weighted avg       0.69      0.61      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On SMOTE OverSampled PCA Dataset\n",
      "[0.67368421 0.73015873 0.66137566 0.68253968] \n",
      "\n",
      "0.6869395711500974\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.8533333333333334\n",
      "Specificity : 0.78\n",
      "F-Score : 0.64\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.51      0.64       125\n",
      "         1.0       0.39      0.78      0.52        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.62      0.65      0.58       175\n",
      "weighted avg       0.72      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On SMOTE OverSampled PCA Dataset\n",
      "[0.65263158 0.6984127  0.65608466 0.69312169] \n",
      "\n",
      "0.675062656641604\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[82 43]\n",
      " [25 25]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.656\n",
      "Precision: 0.7663551401869159\n",
      "Specificity : 0.5\n",
      "F-Score : 0.7068965517241379\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.66      0.71       125\n",
      "         1.0       0.37      0.50      0.42        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.57      0.58      0.57       175\n",
      "weighted avg       0.65      0.61      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On SMOTE OverSampled PCA Dataset\n",
      "[0.74210526 0.75661376 0.73544974 0.68783069] \n",
      "\n",
      "0.7304998607630186\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[73 52]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.584\n",
      "Precision: 0.8690476190476191\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6985645933014353\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.58      0.70       125\n",
      "         1.0       0.43      0.78      0.55        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.65      0.68      0.63       175\n",
      "weighted avg       0.74      0.64      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On SMOTE OverSampled PCA Dataset\n",
      "[0.65263158 0.60846561 0.5978836  0.7037037 ] \n",
      "\n",
      "0.6406711222500696\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on SMOTE OverSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[110  15]\n",
      " [ 41   9]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.88\n",
      "Precision: 0.7284768211920529\n",
      "Specificity : 0.18\n",
      "F-Score : 0.7971014492753623\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.88      0.80       125\n",
      "         1.0       0.38      0.18      0.24        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.55      0.53      0.52       175\n",
      "weighted avg       0.63      0.68      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on SMOTE OverSampled PCA dataset :\n",
      "[0.6        0.57671958 0.66137566 0.65608466] \n",
      "\n",
      "0.6235449735449736\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On SMOTE OverSampled PCA Training Dataset\n",
    "print(\"Naive Bayes on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTE OverSampled PCA Training Dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On SMOTE OverSampled PCA Training Dataset\n",
    "print(\"SVM Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On SMOTE OverSampled PCA Training Dataset\n",
    "print(\"Logistic Regression Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "#4.1 KNN Classifier On SMOTE OverSampled PCA Training Dataset\n",
    "print(\"KNN Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On SMOTE OverSampled PCA Training Dataset\n",
    "print(\"Random Forest Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for SMOTE OverSampled PCA Training Dataset\n",
    "print(\"Voting Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTE OverSampled PCA Training Dataset:\")\n",
    "crossValidation(vclf, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTE OverSampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_sm1, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on SMOTE OverSampled PCA Dataset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTE OverSampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_sm1, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on SMOTE OverSampled PCA Training Dataset:\")\n",
    "clfFitPredict(adb_clf_svc_sm1, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTE OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTE OverSampled PCA Training dataset:\")\n",
    "crossValidation(adb_clf_svc_sm1, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On SMOTE OverSampled PCA Training Dataset\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTE OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(gbc_sm1, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTE OverSampled PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTE OverSampled PCA Training dataset:\")\n",
    "crossValidation(gbc_sm1, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the SMOTE OverSampled PCA Training Dataset\n",
    "\n",
    "print(\"\\nXGBClassifier on the SMOTE OverSampled PCA Training dataset:\")\n",
    "clfFitPredict(xgb_clf_sm1, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTE OverSampled PCA Training dataset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTE OverSampled PCA Training dataset:\")\n",
    "crossValidation(xgb_clf_sm1, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "#Bagging Classifier On the SMOTE OverSampled PCA Training Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTE OverSampled PCA dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on SMOTE OverSampled PCA datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on SMOTE OverSampled PCA Training dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTE OverSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTE OverSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_sm1, y_sm1, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The SMOTE OverSampled PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTE OverSampled PCA dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTE OverSampled PCA dataset\n",
    "print(\"\\nCross Validation of Perceptron on SMOTE OverSampled PCA dataset :\")\n",
    "crossValidation(clf_percept, X_pca_sm1, y_sm1, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    1.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_sm.pkl']"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTE OverSampled Dataset\n",
    "random_svc_sm = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_svc_sm, \"RSCV_SVC_sm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTE OverSampled Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 'auto', 'C': 100}\n",
      "\n",
      "Best Score : 0.6907656341320865\n",
      "\n",
      "Accuracy Score : 0.5828571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled Dataset\")\n",
    "RSCV_SVC_sm_loaded  = joblib.load(\"RSCV_SVC_sm.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_sm_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_sm_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_sm_pca.pkl']"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTE OverSampled PCA Dataset\n",
    "random_svc_sm_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_sm_pca.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_svc_sm_pca, \"RSCV_SVC_sm_pca.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score : 0.6992986557568674\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_SVC_sm_pca_loaded  = joblib.load(\"RSCV_SVC_sm_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_sm_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_sm_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_sm_pca_loaded.predict(X_pca_test_sm1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_sm.pkl']"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On SMOTE OverSampled\n",
    "\n",
    "random_logreg_sm = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_logreg_sm, \"RSCV_LR_sm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTE OverSampled Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l1', 'C': 500}\n",
      "\n",
      "Best Score : 0.7269433080070135\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTE OverSampled Dataset\")\n",
    "RSCV_LR_sm_loaded  = joblib.load(\"RSCV_LR_sm.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_sm_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_sm_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_sm.pkl']"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for LR with SMOTE PCA Dataset\n",
    "random_logreg_pca_sm = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_logreg_pca_sm, \"RSCV_LR_pca_sm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l1', 'C': 1500}\n",
      "\n",
      "Best Score : 0.7044126241963763\n",
      "\n",
      "Accuracy Score : 0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_LR_pca_sm_loaded  = joblib.load(\"RSCV_LR_pca_sm.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_sm_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_sm_loaded.predict(X_pca_test_sm1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_sm.pkl']"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On SMOTE OverSampled Dataset\n",
    "\n",
    "random_rf_sm = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_rf_sm, \"RSCV_RF_sm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with SMOTE OverSampled Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.732115721800117\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with SMOTE OverSampled Dataset\")\n",
    "RSCV_RF_sm_loaded  = joblib.load(\"RSCV_RF_sm.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_sm_loaded .best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_sm_loaded .best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_sm_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_sm.pkl']"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RF on SMOTE PCA Dataset\n",
    "random_rf_pca_sm = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_rf_pca_sm, \"RSCV_RF_pca_sm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 1000, 'min_samples_split': 0.7000000000000001, 'min_samples_leaf': 0.1, 'max_features': 'sqrt', 'max_depth': 12.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.6821449444769142\n",
      "\n",
      "Accuracy Score : 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_RF_pca_sm_loaded  = joblib.load(\"RSCV_RF_pca_sm.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_sm_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_sm_loaded.predict(X_pca_test_sm1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_sm.pkl']"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTE OverSampled Dataset\n",
    "clf_gbc_sm = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(clf_gbc_sm,'RSCV_GBC_sm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with SMOTE OverSampled Dataset\n",
      "\n",
      "Best Score : 0.7629456458211573\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 0.6, 'min_samples_leaf': 0.2, 'max_depth': 30.0, 'learning_rate': 0.25}\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with SMOTE OverSampled Dataset\")\n",
    "RSCV_GBC_sm_loaded  = joblib.load(\"RSCV_GBC_sm.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_sm_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_sm_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_sm_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_sm.pkl']"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTE OverSampled PCA Dataset\n",
    "clf_gbc_pca_sm = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_sm,'RSCV_GBC_pca_sm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.740561075394506\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_sm_loaded  = joblib.load(\"RSCV_GBC_pca_sm.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_sm_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_sm_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_sm_loaded.predict(X_pca_test_sm1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_sm.pkl']"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier On SMOTE OverSampled Dataset\n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_sm = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_sm, \"RSCV_ADC_sm.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.6224430157802454\n",
      "\n",
      "Best Parameters - {'n_estimators': 32, 'learning_rate': 0.25, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_ADC_sm_loaded  = joblib.load(\"RSCV_ADC_sm.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_sm_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_sm_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_sm_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_sm_pca.pkl']"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA SMOTE OverSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_sm_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_sm_pca.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_sm_pca, \"RSCV_ADC_sm_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.6396843950905903\n",
      "\n",
      "Best Parameters - {'n_estimators': 64, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      "Accuracy Score - 0.5428571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_ADC_sm_pca_loaded  = joblib.load(\"RSCV_ADC_sm_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_sm_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_sm_pca_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_ADC_sm_pca_loaded.predict(X_pca_test_sm1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_sm.pkl']"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_sm = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_sm, \"RSCV_ADC_svc_sm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on SMOTE OverSampled Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.6258912916423144\n",
      "\n",
      "Accuracy Score : 0.6228571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on SMOTE OverSampled Dataset\")\n",
    "RSCV_ADC_svc_sm_loaded  = joblib.load(\"RSCV_ADC_svc_sm.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_sm_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_sm_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_pca_sm.pkl']"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_sm = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_sm, \"RSCV_ADC_svc_pca_sm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.6224430157802454\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_sm_loaded  = joblib.load(\"RSCV_ADC_svc_pca_sm.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_sm_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_sm_loaded.predict(X_pca_test_sm1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTE OverSampled Dataset\n",
    "random_svc_sm = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_svc_sm, \"RSCV_SVC_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled Dataset\")\n",
    "RSCV_SVC_sm_loaded  = joblib.load(\"RSCV_SVC_sm.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_sm_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_sm_loaded.predict(X_test)))\n",
    "\n",
    "random_svc_sm_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_sm_pca.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_svc_sm_pca, \"RSCV_SVC_sm_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_SVC_sm_pca_loaded  = joblib.load(\"RSCV_SVC_sm_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_sm_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_sm_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_sm_pca_loaded.predict(X_pca_test_sm1)))\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On SMOTE OverSampled\n",
    "\n",
    "random_logreg_sm = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_logreg_sm, \"RSCV_LR_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTE OverSampled Dataset\")\n",
    "RSCV_LR_sm_loaded  = joblib.load(\"RSCV_LR_sm.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_sm_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_sm_loaded.predict(X_test)))\n",
    "\n",
    "random_logreg_pca_sm = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_logreg_pca_sm, \"RSCV_LR_pca_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_LR_pca_sm_loaded  = joblib.load(\"RSCV_LR_pca_sm.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_sm_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_sm_loaded.predict(X_pca_test_sm1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for RandomForest On SMOTE OverSampled Dataset\n",
    "\n",
    "random_rf_sm = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_rf_sm, \"RSCV_RF_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF with SMOTE OverSampled Dataset\")\n",
    "RSCV_RF_sm_loaded  = joblib.load(\"RSCV_RF_sm.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_sm_loaded .best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_sm_loaded .best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_sm_loaded.predict(X_test)))\n",
    "\n",
    "random_rf_pca_sm = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_rf_pca_sm, \"RSCV_RF_pca_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF on SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_RF_pca_sm_loaded  = joblib.load(\"RSCV_RF_pca_sm.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_sm_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_sm_loaded.predict(X_pca_test_sm1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTE OverSampled Dataset\n",
    "\n",
    "clf_gbc_sm = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(clf_gbc_sm,'RSCV_GBC_sm.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with SMOTE OverSampled Dataset\")\n",
    "RSCV_GBC_sm_loaded  = joblib.load(\"RSCV_GBC_sm.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_sm_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_sm_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_sm_loaded.predict(X_test)))\n",
    "\n",
    "#X_train_sm1, X_test, y_train_sm1, y_test\n",
    "#X_pca_train_sm1, X_pca_test_sm1, y_train_sm1, y_test\n",
    "\n",
    "clf_gbc_pca_sm = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_sm,'RSCV_GBC_pca_sm.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_sm_loaded  = joblib.load(\"RSCV_GBC_pca_sm.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_sm_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_sm_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_sm_loaded.predict(X_pca_test_sm1)))\n",
    "\n",
    "\n",
    "#Hyperparameter for AdaBoost Classifier On SMOTE OverSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_sm = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_sm, \"RSCV_ADC_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_ADC_sm_loaded  = joblib.load(\"RSCV_ADC_sm.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_sm_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_sm_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_sm_loaded.predict(X_test)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA SMOTE OverSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_sm_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_sm_pca.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_sm_pca, \"RSCV_ADC_sm_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_ADC_sm_pca_loaded  = joblib.load(\"RSCV_ADC_sm_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_sm_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_sm_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_sm_pca_loaded.predict(X_pca_test_sm1)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_sm = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_sm.fit(X_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_sm, \"RSCV_ADC_svc_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SVC on SMOTE OverSampled Dataset\")\n",
    "RSCV_ADC_svc_sm_loaded  = joblib.load(\"RSCV_ADC_svc_sm.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_sm_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_sm_loaded.predict(X_test)))\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_sm = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_sm.fit(X_pca_train_sm1, y_train_sm1.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_sm, \"RSCV_ADC_svc_pca_sm.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTE OverSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_sm_loaded  = joblib.load(\"RSCV_ADC_svc_pca_sm.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_sm_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_sm_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_sm_loaded.predict(X_pca_test_sm1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"enn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Dataset Distribution \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After SMOTE Over Sampling\n",
      "\n",
      "1.0    117\n",
      "0.0    114\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Edited Nearest Neighbor Under Sampling \n",
    "enn = EditedNearestNeighbours(sampling_strategy='majority')\n",
    "X_train_enn, y_train_enn = enn.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution \\n\")\n",
    "print(y_train[\"is_patient\"].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After SMOTE Over Sampling\\n\")\n",
    "print(pd.Series(y_train_enn).value_counts())\n",
    "X_train_enn = pd.DataFrame(X_train_enn)\n",
    "y_train_enn = pd.DataFrame(y_train_enn)\n",
    "y_train_enn = y_train_enn.rename(columns = {0:'is_patient'})\n",
    "\n",
    "\n",
    "X_temp_enn = pd.concat([X_train_enn, y_train_enn], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_enn = X_temp_enn.sample(frac=1, random_state=1)\n",
    "X_train_enn  = X_temp_enn.drop([\"is_patient\"], axis=1)\n",
    "y_train_enn  = X_temp_enn[[\"is_patient\"]]\n",
    "\n",
    "\n",
    "X_enn = pd.concat([X_train_enn, X_test], axis=0)\n",
    "y_enn = pd.concat([y_train_enn, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46449406 0.1855652 ]\n",
      "[0.46449406 0.65005927]\n",
      "1.0    117\n",
      "0.0    114\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for ENN Under Sampled Dataset\n",
    "pca_enn = PCA(n_components=2)\n",
    "X_pca_enn = pca_enn.fit_transform(X_train_enn)\n",
    "print(pca_enn.explained_variance_ratio_)\n",
    "print(pca_enn.explained_variance_ratio_.cumsum())\n",
    "y_temp_enn = y_train_enn\n",
    "y_temp_enn[\"PC1\"] = X_pca_enn[:,0]\n",
    "y_temp_enn[\"PC2\"] = X_pca_enn[:,1]\n",
    "sns.scatterplot(data=y_temp_enn, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_enn[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "78          0.0 -0.237062 -0.052460\n",
      "150         1.0  0.812853 -0.176968\n",
      "171         1.0 -0.209677 -0.137952\n",
      "228         1.0 -0.217630 -0.091505\n",
      "190         1.0 -0.182964 -0.263602\n",
      "     is_patient\n",
      "78          0.0\n",
      "150         1.0\n",
      "171         1.0\n",
      "228         1.0\n",
      "190         1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_enn.head())\n",
    "\n",
    "y_train_enn = y_train_enn.drop([\"PC1\", \"PC2\"], axis=1)\n",
    "print(y_train_enn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient\n",
      "78          0.0\n",
      "150         1.0\n",
      "171         1.0\n",
      "228         1.0\n",
      "190         1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_enn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ninth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on ENN Undersampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[45 80]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5257142857142857\n",
      "Sensitivity : 0.36\n",
      "Precision: 0.9375\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5202312138728323\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.36      0.52       125\n",
      "         1.0       0.37      0.94      0.53        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.65      0.65      0.53       175\n",
      "weighted avg       0.78      0.53      0.52       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on ENN Under sampled Training dataset:\n",
      "[0.85294118 0.74509804 0.59405941 0.61386139] \n",
      "\n",
      "0.7014900019413707\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On ENN Undersampled Training dataset\n",
    "print(\"Naive Bayes on ENN Undersampled Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on ENN Undersampled Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on ENN Under sampled Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on ENN Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[55 70]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5771428571428572\n",
      "Sensitivity : 0.44\n",
      "Precision: 0.9322033898305084\n",
      "Specificity : 0.92\n",
      "F-Score : 0.5978260869565217\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.44      0.60       125\n",
      "         1.0       0.40      0.92      0.55        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.66      0.68      0.58       175\n",
      "weighted avg       0.78      0.58      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on ENN Undersample Training dataset:\n",
      "[0.81372549 0.81372549 0.66336634 0.66336634] \n",
      "\n",
      "0.738545913414871\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On ENN UnderSampled Training dataset\n",
    "print(\"SVM Classifier on ENN Undersample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on ENN Undersampled Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on ENN Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.9344262295081968\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6129032258064516\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.46      0.61       125\n",
      "         1.0       0.40      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.67      0.69      0.59       175\n",
      "weighted avg       0.78      0.59      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on ENN Undersample Training dataset:\n",
      "[0.75490196 0.76470588 0.61386139 0.67326733] \n",
      "\n",
      "0.7016841390021356\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On ENN Undersampled Training dataset\n",
    "print(\"Logistic Regression Classifier on ENN Undersample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on ENN Undersampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on ENN undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8068181818181818\n",
      "Specificity : 0.66\n",
      "F-Score : 0.6666666666666666\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.57      0.67       125\n",
      "         1.0       0.38      0.66      0.48        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.59      0.61      0.57       175\n",
      "weighted avg       0.68      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on ENN Undersample Training dataset:\n",
      "[0.74509804 0.70588235 0.6039604  0.67326733] \n",
      "\n",
      "0.6820520287322851\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On ENN Undersample Training dataset\n",
    "print(\"KNN Classifier on ENN undersample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on ENN Undersampled Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on ENN Undersample Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[61 64]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.488\n",
      "Precision: 0.9242424242424242\n",
      "Specificity : 0.9\n",
      "F-Score : 0.6387434554973821\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.49      0.64       125\n",
      "         1.0       0.41      0.90      0.57        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.67      0.69      0.60       175\n",
      "weighted avg       0.78      0.61      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on ENN Undersample Training dataset:\n",
      "[0.83333333 0.80392157 0.69306931 0.6039604 ] \n",
      "\n",
      "0.7335711512327704\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On ENN Under Sampled Training dataset\n",
    "print(\"Random Forest Classifier on ENN Undersample Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on ENN Under sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on ENN Under sampled Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.9230769230769231\n",
      "Specificity : 0.9\n",
      "F-Score : 0.631578947368421\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.48      0.63       125\n",
      "         1.0       0.41      0.90      0.56        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.67      0.69      0.60       175\n",
      "weighted avg       0.78      0.60      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on ENN Under sampled Training dataset:\n",
      "[0.81372549 0.80392157 0.69306931 0.65346535] \n",
      "\n",
      "0.7410454280722191\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for ENN UnderSampled Training Dataset\n",
    "print(\"Voting Classifier on ENN Under sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on ENN Under sampled Training dataset:\")\n",
    "crossValidation(vclf, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On ENN Undersampled Training dataset\n",
    "print(\"Naive Bayes on ENN Undersampled Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on ENN Undersampled Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on ENN Under sampled Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On ENN UnderSampled Training dataset\n",
    "print(\"SVM Classifier on ENN Undersample Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on ENN Undersampled Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On ENN Undersampled Training dataset\n",
    "print(\"Logistic Regression Classifier on ENN Undersample Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on ENN Undersampled Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On ENN Undersample Training dataset\n",
    "print(\"KNN Classifier on ENN undersample Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on ENN Undersampled Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On ENN Under Sampled Training dataset\n",
    "print(\"Random Forest Classifier on ENN Undersample Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on ENN Under sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for ENN UnderSampled Training Dataset\n",
    "print(\"Voting Classifier on ENN Under sampled Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on ENN Under sampled Training dataset:\")\n",
    "crossValidation(vclf, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on ENN UnderSampled Training datset\n",
    "\n",
    "dt_enn = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_enn = AdaBoostClassifier(base_estimator=dt_enn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on ENN UnderSampled Training datset:\")\n",
    "clfFitPredict(adb_clf_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on ENN UnderSampled Training datset:\")\n",
    "crossValidation(adb_clf_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_enn = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_enn = AdaBoostClassifier(base_estimator=svc_adb_enn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on ENN UnderSampled Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on ENN UnderSampled Training datset:\")\n",
    "crossValidation(adb_clf_svc_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On ENN UnderSampled Training datset\n",
    "\n",
    "gbc_enn = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the ENN UnderSampled Training datset:\")\n",
    "clfFitPredict(gbc_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on ENN UnderSampled Training datset:\")\n",
    "crossValidation(gbc_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the ENN UnderSampled Training datset\n",
    "\n",
    "xgb_clf_enn = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the ENN OverSampled dataset:\")\n",
    "clfFitPredict(xgb_clf_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on ENN UnderSampled Training datset:\")\n",
    "crossValidation(xgb_clf_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on ENN UnderSampled Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.9523809523809523\n",
      "Specificity : 0.94\n",
      "F-Score : 0.6382978723404255\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.48      0.64       125\n",
      "         1.0       0.42      0.94      0.58        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.69      0.71      0.61       175\n",
      "weighted avg       0.80      0.61      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on ENN UnderSampled Training datset:\n",
      "[0.84313725 0.75490196 0.72277228 0.6039604 ] \n",
      "\n",
      "0.7311929722384004\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on ENN UnderSampled Training datset\n",
    "\n",
    "dt_enn = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_enn = AdaBoostClassifier(base_estimator=dt_enn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on ENN UnderSampled Training datset:\")\n",
    "clfFitPredict(adb_clf_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on ENN UnderSampled Training datset:\")\n",
    "crossValidation(adb_clf_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on ENN UnderSampled Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[62 63]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.496\n",
      "Precision: 0.9393939393939394\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6492146596858639\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.50      0.65       125\n",
      "         1.0       0.42      0.92      0.58        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.68      0.71      0.61       175\n",
      "weighted avg       0.79      0.62      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on ENN UnderSampled Training datset:\n",
      "[0.76470588 0.71568627 0.63366337 0.68316832] \n",
      "\n",
      "0.6993059600077656\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_enn = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_enn = AdaBoostClassifier(base_estimator=svc_adb_enn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on ENN UnderSampled Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on ENN UnderSampled Training datset:\")\n",
    "crossValidation(adb_clf_svc_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the ENN UnderSampled Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.8823529411764706\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6217616580310881\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.48      0.62       125\n",
      "         1.0       0.39      0.84      0.54        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.64      0.66      0.58       175\n",
      "weighted avg       0.74      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on ENN UnderSampled Training datset:\n",
      "[0.81372549 0.78431373 0.67326733 0.59405941] \n",
      "\n",
      "0.7163414870898855\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On ENN UnderSampled Training datset\n",
    "\n",
    "gbc_enn = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the ENN UnderSampled Training datset:\")\n",
    "clfFitPredict(gbc_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on ENN UnderSampled Training datset:\")\n",
    "crossValidation(gbc_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the ENN UnderSampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 17 108]\n",
      " [  1  49]]\n",
      "\n",
      "Accuracy : 0.37714285714285717\n",
      "Sensitivity : 0.136\n",
      "Precision: 0.9444444444444444\n",
      "Specificity : 0.98\n",
      "F-Score : 0.2377622377622378\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.14      0.24       125\n",
      "         1.0       0.31      0.98      0.47        50\n",
      "\n",
      "    accuracy                           0.38       175\n",
      "   macro avg       0.63      0.56      0.36       175\n",
      "weighted avg       0.76      0.38      0.31       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on ENN UnderSampled Training datset:\n",
      "[0.58823529 0.58823529 0.59405941 0.58415842] \n",
      "\n",
      "0.5886721025043681\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the ENN UnderSampled Training datset\n",
    "\n",
    "xgb_clf_enn = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the ENN UnderSampled dataset:\")\n",
    "clfFitPredict(xgb_clf_enn, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on ENN UnderSampled Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on ENN UnderSampled Training datset:\")\n",
    "crossValidation(xgb_clf_enn, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bagging Classifier On the ENN OverSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on ENN OverSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on ENN OverSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on ENN OverSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_enn, y_enn, 4)\n",
    "#X_train_enn, X_test, y_train_enn, y_test\n",
    "#X_enn, y_enn\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On ENN OverSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_enn, X_test, y_train_enn, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On ENN OverSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_enn, y_enn, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The ENN OverSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on ENN OverSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on ENN OverSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on ENN OverSampled dataset :\")\n",
    "crossValidation(clf_percept, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on ENN UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8717948717948718\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6699507389162562\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.54      0.67       125\n",
      "         1.0       0.41      0.80      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.64      0.67      0.61       175\n",
      "weighted avg       0.74      0.62      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on ENN UnderSampled dataset :\n",
      "[0.73529412 0.79411765 0.66336634 0.67326733] \n",
      "\n",
      "0.7165113570180548\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On ENN UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8717948717948718\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6699507389162562\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.54      0.67       125\n",
      "         1.0       0.41      0.80      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.64      0.67      0.61       175\n",
      "weighted avg       0.74      0.62      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On ENN UnderSampled Dataset\n",
      "[0.73529412 0.79411765 0.66336634 0.67326733] \n",
      "\n",
      "0.7165113570180548\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On ENN UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6914285714285714\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.9080459770114943\n",
      "Specificity : 0.84\n",
      "F-Score : 0.7452830188679246\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.63      0.75       125\n",
      "         1.0       0.48      0.84      0.61        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.69      0.74      0.68       175\n",
      "weighted avg       0.78      0.69      0.71       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On ENN UnderSampled Dataset\n",
      "[0.69607843 0.82352941 0.64356436 0.71287129] \n",
      "\n",
      "0.7190108716754029\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On ENN UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.8928571428571429\n",
      "Specificity : 0.88\n",
      "F-Score : 0.5524861878453039\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.40      0.55       125\n",
      "         1.0       0.37      0.88      0.52        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.63      0.64      0.54       175\n",
      "weighted avg       0.74      0.54      0.54       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On ENN UnderSampled Dataset\n",
      "[0.82352941 0.83333333 0.62376238 0.64356436] \n",
      "\n",
      "0.7310473694428267\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On ENN UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9122807017543859\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5714285714285714\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.42      0.57       125\n",
      "         1.0       0.38      0.90      0.54        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.65      0.66      0.55       175\n",
      "weighted avg       0.76      0.55      0.56       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On ENN UnderSampled Dataset\n",
      "[0.7745098  0.82352941 0.66336634 0.69306931] \n",
      "\n",
      "0.7386187148126577\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On ENN UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[62 63]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.496\n",
      "Precision: 0.9253731343283582\n",
      "Specificity : 0.9\n",
      "F-Score : 0.6458333333333334\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.50      0.65       125\n",
      "         1.0       0.42      0.90      0.57        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.67      0.70      0.61       175\n",
      "weighted avg       0.78      0.61      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On ENN UnderSampled Dataset\n",
      "[0.81372549 0.79411765 0.67326733 0.62376238] \n",
      "\n",
      "0.7262182100562998\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On ENN UnderSampled Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.9344262295081968\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6129032258064516\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.46      0.61       125\n",
      "         1.0       0.40      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.67      0.69      0.59       175\n",
      "weighted avg       0.78      0.59      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On ENN UnderSampled Dataset\n",
      "[0.76470588 0.76470588 0.64356436 0.66336634] \n",
      "\n",
      "0.7090856144437974\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the ENN UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on ENN UnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on ENN UnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on ENN UnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_enn, y_enn, 4)\n",
    "#X_train_enn, X_test, y_train_enn, y_test\n",
    "#X_enn, y_enn\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On ENN UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_enn, X_test, y_train_enn, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On ENN UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_enn, y_enn, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on ENN UnderSampled dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[30 95]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.4514285714285714\n",
      "Sensitivity : 0.24\n",
      "Precision: 0.967741935483871\n",
      "Specificity : 0.98\n",
      "F-Score : 0.38461538461538464\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.24      0.38       125\n",
      "         1.0       0.34      0.98      0.51        50\n",
      "\n",
      "    accuracy                           0.45       175\n",
      "   macro avg       0.65      0.61      0.44       175\n",
      "weighted avg       0.79      0.45      0.42       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on ENN UnderSampled dataset :\n",
      "[0.81372549 0.58823529 0.63366337 0.55445545] \n",
      "\n",
      "0.6475198990487284\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The ENN UnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on ENN UnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_enn, X_test, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on ENN UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on ENN UnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46449406 0.1855652  0.13173475 0.08290068 0.05001515 0.04598093\n",
      " 0.03327105 0.00285449 0.0018379  0.00134578]\n",
      "[0.46449406 0.65005927 0.78179401 0.86469469 0.91470984 0.96069077\n",
      " 0.99396183 0.99681631 0.99865422 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With PCA with ENN Dataset\n",
    "\n",
    "pca_enn_1 = PCA()\n",
    "X_pca_enn_1 = pca_enn_1.fit_transform(X_train_enn)\n",
    "print(pca_enn_1.explained_variance_ratio_)\n",
    "print(pca_enn_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_enn1 = PCA(n_components=6)\n",
    "X_pca_train_enn1 = pd.DataFrame(pca_enn1.fit_transform(X_train_enn))\n",
    "X_pca_test_enn1 = pd.DataFrame(pca_enn1.transform(X_test))\n",
    "\n",
    "X_pca_enn = pd.concat([X_pca_train_enn1, X_pca_test_enn1], axis=0)\n",
    "#print(type(X_pca_train_enn1), type(X_pca_test_enn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on ENN Undersampled PCA Training  dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[44 81]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5028571428571429\n",
      "Sensitivity : 0.352\n",
      "Precision: 0.88\n",
      "Specificity : 0.88\n",
      "F-Score : 0.5028571428571428\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.35      0.50       125\n",
      "         1.0       0.35      0.88      0.50        50\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.62      0.62      0.50       175\n",
      "weighted avg       0.73      0.50      0.50       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on ENN Under sampled PCA Training dataset:\n",
      "[0.75490196 0.7254902  0.57425743 0.59405941] \n",
      "\n",
      "0.6621772471364784\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on ENN Undersample PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[53 72]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.424\n",
      "Precision: 0.9464285714285714\n",
      "Specificity : 0.94\n",
      "F-Score : 0.585635359116022\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.42      0.59       125\n",
      "         1.0       0.39      0.94      0.56        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.67      0.68      0.57       175\n",
      "weighted avg       0.79      0.57      0.58       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on ENN Undersample PCA Trained dataset:\n",
      "[0.78431373 0.83333333 0.62376238 0.69306931] \n",
      "\n",
      "0.7336196854979615\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on ENN Undersample PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.9344262295081968\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6129032258064516\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.46      0.61       125\n",
      "         1.0       0.40      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.67      0.69      0.59       175\n",
      "weighted avg       0.78      0.59      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on ENN Undersample PCA Trained dataset:\n",
      "[0.75490196 0.79411765 0.62376238 0.67326733] \n",
      "\n",
      "0.7115123277033586\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on ENN undersample PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [13 37]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8452380952380952\n",
      "Specificity : 0.74\n",
      "F-Score : 0.6794258373205742\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.57      0.68       125\n",
      "         1.0       0.41      0.74      0.52        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.63      0.65      0.60       175\n",
      "weighted avg       0.72      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on ENN Undersample Training dataset:\n",
      "[0.73529412 0.70588235 0.57425743 0.65346535] \n",
      "\n",
      "0.6672248107163659\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on ENN Undersample PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[65 60]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.52\n",
      "Precision: 0.9027777777777778\n",
      "Specificity : 0.86\n",
      "F-Score : 0.6598984771573604\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.52      0.66       125\n",
      "         1.0       0.42      0.86      0.56        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.66      0.69      0.61       175\n",
      "weighted avg       0.76      0.62      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on ENN Undersample Training dataset:\n",
      "[0.82352941 0.80392157 0.65346535 0.71287129] \n",
      "\n",
      "0.7484469035138808\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on ENN UnderSampled PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.9230769230769231\n",
      "Specificity : 0.9\n",
      "F-Score : 0.631578947368421\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.48      0.63       125\n",
      "         1.0       0.41      0.90      0.56        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.67      0.69      0.60       175\n",
      "weighted avg       0.78      0.60      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on ENN UnderSampled PCA Trained dataset:\n",
      "[0.76470588 0.82352941 0.64356436 0.69306931] \n",
      "\n",
      "0.7312172393709959\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on ENN UnderSampled PCATraining datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[70 55]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.56\n",
      "Precision: 0.875\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6829268292682927\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.56      0.68       125\n",
      "         1.0       0.42      0.80      0.55        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.65      0.68      0.62       175\n",
      "weighted avg       0.75      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on ENN UnderSampled PCA Training datset:\n",
      "[0.84313725 0.80392157 0.66336634 0.63366337] \n",
      "\n",
      "0.7360221316249272\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on ENN UnderSampled PCA Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.6\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.9365079365079365\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6276595744680851\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.47      0.63       125\n",
      "         1.0       0.41      0.92      0.57        50\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.67      0.70      0.60       175\n",
      "weighted avg       0.79      0.60      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on ENN UnderSampled PCA Training datset:\n",
      "[0.76470588 0.70588235 0.6039604  0.68316832] \n",
      "\n",
      "0.6894292370413513\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the ENN UnderSampled PCA Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[62 63]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.496\n",
      "Precision: 0.8857142857142857\n",
      "Specificity : 0.84\n",
      "F-Score : 0.635897435897436\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.50      0.64       125\n",
      "         1.0       0.40      0.84      0.54        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.64      0.67      0.59       175\n",
      "weighted avg       0.75      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on ENN UnderSampled PCA Training datset:\n",
      "[0.75490196 0.78431373 0.64356436 0.67326733] \n",
      "\n",
      "0.7140118423607067\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the ENN UnderSampled PCA dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 21 104]\n",
      " [  1  49]]\n",
      "\n",
      "Accuracy : 0.4\n",
      "Sensitivity : 0.168\n",
      "Precision: 0.9545454545454546\n",
      "Specificity : 0.98\n",
      "F-Score : 0.28571428571428575\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.17      0.29       125\n",
      "         1.0       0.32      0.98      0.48        50\n",
      "\n",
      "    accuracy                           0.40       175\n",
      "   macro avg       0.64      0.57      0.38       175\n",
      "weighted avg       0.77      0.40      0.34       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on ENN UnderSampled PCA Training datset:\n",
      "[0.58823529 0.58823529 0.59405941 0.58415842] \n",
      "\n",
      "0.5886721025043681\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on ENN UnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.8648648648648649\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6432160804020101\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.51      0.64       125\n",
      "         1.0       0.40      0.80      0.53        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.63      0.66      0.59       175\n",
      "weighted avg       0.73      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on ENN UnderSampled PCA dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80392157 0.76470588 0.75247525 0.62376238] \n",
      "\n",
      "0.7362162686856921\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On ENN UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[64 61]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.512\n",
      "Precision: 0.8648648648648649\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6432160804020101\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.51      0.64       125\n",
      "         1.0       0.40      0.80      0.53        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.63      0.66      0.59       175\n",
      "weighted avg       0.73      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On ENN UnderSampled PCA Dataset\n",
      "[0.80392157 0.76470588 0.75247525 0.62376238] \n",
      "\n",
      "0.7362162686856921\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On ENN UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.9516129032258065\n",
      "Specificity : 0.94\n",
      "F-Score : 0.6310160427807486\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.47      0.63       125\n",
      "         1.0       0.42      0.94      0.58        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.68      0.71      0.60       175\n",
      "weighted avg       0.80      0.61      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On ENN UnderSampled PCA Dataset\n",
      "[0.73529412 0.79411765 0.65346535 0.61386139] \n",
      "\n",
      "0.6991846243447875\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On ENN UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9230769230769231\n",
      "Specificity : 0.92\n",
      "F-Score : 0.5423728813559322\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.38      0.54       125\n",
      "         1.0       0.37      0.92      0.53        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.65      0.65      0.54       175\n",
      "weighted avg       0.77      0.54      0.54       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On ENN UnderSampled PCA Dataset\n",
      "[0.78431373 0.85294118 0.63366337 0.66336634] \n",
      "\n",
      "0.7335711512327704\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On ENN UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9285714285714286\n",
      "Specificity : 0.92\n",
      "F-Score : 0.574585635359116\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.42      0.57       125\n",
      "         1.0       0.39      0.92      0.54        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.66      0.67      0.56       175\n",
      "weighted avg       0.77      0.56      0.57       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On ENN UnderSampled PCA Dataset\n",
      "[0.76470588 0.82352941 0.63366337 0.72277228] \n",
      "\n",
      "0.7361677344205009\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On ENN UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.9516129032258065\n",
      "Specificity : 0.94\n",
      "F-Score : 0.6310160427807486\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.47      0.63       125\n",
      "         1.0       0.42      0.94      0.58        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.68      0.71      0.60       175\n",
      "weighted avg       0.80      0.61      0.62       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On ENN UnderSampled PCA Dataset\n",
      "[0.82352941 0.87254902 0.69306931 0.69306931] \n",
      "\n",
      "0.7705542613084837\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On ENN UnderSampled PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[58 67]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.464\n",
      "Precision: 0.9354838709677419\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6203208556149732\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62       125\n",
      "         1.0       0.41      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.67      0.69      0.59       175\n",
      "weighted avg       0.78      0.59      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On ENN UnderSampled PCA Dataset\n",
      "[0.76470588 0.80392157 0.63366337 0.68316832] \n",
      "\n",
      "0.7213647835371773\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on ENN UnderSampled PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[38 87]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.49714285714285716\n",
      "Sensitivity : 0.304\n",
      "Precision: 0.9743589743589743\n",
      "Specificity : 0.98\n",
      "F-Score : 0.46341463414634143\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.30      0.46       125\n",
      "         1.0       0.36      0.98      0.53        50\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.67      0.64      0.50       175\n",
      "weighted avg       0.80      0.50      0.48       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on ENN UnderSampled PCA dataset :\n",
      "[0.83333333 0.78431373 0.59405941 0.61386139] \n",
      "\n",
      "0.7063919627256844\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On ENN Undersampled PCA Training dataset\n",
    "print(\"Naive Bayes on ENN Undersampled PCA Training  dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on ENN Undersampled PCA Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on ENN Under sampled PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On ENN UnderSampled PCA Trained dataset\n",
    "print(\"SVM Classifier on ENN Undersample PCA Trained dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on ENN Undersampled PCA Trained datset\n",
    "print(\"\\nCross Validation of SVM Classifier on ENN Undersample PCA Trained dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On ENN Undersampled PCA Trained dataset\n",
    "print(\"Logistic Regression Classifier on ENN Undersample PCA Trained dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on ENN Undersampled PCA Trained dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on ENN Undersample PCA Trained dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_enn, y_enn, 4)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "#4.1 KNN Classifier On ENN Undersample PCA Trained dataset\n",
    "print(\"KNN Classifier on ENN undersample PCA Trained dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on ENN Undersampled Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On ENN Under Sampled PCA Trained dataset\n",
    "print(\"Random Forest Classifier on ENN Undersample PCA Trained dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on ENN Under sampled Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on ENN Undersample Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for ENN UnderSampled PCA Trained Dataset\n",
    "print(\"Voting Classifier on ENN UnderSampled PCA Trained dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on ENN UnderSampled PCA Trained datset\n",
    "print(\"\\nCross Validation of Voting Classifier on ENN UnderSampled PCA Trained dataset:\")\n",
    "crossValidation(vclf, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on ENN UnderSampled PCA Training datset\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on ENN UnderSampled PCATraining datset:\")\n",
    "clfFitPredict(adb_clf_enn, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on ENN UnderSampled PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on ENN UnderSampled PCA Training datset:\")\n",
    "crossValidation(adb_clf_enn, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on ENN UnderSampled PCA Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_enn, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on ENN UnderSampled PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on ENN UnderSampled PCA Training datset:\")\n",
    "crossValidation(adb_clf_svc_enn, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On ENN UnderSampled PCA Training datset\n",
    "print(\"\\nGradientBoostingClassifier on the ENN UnderSampled PCA Training datset:\")\n",
    "clfFitPredict(gbc_enn, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on ENN UnderSampled PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on ENN UnderSampled PCA Training datset:\")\n",
    "crossValidation(gbc_enn, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the ENN UnderSampled PCA Training datset\n",
    "\n",
    "print(\"\\nXGBClassifier on the ENN UnderSampled PCA dataset:\")\n",
    "clfFitPredict(xgb_clf_enn, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on ENN UnderSampled PCA Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on ENN UnderSampled PCA Training datset:\")\n",
    "crossValidation(xgb_clf_enn, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Bagging Classifier On the ENN UnderSampled PCA Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on ENN UnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on ENN UnderSampled PCA datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on ENN UnderSampled PCA dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On ENN UnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On ENN UnderSampled PCA Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_enn, y_enn, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The ENN UnderSampled PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on ENN UnderSampled PCA dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on ENN UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on ENN UnderSampled PCA dataset :\")\n",
    "crossValidation(clf_percept, X_pca_enn, y_enn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_enn.pkl']"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on ENN UnderSampled Dataset\n",
    "random_svc_enn = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_svc_enn, \"RSCV_SVC_enn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with ENN UnderSampled Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 'auto', 'C': 100}\n",
      "\n",
      "Best Score : 0.861413043478261\n",
      "\n",
      "Accuracy Score : 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled Dataset\")\n",
    "RSCV_SVC_enn_loaded  = joblib.load(\"RSCV_SVC_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_enn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_enn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_enn_pca.pkl']"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_svc_enn_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_enn_pca.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_svc_enn_pca, \"RSCV_SVC_enn_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 'auto', 'C': 100}\n",
      "\n",
      "Best Score : 0.8614130434782608\n",
      "\n",
      "Accuracy Score : 0.5828571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_SVC_enn_pca_loaded  = joblib.load(\"RSCV_SVC_enn_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_enn_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_enn_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_enn_pca_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_enn.pkl']"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On ENN UnderSampled\n",
    "\n",
    "random_logreg_enn = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_logreg_enn, \"RSCV_LR_enn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with ENN UnderSampled Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 50}\n",
      "\n",
      "Best Score : 0.870108695652174\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with ENN UnderSampled Dataset\")\n",
    "RSCV_LR_enn_loaded  = joblib.load(\"RSCV_LR_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_enn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_enn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_enn.pkl']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logreg_pca_enn = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_logreg_pca_enn, \"RSCV_LR_pca_enn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.861413043478261\n",
      "\n",
      "Accuracy Score : 0.6228571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_LR_pca_enn_loaded  = joblib.load(\"RSCV_LR_pca_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_enn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_enn_loaded.predict(X_pca_test_enn1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_enn.pkl']"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On ENN UnderSampled Dataset\n",
    "\n",
    "random_rf_enn = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_rf_enn, \"RSCV_RF_enn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with ENN UnderSampled Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 26.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.8311594202898551\n",
      "\n",
      "Accuracy Score : 0.6228571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with ENN UnderSampled Dataset\")\n",
    "RSCV_RF_enn_loaded  = joblib.load(\"RSCV_RF_enn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_enn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_enn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   22.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_enn.pkl']"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rf_pca_enn = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_rf_pca_enn, \"RSCV_RF_pca_enn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.8050724637681158\n",
      "\n",
      "Accuracy Score : 0.5828571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on ENN UnderSampled PCA Dataset\")\n",
    "RSCV_RF_pca_enn_loaded  = joblib.load(\"RSCV_RF_pca_enn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_enn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_enn_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_enn.pkl']"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On ENN UnderSampled Dataset\n",
    "\n",
    "clf_gbc_enn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(clf_gbc_enn,'RSCV_GBC_enn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with ENN UnderSampled Dataset\n",
      "\n",
      "Best Score : 0.844021739130435\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 1.0, 'min_samples_leaf': 0.1, 'max_depth': 22.0, 'learning_rate': 0.005}\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with ENN UnderSampled Dataset\")\n",
    "RSCV_GBC_enn_loaded  = joblib.load(\"RSCV_GBC_enn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_enn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_enn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_enn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_enn.pkl']"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gbc_pca_enn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_enn,'RSCV_GBC_pca_enn.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Score : 0.8402173913043478\n",
      "\n",
      "Best Parameters : {'n_estimators': 1500, 'min_samples_split': 1.0, 'min_samples_leaf': 0.1, 'max_depth': 22.0, 'learning_rate': 0.005}\n",
      "\n",
      "Accuracy Score : 0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_enn_loaded  = joblib.load(\"RSCV_GBC_pca_enn.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_enn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_enn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_enn_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_enn.pkl']"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier On ENN UnderSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_enn = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_enn, \"RSCV_ADC_enn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.7195652173913043\n",
      "\n",
      "Best Parameters - {'n_estimators': 64, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      "Accuracy Score - 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_enn_loaded  = joblib.load(\"RSCV_ADC_enn.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_enn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_enn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score -\", accuracy_score(y_test, RSCV_ADC_enn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_enn_pca.pkl']"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA ENN UnderSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_enn_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_enn_pca.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_enn_pca, \"RSCV_ADC_enn_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Score - 0.7717391304347826\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_enn_pca_loaded  = joblib.load(\"RSCV_ADC_enn_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_enn_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_enn_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_enn_pca_loaded.predict(X_pca_test_enn1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_enn.pkl']"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_enn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_enn, \"RSCV_ADC_svc_enn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on ENN UnderSampled Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5065217391304347\n",
      "\n",
      "Accuracy Score : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on ENN UnderSampled Dataset\")\n",
    "RSCV_ADC_svc_enn_loaded  = joblib.load(\"RSCV_ADC_svc_enn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_enn_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_enn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_pca_enn.pkl']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_enn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_enn, \"RSCV_ADC_svc_pca_enn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for Adaboost with SVC with ENN UnderSampled PCA Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5065217391304347\n",
      "\n",
      "Accuracy Score : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for Adaboost with SVC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_enn_loaded  = joblib.load(\"RSCV_ADC_svc_pca_enn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_enn_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_enn_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperparameter Tuning for SVC on ENN UnderSampled Dataset\n",
    "random_svc_enn = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_svc_enn, \"RSCV_SVC_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled Dataset\")\n",
    "RSCV_SVC_enn_loaded  = joblib.load(\"RSCV_SVC_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_enn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_enn_loaded.predict(X_test)))\n",
    "\n",
    "random_svc_enn_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_enn_pca.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_svc_enn_pca, \"RSCV_SVC_enn_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_SVC_enn_pca_loaded  = joblib.load(\"RSCV_SVC_enn_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_enn_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_enn_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_enn_pca_loaded.predict(X_pca_test_enn1)))\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On ENN UnderSampled\n",
    "\n",
    "random_logreg_enn = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_logreg_enn, \"RSCV_LR_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with ENN UnderSampled Dataset\")\n",
    "RSCV_LR_enn_loaded  = joblib.load(\"RSCV_LR_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_enn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_enn_loaded.predict(X_test)))\n",
    "\n",
    "random_logreg_pca_enn = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_logreg_pca_enn, \"RSCV_LR_pca_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_LR_pca_enn_loaded  = joblib.load(\"RSCV_LR_pca_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_enn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_enn_loaded.predict(X_pca_test_enn1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for RandomForest On ENN UnderSampled Dataset\n",
    "\n",
    "random_rf_enn = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_rf_enn, \"RSCV_RF_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF with ENN UnderSampled Dataset\")\n",
    "RSCV_RF_enn_loaded  = joblib.load(\"RSCV_RF_enn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_enn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_enn_loaded.predict(X_test)))\n",
    "\n",
    "random_rf_pca_enn = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_rf_pca_enn, \"RSCV_RF_pca_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF on ENN UnderSampled PCA Dataset\")\n",
    "RSCV_RF_pca_enn_loaded  = joblib.load(\"RSCV_RF_pca_enn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_enn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_enn_loaded.predict(X_pca_test_enn1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for GradientBoostingClassifier On ENN UnderSampled Dataset\n",
    "\n",
    "clf_gbc_enn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(clf_gbc_enn,'RSCV_GBC_enn.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with ENN UnderSampled Dataset\")\n",
    "RSCV_GBC_enn_loaded  = joblib.load(\"RSCV_GBC_enn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_enn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_enn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_enn_loaded.predict(X_test)))\n",
    "\n",
    "clf_gbc_pca_enn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_enn,'RSCV_GBC_pca_enn.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_GBC_pca_enn_loaded  = joblib.load(\"RSCV_GBC_pca_enn.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_enn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_enn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_enn_loaded.predict(X_pca_test_enn1)))\n",
    "\n",
    "\n",
    "#Hyperparameter for AdaBoost Classifier On ENN UnderSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_enn = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_enn, \"RSCV_ADC_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_enn_loaded  = joblib.load(\"RSCV_ADC_enn.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_enn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_enn_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_enn_loaded.predict(X_test)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier on PCA ENN UnderSampled Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_enn_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_enn_pca.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_enn_pca, \"RSCV_ADC_enn_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_enn_pca_loaded  = joblib.load(\"RSCV_ADC_enn_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_enn_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_enn_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_enn_pca_loaded.predict(X_pca_test_enn1)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_enn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_enn.fit(X_train_enn, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_enn, \"RSCV_ADC_svc_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SVC on ENN UnderSampled Dataset\")\n",
    "RSCV_ADC_svc_enn_loaded  = joblib.load(\"RSCV_ADC_svc_enn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_enn_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_enn_loaded.predict(X_test)))\n",
    "\n",
    "#X_train_enn, X_test, y_train_enn, y_test\n",
    "#X_pca_train_enn1, X_pca_test_enn1, y_train_enn, y_test\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_enn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_enn.fit(X_pca_train_enn1, y_train_enn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_enn, \"RSCV_ADC_svc_pca_enn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with ENN UnderSampled PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_enn_loaded  = joblib.load(\"RSCV_ADC_svc_pca_enn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_enn_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_enn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_enn_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"smoteenn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Dataset Distribution \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After SMOTEENN Combination Sampling\n",
      "\n",
      "1.0    182\n",
      "0.0    110\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#OverSampling + UnderSampling\n",
    "#SMOTEENN \n",
    " \n",
    "smoteEnn = SMOTEENN(random_state=0)\n",
    "X_train_smoteEnn, y_train_smoteEnn = smoteEnn.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution \\n\")\n",
    "print(y_train[\"is_patient\"].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After SMOTEENN Combination Sampling\\n\")\n",
    "print(pd.Series(y_train_smoteEnn).value_counts())\n",
    "X_train_smoteEnn = pd.DataFrame(X_train_smoteEnn)\n",
    "y_train_smoteEnn = pd.DataFrame(y_train_smoteEnn)\n",
    "y_train_smoteEnn = y_train_smoteEnn.rename(columns = {0:'is_patient'})\n",
    "\n",
    "\n",
    "X_temp_smoteEnn = pd.concat([X_train_smoteEnn, y_train_smoteEnn], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_smoteEnn = X_temp_smoteEnn.sample(frac=1, random_state=1)\n",
    "X_train_smoteEnn  = X_temp_smoteEnn.drop([\"is_patient\"], axis=1)\n",
    "y_train_smoteEnn  = X_temp_smoteEnn[[\"is_patient\"]]\n",
    "\n",
    "\n",
    "X_smoteEnn = pd.concat([X_train_smoteEnn, X_test], axis=0)\n",
    "y_smoteEnn = pd.concat([y_train_smoteEnn, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51873889 0.18483937]\n",
      "[0.51873889 0.70357826]\n",
      "1.0    182\n",
      "0.0    110\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for SMOTEENN Combination Sampling Dataset\n",
    "pca_smoteenn = PCA(n_components=2)\n",
    "X_pca_smoteenn = pca_smoteenn.fit_transform(X_train_smoteEnn)\n",
    "print(pca_smoteenn.explained_variance_ratio_)\n",
    "print(pca_smoteenn.explained_variance_ratio_.cumsum())\n",
    "y_temp_smoteenn = y_train_smoteEnn\n",
    "y_temp_smoteenn[\"PC1\"] = X_pca_smoteenn[:,0]\n",
    "y_temp_smoteenn[\"PC2\"] = X_pca_smoteenn[:,1]\n",
    "sns.scatterplot(data=y_temp_smoteenn, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_smoteenn[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "132         1.0 -0.232828 -0.333678\n",
      "267         1.0 -0.281533 -0.018705\n",
      "266         1.0  0.735765  0.033367\n",
      "62          0.0  0.653135  0.274181\n",
      "110         1.0 -0.225814 -0.453469\n",
      "     is_patient\n",
      "132         1.0\n",
      "267         1.0\n",
      "266         1.0\n",
      "62          0.0\n",
      "110         1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_smoteEnn.head())\n",
    "y_train_smoteEnn = y_train_smoteEnn.drop(['PC1', 'PC2'], axis=1)\n",
    "print(y_train_smoteEnn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tenth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on SMOTEENN Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[46 79]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5314285714285715\n",
      "Sensitivity : 0.368\n",
      "Precision: 0.9387755102040817\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5287356321839081\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.37      0.53       125\n",
      "         1.0       0.37      0.94      0.53        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.66      0.65      0.53       175\n",
      "weighted avg       0.78      0.53      0.53       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on SMOTEENN Combined Training dataset:\n",
      "[0.87179487 0.82051282 0.65811966 0.67241379] \n",
      "\n",
      "0.7557102858826997\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On SMOTEENN Combined Training dataset\n",
    "print(\"Naive Bayes on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on SMOTEENN Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[51 74]\n",
      " [ 2 48]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.408\n",
      "Precision: 0.9622641509433962\n",
      "Specificity : 0.96\n",
      "F-Score : 0.5730337078651685\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.41      0.57       125\n",
      "         1.0       0.39      0.96      0.56        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.68      0.68      0.57       175\n",
      "weighted avg       0.80      0.57      0.57       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on SMOTEENN Combined Training dataset:\n",
      "[0.85470085 0.82905983 0.75213675 0.72413793] \n",
      "\n",
      "0.7900088417329797\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"SVM Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on SMOTEENN Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[51 74]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.408\n",
      "Precision: 0.9444444444444444\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5698324022346368\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57       125\n",
      "         1.0       0.39      0.94      0.55        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.67      0.67      0.56       175\n",
      "weighted avg       0.79      0.56      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on SMOTEENN Combined Training dataset:\n",
      "[0.8034188  0.84615385 0.76923077 0.72413793] \n",
      "\n",
      "0.7857353374594753\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"Logistic Regression Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on SMOTEENN Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[70 55]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.56\n",
      "Precision: 0.7954545454545454\n",
      "Specificity : 0.64\n",
      "F-Score : 0.6572769953051644\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.56      0.66       125\n",
      "         1.0       0.37      0.64      0.47        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.58      0.60      0.56       175\n",
      "weighted avg       0.67      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on SMOTEENN Combined Training dataset:\n",
      "[0.91452991 0.8974359  0.76923077 0.60344828] \n",
      "\n",
      "0.7961612142646626\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"KNN Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTEENN Combined Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on SMOTEENN Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[61 64]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.6057142857142858\n",
      "Sensitivity : 0.488\n",
      "Precision: 0.9242424242424242\n",
      "Specificity : 0.9\n",
      "F-Score : 0.6387434554973821\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.49      0.64       125\n",
      "         1.0       0.41      0.90      0.57        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.67      0.69      0.60       175\n",
      "weighted avg       0.78      0.61      0.62       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on SMOTEENN Combined Training dataset:\n",
      "[0.87179487 0.82905983 0.74358974 0.63793103] \n",
      "\n",
      "0.7705938697318009\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"Random Forest Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on SMOTEENN Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[56 69]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.448\n",
      "Precision: 0.9333333333333333\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6054054054054054\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.45      0.61       125\n",
      "         1.0       0.40      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.67      0.68      0.58       175\n",
      "weighted avg       0.78      0.58      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on SMOTEENN Combined Training dataset:\n",
      "[0.87179487 0.85470085 0.77777778 0.71551724] \n",
      "\n",
      "0.8049476864132037\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for SMOTEENN Combined Training Dataset\n",
    "print(\"Voting Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(vclf, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on SMOTEENN Combined Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.9090909090909091\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5555555555555556\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.40      0.56       125\n",
      "         1.0       0.38      0.90      0.53        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.64      0.65      0.54       175\n",
      "weighted avg       0.76      0.54      0.55       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on SMOTEENN Combined Training datset:\n",
      "[0.88034188 0.83760684 0.72649573 0.6637931 ] \n",
      "\n",
      "0.7770593869731801\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTEENN Combined Training datset\n",
    "\n",
    "dt_smoteEnn = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_smoteEnn = AdaBoostClassifier(base_estimator=dt_smoteEnn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTEENN Combined Training datset:\")\n",
    "clfFitPredict(adb_clf_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(adb_clf_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on SMOTEENN Combined Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[36 89]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.4857142857142857\n",
      "Sensitivity : 0.288\n",
      "Precision: 0.972972972972973\n",
      "Specificity : 0.98\n",
      "F-Score : 0.4444444444444444\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.29      0.44       125\n",
      "         1.0       0.36      0.98      0.52        50\n",
      "\n",
      "    accuracy                           0.49       175\n",
      "   macro avg       0.66      0.63      0.48       175\n",
      "weighted avg       0.80      0.49      0.47       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on SMOTEENN Combined Training datset:\n",
      "[0.81196581 0.81196581 0.71794872 0.73275862] \n",
      "\n",
      "0.7686597406424993\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_smoteEnn = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_smoteEnn = AdaBoostClassifier(base_estimator=svc_adb_smoteEnn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on SMOTEENN Combined Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(adb_clf_svc_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the SMOTEENN Combined Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[59 66]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.5771428571428572\n",
      "Sensitivity : 0.472\n",
      "Precision: 0.8805970149253731\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6145833333333333\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.47      0.61       125\n",
      "         1.0       0.39      0.84      0.53        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.63      0.66      0.57       175\n",
      "weighted avg       0.74      0.58      0.59       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on SMOTEENN Combined Training datset:\n",
      "[0.86324786 0.81196581 0.76923077 0.64655172] \n",
      "\n",
      "0.7727490421455939\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On SMOTEENN Combined Training datset\n",
    "\n",
    "gbc_smoteEnn = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTEENN Combined Training datset:\")\n",
    "clfFitPredict(gbc_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(gbc_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the ENN OverSampled dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  0 125]\n",
      " [  0  50]]\n",
      "\n",
      "Accuracy : 0.2857142857142857\n",
      "Sensitivity : 0.0\n",
      "Precision: nan\n",
      "Specificity : 1.0\n",
      "F-Score : nan\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       125\n",
      "         1.0       0.29      1.00      0.44        50\n",
      "\n",
      "    accuracy                           0.29       175\n",
      "   macro avg       0.14      0.50      0.22       175\n",
      "weighted avg       0.08      0.29      0.13       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on SMOTEENN Combined Training datset:\n",
      "[0.76068376 0.67521368 0.63247863 0.61206897] \n",
      "\n",
      "0.6701112584733273\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the SMOTEENN Combined Training datset\n",
    "\n",
    "xgb_clf_smoteEnn = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the ENN OverSampled dataset:\")\n",
    "clfFitPredict(xgb_clf_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(xgb_clf_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bagging Classifier On the SMOTEENN UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTEENN dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on SMOTEENN datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on SMOTEENN dataset :\")\n",
    "crossValidation(clf_bagging, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "#X_train_smoteEnn, X_test, y_train_smoteEnn, y_test\n",
    "#X_smoteEnn, y_smoteEnn\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTEENN Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTEENN Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_smoteEnn, y_smoteEnn, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The SMOTEENN Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTEENN dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTEENN datset\n",
    "print(\"\\nCross Validation of Perceptron on SMOTEENN dataset :\")\n",
    "crossValidation(clf_percept, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on SMOTEENN dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[69 56]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.552\n",
      "Precision: 0.8214285714285714\n",
      "Specificity : 0.7\n",
      "F-Score : 0.6602870813397129\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.55      0.66       125\n",
      "         1.0       0.38      0.70      0.50        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.60      0.63      0.58       175\n",
      "weighted avg       0.70      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on SMOTEENN dataset :\n",
      "[0.84615385 0.81196581 0.79487179 0.60344828] \n",
      "\n",
      "0.7641099322133804\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On SMOTEENN Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[69 56]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.552\n",
      "Precision: 0.8214285714285714\n",
      "Specificity : 0.7\n",
      "F-Score : 0.6602870813397129\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.55      0.66       125\n",
      "         1.0       0.38      0.70      0.50        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.60      0.63      0.58       175\n",
      "weighted avg       0.70      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On SMOTEENN Dataset\n",
      "[0.84615385 0.81196581 0.79487179 0.60344828] \n",
      "\n",
      "0.7641099322133804\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On SMOTEENN Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[56 69]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5828571428571429\n",
      "Sensitivity : 0.448\n",
      "Precision: 0.9333333333333333\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6054054054054054\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.45      0.61       125\n",
      "         1.0       0.40      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.67      0.68      0.58       175\n",
      "weighted avg       0.78      0.58      0.59       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On SMOTEENN Dataset\n",
      "[0.8974359  0.86324786 0.76068376 0.69827586] \n",
      "\n",
      "0.8049108458591216\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On SMOTEENN Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[48 77]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5428571428571428\n",
      "Sensitivity : 0.384\n",
      "Precision: 0.9411764705882353\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5454545454545454\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.38      0.55       125\n",
      "         1.0       0.38      0.94      0.54        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.66      0.66      0.54       175\n",
      "weighted avg       0.78      0.54      0.54       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On SMOTEENN Dataset\n",
      "[0.88034188 0.86324786 0.76923077 0.69827586] \n",
      "\n",
      "0.8027740937223695\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On SMOTEENN Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[53 72]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.424\n",
      "Precision: 0.9137931034482759\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5792349726775956\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.42      0.58       125\n",
      "         1.0       0.38      0.90      0.54        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.65      0.66      0.56       175\n",
      "weighted avg       0.76      0.56      0.57       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On SMOTEENN Dataset\n",
      "[0.84615385 0.83760684 0.73504274 0.72413793] \n",
      "\n",
      "0.7857353374594754\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On SMOTEENN Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[63 62]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.504\n",
      "Precision: 0.9264705882352942\n",
      "Specificity : 0.9\n",
      "F-Score : 0.6528497409326425\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.50      0.65       125\n",
      "         1.0       0.42      0.90      0.57        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.67      0.70      0.61       175\n",
      "weighted avg       0.78      0.62      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On SMOTEENN Dataset\n",
      "[0.88888889 0.85470085 0.8034188  0.63793103] \n",
      "\n",
      "0.7962348953728264\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On SMOTEENN Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[51 74]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.408\n",
      "Precision: 0.9444444444444444\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5698324022346368\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57       125\n",
      "         1.0       0.39      0.94      0.55        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.67      0.67      0.56       175\n",
      "weighted avg       0.79      0.56      0.56       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On SMOTEENN Dataset\n",
      "[0.83760684 0.85470085 0.76068376 0.71551724] \n",
      "\n",
      "0.7921271735926909\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the SMOTEENN UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTEENN dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on SMOTEENN datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on SMOTEENN dataset :\")\n",
    "crossValidation(clf_bagging, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "#X_train_smoteEnn, X_test, y_train_smoteEnn, y_test\n",
    "#X_smoteEnn, y_smoteEnn\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTEENN Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTEENN Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_smoteEnn, y_smoteEnn, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on SMOTEENN dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[65 60]\n",
      " [ 8 42]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.52\n",
      "Precision: 0.8904109589041096\n",
      "Specificity : 0.84\n",
      "F-Score : 0.6565656565656566\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.52      0.66       125\n",
      "         1.0       0.41      0.84      0.55        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.65      0.68      0.60       175\n",
      "weighted avg       0.75      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on SMOTEENN dataset :\n",
      "[0.74358974 0.78632479 0.55555556 0.71551724] \n",
      "\n",
      "0.7002468317123489\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The SMOTEENN Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTEENN dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTEENN datset\n",
    "print(\"\\nCross Validation of Perceptron on SMOTEENN dataset :\")\n",
    "crossValidation(clf_percept, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On SMOTEENN Combined Training dataset\n",
    "print(\"Naive Bayes on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"SVM Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"Logistic Regression Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"KNN Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTEENN Combined Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On SMOTEENN Combined Training dataset\n",
    "print(\"Random Forest Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for SMOTEENN Combined Training Dataset\n",
    "print(\"Voting Classifier on SMOTEENN Combined Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTEENN Combined Training dataset:\")\n",
    "crossValidation(vclf, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTEENN Combined Training datset\n",
    "\n",
    "dt_smoteEnn = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_smoteEnn = AdaBoostClassifier(base_estimator=dt_smoteEnn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTEENN Combined Training datset:\")\n",
    "clfFitPredict(adb_clf_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(adb_clf_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_smoteEnn = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_smoteEnn = AdaBoostClassifier(base_estimator=svc_adb_smoteEnn, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on SMOTEENN Combined Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(adb_clf_svc_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On SMOTEENN Combined Training datset\n",
    "\n",
    "gbc_smoteEnn = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTEENN Combined Training datset:\")\n",
    "clfFitPredict(gbc_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(gbc_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the SMOTEENN Combined Training datset\n",
    "\n",
    "xgb_clf_smoteEnn = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the ENN OverSampled dataset:\")\n",
    "clfFitPredict(xgb_clf_smoteEnn, X_train_smoteEnn, X_test, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTEENN Combined Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTEENN Combined Training datset:\")\n",
    "crossValidation(xgb_clf_smoteEnn, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Bagging Classifier On the UnderSampled Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on UnderSampled dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on UnderSampled datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on UnderSampled dataset :\")\n",
    "crossValidation(clf_bagging, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_under, X_test, y_train_under, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On UnderSampled Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_under, y_under, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The UnderSampled Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on UnderSampled dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_under, X_test, y_train_under, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on UnderSampled datset\n",
    "print(\"\\nCross Validation of Perceptron on UnderSampled dataset :\")\n",
    "crossValidation(clf_percept, X_under, y_under, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51873889 0.18483937 0.11508746 0.07150545 0.04128101 0.03626424\n",
      " 0.02746602 0.00229828 0.00145974 0.00105953]\n",
      "[0.51873889 0.70357826 0.81866573 0.89017118 0.93145219 0.96771643\n",
      " 0.99518245 0.99748073 0.99894047 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Classification With PCA with SMOTEENN Dataset\n",
    "\n",
    "pca_smoteEnn_1 = PCA()\n",
    "X_pca_smoteEnn_1 = pca_smoteEnn_1.fit_transform(X_train_smoteEnn)\n",
    "print(pca_smoteEnn_1.explained_variance_ratio_)\n",
    "print(pca_smoteEnn_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_smoteEnn1 = PCA(n_components=6)\n",
    "X_pca_train_smoteEnn1 = pd.DataFrame(pca_smoteEnn1.fit_transform(X_train_smoteEnn))\n",
    "X_pca_test_smoteEnn1 = pd.DataFrame(pca_smoteEnn1.transform(X_test))\n",
    "\n",
    "X_pca_smoteEnn = pd.concat([X_pca_train_smoteEnn1, X_pca_test_smoteEnn1], axis=0)\n",
    "#print(type(X_pca_train_enn1), type(X_pca_test_enn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on SMOTEENN PCA Training  dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[49 76]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.5142857142857142\n",
      "Sensitivity : 0.392\n",
      "Precision: 0.8448275862068966\n",
      "Specificity : 0.82\n",
      "F-Score : 0.53551912568306\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.39      0.54       125\n",
      "         1.0       0.35      0.82      0.49        50\n",
      "\n",
      "    accuracy                           0.51       175\n",
      "   macro avg       0.60      0.61      0.51       175\n",
      "weighted avg       0.70      0.51      0.52       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on SMOTEENN PCA Training dataset:\n",
      "[0.74358974 0.79487179 0.66666667 0.5862069 ] \n",
      "\n",
      "0.6978337754199823\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on SMOTEENN PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.9803921568627451\n",
      "Specificity : 0.98\n",
      "F-Score : 0.5681818181818182\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.40      0.57       125\n",
      "         1.0       0.40      0.98      0.56        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.69      0.69      0.57       175\n",
      "weighted avg       0.81      0.57      0.57       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on SMOTEENN PCA Trained dataset:\n",
      "[0.85470085 0.84615385 0.73504274 0.74137931] \n",
      "\n",
      "0.7943191865605659\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on SMOTEENN PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.9433962264150944\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5617977528089887\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.40      0.56       125\n",
      "         1.0       0.39      0.94      0.55        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.66      0.67      0.55       175\n",
      "weighted avg       0.78      0.55      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on SMOTEENN PCA Trained dataset:\n",
      "[0.81196581 0.84615385 0.76923077 0.70689655] \n",
      "\n",
      "0.7835617447686413\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on SMOTEENN PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[69 56]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.5771428571428572\n",
      "Sensitivity : 0.552\n",
      "Precision: 0.7931034482758621\n",
      "Specificity : 0.64\n",
      "F-Score : 0.6509433962264152\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.55      0.65       125\n",
      "         1.0       0.36      0.64      0.46        50\n",
      "\n",
      "    accuracy                           0.58       175\n",
      "   macro avg       0.58      0.60      0.56       175\n",
      "weighted avg       0.67      0.58      0.60       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on SMOTEENN Training dataset:\n",
      "[0.88888889 0.88888889 0.81196581 0.67241379] \n",
      "\n",
      "0.8155393457117595\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on SMOTEENN PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[66 59]\n",
      " [13 37]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.528\n",
      "Precision: 0.8354430379746836\n",
      "Specificity : 0.74\n",
      "F-Score : 0.6470588235294118\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.53      0.65       125\n",
      "         1.0       0.39      0.74      0.51        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.61      0.63      0.58       175\n",
      "weighted avg       0.71      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on SMOTEENN Training dataset:\n",
      "[0.88034188 0.86324786 0.77777778 0.68965517] \n",
      "\n",
      "0.8027556734453286\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on SMOTEENN PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[57 68]\n",
      " [ 7 43]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.456\n",
      "Precision: 0.890625\n",
      "Specificity : 0.86\n",
      "F-Score : 0.6031746031746033\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.46      0.60       125\n",
      "         1.0       0.39      0.86      0.53        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.64      0.66      0.57       175\n",
      "weighted avg       0.75      0.57      0.58       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on SMOTEENN PCA Trained dataset:\n",
      "[0.83760684 0.85470085 0.76923077 0.69827586] \n",
      "\n",
      "0.7899535809018567\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on SMOTEENN PCATraining datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[65 60]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.52\n",
      "Precision: 0.8552631578947368\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6467661691542289\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.52      0.65       125\n",
      "         1.0       0.39      0.78      0.52        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.62      0.65      0.59       175\n",
      "weighted avg       0.72      0.59      0.61       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on SMOTEENN PCA Training datset:\n",
      "[0.84615385 0.85470085 0.75213675 0.6637931 ] \n",
      "\n",
      "0.7791961391099322\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on SMOTEENN PCA Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[38 87]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.49714285714285716\n",
      "Sensitivity : 0.304\n",
      "Precision: 0.9743589743589743\n",
      "Specificity : 0.98\n",
      "F-Score : 0.46341463414634143\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.30      0.46       125\n",
      "         1.0       0.36      0.98      0.53        50\n",
      "\n",
      "    accuracy                           0.50       175\n",
      "   macro avg       0.67      0.64      0.50       175\n",
      "weighted avg       0.80      0.50      0.48       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on SMOTEENN PCA Training datset:\n",
      "[0.77777778 0.82905983 0.72649573 0.74137931] \n",
      "\n",
      "0.7686781609195403\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the SMOTEENN PCA Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[60 65]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.48\n",
      "Precision: 0.7894736842105263\n",
      "Specificity : 0.68\n",
      "F-Score : 0.5970149253731344\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.48      0.60       125\n",
      "         1.0       0.34      0.68      0.46        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.57      0.58      0.53       175\n",
      "weighted avg       0.66      0.54      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on SMOTEENN PCA Training datset:\n",
      "[0.88888889 0.8034188  0.8034188  0.63793103] \n",
      "\n",
      "0.7834143825523137\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the SMOTEENN PCA dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[  0 125]\n",
      " [  0  50]]\n",
      "\n",
      "Accuracy : 0.2857142857142857\n",
      "Sensitivity : 0.0\n",
      "Precision: nan\n",
      "Specificity : 1.0\n",
      "F-Score : nan\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       125\n",
      "         1.0       0.29      1.00      0.44        50\n",
      "\n",
      "    accuracy                           0.29       175\n",
      "   macro avg       0.14      0.50      0.22       175\n",
      "weighted avg       0.08      0.29      0.13       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on SMOTEENN PCA Training datset:\n",
      "[0.72649573 0.64102564 0.61538462 0.56034483] \n",
      "\n",
      "0.6358127026230475\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on SMOTEENN PCA Training dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.8172043010752689\n",
      "Specificity : 0.66\n",
      "F-Score : 0.6972477064220183\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.61      0.70       125\n",
      "         1.0       0.40      0.66      0.50        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.61      0.63      0.60       175\n",
      "weighted avg       0.70      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on SMOTEENN  PCA Training dataset :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84615385 0.81196581 0.79487179 0.60344828] \n",
      "\n",
      "0.7641099322133804\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On SMOTEENN  PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[76 49]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.608\n",
      "Precision: 0.8172043010752689\n",
      "Specificity : 0.66\n",
      "F-Score : 0.6972477064220183\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.61      0.70       125\n",
      "         1.0       0.40      0.66      0.50        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.61      0.63      0.60       175\n",
      "weighted avg       0.70      0.62      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On SMOTEENN  PCA Training Dataset\n",
      "[0.84615385 0.81196581 0.79487179 0.60344828] \n",
      "\n",
      "0.7641099322133804\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On SMOTEENN  PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 1 49]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.9803921568627451\n",
      "Specificity : 0.98\n",
      "F-Score : 0.5681818181818182\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.40      0.57       125\n",
      "         1.0       0.40      0.98      0.56        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.69      0.69      0.57       175\n",
      "weighted avg       0.81      0.57      0.57       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On SMOTEENN  PCA Training Dataset\n",
      "[0.8974359  0.86324786 0.76068376 0.69827586] \n",
      "\n",
      "0.8049108458591216\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On SMOTEENN  PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[50 75]\n",
      " [ 6 44]]\n",
      "\n",
      "Accuracy : 0.5371428571428571\n",
      "Sensitivity : 0.4\n",
      "Precision: 0.8928571428571429\n",
      "Specificity : 0.88\n",
      "F-Score : 0.5524861878453039\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.40      0.55       125\n",
      "         1.0       0.37      0.88      0.52        50\n",
      "\n",
      "    accuracy                           0.54       175\n",
      "   macro avg       0.63      0.64      0.54       175\n",
      "weighted avg       0.74      0.54      0.54       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On SMOTEENN  PCA Training Dataset\n",
      "[0.88034188 0.86324786 0.76923077 0.69827586] \n",
      "\n",
      "0.8027740937223695\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On SMOTEENN  PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[55 70]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5714285714285714\n",
      "Sensitivity : 0.44\n",
      "Precision: 0.9166666666666666\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5945945945945945\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.44      0.59       125\n",
      "         1.0       0.39      0.90      0.55        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.65      0.67      0.57       175\n",
      "weighted avg       0.77      0.57      0.58       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On SMOTEENN  PCA Training Dataset\n",
      "[0.84615385 0.83760684 0.73504274 0.72413793] \n",
      "\n",
      "0.7857353374594754\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On SMOTEENN  PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[67 58]\n",
      " [14 36]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.536\n",
      "Precision: 0.8271604938271605\n",
      "Specificity : 0.72\n",
      "F-Score : 0.6504854368932038\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.54      0.65       125\n",
      "         1.0       0.38      0.72      0.50        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.61      0.63      0.58       175\n",
      "weighted avg       0.70      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On SMOTEENN  PCA Training Dataset\n",
      "[0.88888889 0.85470085 0.8034188  0.63793103] \n",
      "\n",
      "0.7962348953728264\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On SMOTEENN  PCA Training Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 3 47]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9454545454545454\n",
      "Specificity : 0.94\n",
      "F-Score : 0.5777777777777777\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.42      0.58       125\n",
      "         1.0       0.39      0.94      0.55        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.67      0.68      0.57       175\n",
      "weighted avg       0.79      0.57      0.57       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On SMOTEENN  PCA Training Dataset\n",
      "[0.83760684 0.85470085 0.76068376 0.71551724] \n",
      "\n",
      "0.7921271735926909\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on SMOTEENN  PCA Training dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[109  16]\n",
      " [ 37  13]]\n",
      "\n",
      "Accuracy : 0.6971428571428572\n",
      "Sensitivity : 0.872\n",
      "Precision: 0.7465753424657534\n",
      "Specificity : 0.26\n",
      "F-Score : 0.8044280442804429\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.87      0.80       125\n",
      "         1.0       0.45      0.26      0.33        50\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.60      0.57      0.57       175\n",
      "weighted avg       0.66      0.70      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on SMOTEENN  PCA Training dataset :\n",
      "[0.74358974 0.78632479 0.55555556 0.71551724] \n",
      "\n",
      "0.7002468317123489\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On SMOTEENN PCA Training dataset\n",
    "print(\"Naive Bayes on SMOTEENN PCA Training  dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTEENN PCA Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTEENN PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On SMOTEENN PCA Trained dataset\n",
    "print(\"SVM Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTEENN PCA Trained datset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#3.1 Logistic Regression Classifier On SMOTEENN PCA Trained dataset\n",
    "print(\"Logistic Regression Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTEENN PCA Trained dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "#4.1 KNN Classifier On SMOTEENN PCA Trained dataset\n",
    "print(\"KNN Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTEENN Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTEENN Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On SMOTEENN PCA Trained dataset\n",
    "print(\"Random Forest Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTEENN Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTEENN Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for SMOTEENN PCA Trained Dataset\n",
    "print(\"Voting Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTEENN PCA Trained datset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTEENN PCA Trained dataset:\")\n",
    "crossValidation(vclf, X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTEENN PCA Training datset\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTEENN PCATraining datset:\")\n",
    "clfFitPredict(adb_clf_smoteEnn, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "# Cross Validation on AdaBoost Classifier on SMOTEENN PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTEENN PCA Training datset:\")\n",
    "crossValidation(adb_clf_smoteEnn, X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on SMOTEENN PCA Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_smoteEnn, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTEENN PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTEENN PCA Training datset:\")\n",
    "crossValidation(adb_clf_svc_smoteEnn, X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On SMOTEENN PCA Training datset\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTEENN PCA Training datset:\")\n",
    "clfFitPredict(gbc_smoteEnn, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTEENN PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTEENN PCA Training datset:\")\n",
    "crossValidation(gbc_smoteEnn, X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the SMOTEENN PCA Training datset\n",
    "\n",
    "print(\"\\nXGBClassifier on the SMOTEENN PCA dataset:\")\n",
    "clfFitPredict(xgb_clf_smoteEnn, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTEENN PCA Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTEENN PCA Training datset:\")\n",
    "crossValidation(xgb_clf_smoteEnn, X_pca_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "#Bagging Classifier On the SMOTEENN  PCA Training Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTEENN PCA Training dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on SMOTEENN  PCA Training dataset\n",
    "print(\"\\nCross Validation of Bagging Classifier on SMOTEENN  PCA Training dataset :\")\n",
    "crossValidation(clf_bagging, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "#X_train_smoteEnn, X_test, y_train_smoteEnn, y_test\n",
    "#X_smoteEnn, y_smoteEnn\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTEENN  PCA Training Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTEENN  PCA Training Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_smoteEnn, y_smoteEnn, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The SMOTEENN  PCA Training Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTEENN  PCA Training dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTEENN  PCA Training dataset\n",
    "print(\"\\nCross Validation of Perceptron on SMOTEENN  PCA Training dataset :\")\n",
    "crossValidation(clf_percept, X_smoteEnn, y_smoteEnn, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_smoteEnn.pkl']"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTEENN Combination Dataset\n",
    "random_svc_smoteEnn = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_svc_smoteEnn, \"RSCV_SVC_smoteEnn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTEENN Combination Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score : 0.883448275862069\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTEENN Combination Dataset\")\n",
    "RSCV_SVC_smoteEnn_loaded  = joblib.load(\"RSCV_SVC_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteEnn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteEnn_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_smoteEnn_pca.pkl']"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_svc_smoteEnn_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteEnn_pca.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_svc_smoteEnn_pca, \"RSCV_SVC_smoteEnn_pca.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTEENN Combination PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score : 0.8936781609195401\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTEENN Combination PCA Dataset\")\n",
    "RSCV_SVC_smoteEnn_pca_loaded  = joblib.load(\"RSCV_SVC_smoteEnn_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteEnn_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteEnn_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteEnn_pca_loaded.predict(X_pca_test_smoteEnn1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_smoteEnn.pkl']"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On SMOTEENN Combination\n",
    "\n",
    "random_logreg_smoteEnn = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_logreg_smoteEnn, \"RSCV_LR_smoteEnn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTEENN Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l1', 'C': 500}\n",
      "\n",
      "Best Score : 0.900574712643678\n",
      "\n",
      "Accuracy Score : 0.5771428571428572\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTEENN Dataset\")\n",
    "RSCV_LR_smoteEnn_loaded  = joblib.load(\"RSCV_LR_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_smoteEnn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_smoteEnn_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_smoteEnn.pkl']"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logreg_pca_smoteEnn = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_logreg_pca_smoteEnn, \"RSCV_LR_pca_smoteEnn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTEENN PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.861413043478261\n",
      "\n",
      "Accuracy Score : 0.6914285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTEENN PCA Dataset\")\n",
    "RSCV_LR_pca_smoteEnn_loaded  = joblib.load(\"RSCV_LR_pca_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_smoteEnn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_smoteEnn_loaded.predict(X_pca_test_smoteEnn1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_smoteEnn.pkl']"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On SMOTEENN Dataset\n",
    "\n",
    "random_rf_smoteEnn = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_rf_smoteEnn, \"RSCV_RF_smoteEnn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with SMOTEENN Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 26.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.866551724137931\n",
      "\n",
      "Accuracy Score : 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with SMOTEENN Dataset\")\n",
    "RSCV_RF_smoteEnn_loaded  = joblib.load(\"RSCV_RF_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_smoteEnn_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   25.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_smoteEnn.pkl']"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rf_pca_smoteEnn = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_rf_pca_smoteEnn, \"RSCV_RF_pca_smoteEnn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on SMOTEENN PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.8632183908045977\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on SMOTEENN PCA Dataset\")\n",
    "RSCV_RF_pca_smoteEnn_loaded  = joblib.load(\"RSCV_RF_pca_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_smoteEnn_loaded.predict(X_pca_test_smoteEnn1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_smoteEnn.pkl']"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTEENN Dataset\n",
    "\n",
    "clf_gbc_smoteEnn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(clf_gbc_smoteEnn,'RSCV_GBC_smoteEnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with SMOTEENN Dataset\n",
      "\n",
      "Best Score : 0.8937931034482759\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with SMOTEENN Dataset\")\n",
    "RSCV_GBC_smoteEnn_loaded  = joblib.load(\"RSCV_GBC_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_smoteEnn_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_smoteEnn.pkl']"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gbc_pca_smoteEnn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_smoteEnn,'RSCV_GBC_pca_smoteEnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with SMOTEENN PCA Dataset\n",
      "\n",
      "Best Score : 0.9210344827586207\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with SMOTEENN PCA Dataset\")\n",
    "RSCV_GBC_pca_smoteEnn_loaded  = joblib.load(\"RSCV_GBC_pca_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_smoteEnn_loaded.predict(X_pca_test_smoteEnn1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_smoteEnn.pkl']"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier On SMOTEENN Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteEnn = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteEnn, \"RSCV_ADC_smoteEnn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SMOTEENN PCA Dataset\n",
      "\n",
      "Best Score - 0.6598850574712645\n",
      "\n",
      "Best Parameters - {'n_estimators': 16, 'learning_rate': 0.1, 'algorithm': 'SAMME.R'}\n",
      "\n",
      " Accuracy Score - 0.5828571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SMOTEENN PCA Dataset\")\n",
    "RSCV_ADC_smoteEnn_loaded  = joblib.load(\"RSCV_ADC_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_smoteEnn_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteEnn_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_smoteEnn_pca.pkl']"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on SMOTEENN PCA Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteEnn_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteEnn_pca.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteEnn_pca, \"RSCV_ADC_smoteEnn_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SMOTEENN PCA Dataset\n",
      "\n",
      "Best Score - 0.6565517241379311\n",
      "\n",
      "Best Parameters - {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      " Accuracy Score - 0.6457142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SMOTEENN PCA Dataset\")\n",
    "RSCV_ADC_smoteEnn_pca_loaded  = joblib.load(\"RSCV_ADC_smoteEnn_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteEnn_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_smoteEnn_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteEnn_pca_loaded.predict(X_pca_test_smoteEnn1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_smoteEnn.pkl']"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_smoteEnn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_smoteEnn, \"RSCV_ADC_svc_smoteEnn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on SMOTEENN Dataset\n",
      "\n",
      "Best Score : 0.6232183908045977\n",
      "\n",
      "Best Parameter : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Accuracy Score : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on SMOTEENN Dataset\")\n",
    "RSCV_ADC_svc_smoteEnn_loaded  = joblib.load(\"RSCV_ADC_svc_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_smoteEnn_loaded.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_pca_smoteEnn.pkl']"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_smoteEnn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_smoteEnn, \"RSCV_ADC_svc_pca_smoteEnn.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for Adaboost with SVC with SMOTEENN PCA Dataset\n",
      "\n",
      "Best Score : 0.6232183908045977\n",
      "\n",
      "Best Parameter : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Accuracy Score : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for Adaboost with SVC with SMOTEENN PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_smoteEnn_loaded  = joblib.load(\"RSCV_ADC_svc_pca_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_smoteEnn_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTEENN Combination Dataset\n",
    "random_svc_smoteEnn = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_svc_smoteEnn, \"RSCV_SVC_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTEENN Combination Dataset\")\n",
    "RSCV_SVC_smoteEnn_loaded  = joblib.load(\"RSCV_SVC_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteEnn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteEnn_loaded.predict(X_test)))\n",
    "\n",
    "random_svc_smoteEnn_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteEnn_pca.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_svc_smoteEnn_pca, \"RSCV_SVC_smoteEnn_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTEENN Combination PCA Dataset\")\n",
    "RSCV_SVC_smoteEnn_pca_loaded  = joblib.load(\"RSCV_SVC_smoteEnn_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteEnn_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteEnn_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteEnn_pca_loaded.predict(X_pca_test_smoteEnn1)))\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On SMOTEENN Combination\n",
    "\n",
    "random_logreg_smoteEnn = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_logreg_smoteEnn, \"RSCV_LR_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTEENN Dataset\")\n",
    "RSCV_LR_smoteEnn_loaded  = joblib.load(\"RSCV_LR_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_smoteEnn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_smoteEnn_loaded.predict(X_test)))\n",
    "\n",
    "random_logreg_pca_smoteEnn = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_logreg_pca_smoteEnn, \"RSCV_LR_pca_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTEENN PCA Dataset\")\n",
    "RSCV_LR_pca_smoteEnn_loaded  = joblib.load(\"RSCV_LR_pca_enn.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_smoteEnn_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_smoteEnn_loaded.predict(X_pca_test_smoteEnn1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for RandomForest On SMOTEENN Dataset\n",
    "\n",
    "random_rf_smoteEnn = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_rf_smoteEnn, \"RSCV_RF_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF with SMOTEENN Dataset\")\n",
    "RSCV_RF_smoteEnn_loaded  = joblib.load(\"RSCV_RF_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_smoteEnn_loaded.predict(X_test)))\n",
    "\n",
    "random_rf_pca_smoteEnn = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_rf_pca_smoteEnn, \"RSCV_RF_pca_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF on SMOTEENN PCA Dataset\")\n",
    "RSCV_RF_pca_smoteEnn_loaded  = joblib.load(\"RSCV_RF_pca_smoteEnn.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_smoteEnn_loaded.predict(X_pca_test_smoteEnn1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTEENN Dataset\n",
    "\n",
    "clf_gbc_smoteEnn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(clf_gbc_smoteEnn,'RSCV_GBC_smoteEnn.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with SMOTEENN Dataset\")\n",
    "RSCV_GBC_smoteENN_loaded  = joblib.load(\"RSCV_GBC_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_smoteEnn_loaded.predict(X_test)))\n",
    "\n",
    "clf_gbc_pca_smoteEnn = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_smoteEnn,'RSCV_GBC_pca_smoteEnn.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with SMOTEENN PCA Dataset\")\n",
    "RSCV_GBC_pca_smoteEnn_loaded  = joblib.load(\"RSCV_GBC_pca_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_smoteEnn_loaded.predict(X_pca_test_smoteEnn1)))\n",
    "\n",
    "\n",
    "#Hyperparameter for AdaBoost Classifier On SMOTEENN Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteEnn = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteEnn, \"RSCV_ADC_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SMOTEENN PCA Dataset\")\n",
    "RSCV_ADC_smoteEnn_loaded  = joblib.load(\"RSCV_ADC_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_smoteEnn_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteEnn_loaded.predict(X_test)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier on SMOTEENN PCA Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteEnn_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteEnn_pca.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteEnn_pca, \"RSCV_ADC_smoteEnn_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SMOTEENN PCA Dataset\")\n",
    "RSCV_ADC_smoteEnn_pca_loaded  = joblib.load(\"RSCV_ADC_smoteEnn_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteEnn_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_smoteEnn_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteEnn_pca_loaded.predict(X_pca_test_smoteEnn1)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_smoteEnn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_smoteEnn.fit(X_train_smoteEnn, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_smoteEnn, \"RSCV_ADC_svc_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SVC on SMOTEENN Dataset\")\n",
    "RSCV_ADC_svc_smoteEnn_loaded  = joblib.load(\"RSCV_ADC_svc_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_smoteEnn_loaded.predict(X_test)))\n",
    "\n",
    "#X_pca_train_smoteEnn1, X_pca_test_smoteEnn1, y_train_smoteEnn, y_test\n",
    "#X_train_smoteEnn, X_test, y_train_smoteEnn, y_test\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_smoteEnn = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_smoteEnn.fit(X_pca_train_smoteEnn1, y_train_smoteEnn.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_smoteEnn, \"RSCV_ADC_svc_pca_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTEENN PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_smoteEnn_loaded  = joblib.load(\"RSCV_ADC_svc_pca_smoteEnn.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_smoteEnn_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_smoteEnn_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_smoteEnn_loaded.predict(X_pca_test_enn1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"smotetomek\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Dataset Distribution \n",
      "\n",
      "0.0    291\n",
      "1.0    117\n",
      "Name: is_patient, dtype: int64\n",
      "\n",
      "Training Dataset Distribution After SMOTETomek Combination Sampling\n",
      "\n",
      "0.0    273\n",
      "1.0    273\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#OverSampling + UnderSampling\n",
    "#SMOTETomek\n",
    " \n",
    "smoteTomek = SMOTETomek(random_state=0)\n",
    "X_train_smoteTomek, y_train_smoteTomek = smoteTomek.fit_resample(X_train, y_train.values.ravel())\n",
    "print(\"Original Training Dataset Distribution \\n\")\n",
    "print(y_train[\"is_patient\"].value_counts())\n",
    "print(\"\\nTraining Dataset Distribution After SMOTETomek Combination Sampling\\n\")\n",
    "print(pd.Series(y_train_smoteTomek).value_counts())\n",
    "X_train_smoteTomek = pd.DataFrame(X_train_smoteTomek)\n",
    "y_train_smoteTomek = pd.DataFrame(y_train_smoteTomek)\n",
    "y_train_smoteTomek = y_train_smoteTomek.rename(columns = {0:'is_patient'})\n",
    "\n",
    "\n",
    "X_temp_smoteTomek = pd.concat([X_train_smoteTomek, y_train_smoteTomek], axis=1)\n",
    "#shuffling the training dataset\n",
    "X_temp_smoteTomek = X_temp_smoteTomek.sample(frac=1, random_state=1)\n",
    "X_train_smoteTomek  = X_temp_smoteTomek.drop([\"is_patient\"], axis=1)\n",
    "y_train_smoteTomek  = X_temp_smoteTomek[[\"is_patient\"]]\n",
    "\n",
    "\n",
    "X_smoteTomek = pd.concat([X_train_smoteTomek, X_test], axis=0)\n",
    "y_smoteTomek = pd.concat([y_train_smoteTomek, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55921241 0.17885053]\n",
      "[0.55921241 0.73806294]\n",
      "0.0    273\n",
      "1.0    273\n",
      "Name: is_patient, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/srix/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PCA for SMOTETomek Combination Sampling Dataset\n",
    "pca_smoteTomek = PCA(n_components=2)\n",
    "X_pca_smoteTomek = pca_smoteTomek.fit_transform(X_train_smoteTomek)\n",
    "print(pca_smoteTomek.explained_variance_ratio_)\n",
    "print(pca_smoteTomek.explained_variance_ratio_.cumsum())\n",
    "y_temp_smoteTomek = y_train_smoteTomek\n",
    "y_temp_smoteTomek[\"PC1\"] = X_pca_smoteTomek[:,0]\n",
    "y_temp_smoteTomek[\"PC2\"] = X_pca_smoteTomek[:,1]\n",
    "sns.scatterplot(data=y_temp_smoteTomek, x=\"PC1\", y=\"PC2\", hue=\"is_patient\", alpha=0.4)\n",
    "print(y_temp_smoteTomek[\"is_patient\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     is_patient       PC1       PC2\n",
      "207         1.0  0.718499  0.149035\n",
      "90          1.0 -0.265133  0.084205\n",
      "255         0.0 -0.271702  0.012900\n",
      "453         1.0  0.750203 -0.275672\n",
      "484         1.0 -0.257684 -0.192017\n",
      "     is_patient\n",
      "207         1.0\n",
      "90          1.0\n",
      "255         0.0\n",
      "453         1.0\n",
      "484         1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train_smoteTomek.head())\n",
    "y_train_smoteTomek = y_train_smoteTomek.drop(['PC1', 'PC2'], axis=1)\n",
    "print(y_train_smoteTomek.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eleventh\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Naive Bayes on SMOTETomek Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[52 73]\n",
      " [ 5 45]]\n",
      "\n",
      "Accuracy : 0.5542857142857143\n",
      "Sensitivity : 0.416\n",
      "Precision: 0.9122807017543859\n",
      "Specificity : 0.9\n",
      "F-Score : 0.5714285714285714\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.42      0.57       125\n",
      "         1.0       0.38      0.90      0.54        50\n",
      "\n",
      "    accuracy                           0.55       175\n",
      "   macro avg       0.65      0.66      0.55       175\n",
      "weighted avg       0.76      0.55      0.56       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on SMOTETomek Combined Training dataset:\n",
      "[0.69060773 0.69444444 0.63888889 0.65      ] \n",
      "\n",
      "0.6684852670349908\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#1 Naive Bayes On SMOTETomek Combined Training dataset\n",
    "print(\"Naive Bayes on SMOTETomek Combined Training dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTETomek Combined Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier on SMOTETomek Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[70 55]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.56\n",
      "Precision: 0.8641975308641975\n",
      "Specificity : 0.78\n",
      "F-Score : 0.6796116504854369\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.56      0.68       125\n",
      "         1.0       0.41      0.78      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.64      0.67      0.61       175\n",
      "weighted avg       0.74      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on SMOTETomek Combined Training dataset:\n",
      "[0.71270718 0.69444444 0.67222222 0.67777778] \n",
      "\n",
      "0.6892879066912216\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.1 SVM Classifier On SMOTETomek Combined Training dataset\n",
    "print(\"SVM Classifier on SMOTETomek Combined Training dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTETomek Combined Training dataset:\")\n",
    "crossValidation(LinearSVC(), X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier on SMOTETomek Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8791208791208791\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7407407407407407\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.64      0.74       125\n",
      "         1.0       0.46      0.78      0.58        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.67      0.71      0.66       175\n",
      "weighted avg       0.76      0.68      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on SMOTETomek Combined Training dataset:\n",
      "[0.71823204 0.63333333 0.62777778 0.70555556] \n",
      "\n",
      "0.6712246777163905\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.1 Logistic Regression Classifier On SMOTETomek Combined Training dataset\n",
    "print(\"Logistic Regression Classifier on SMOTETomek Combined Training dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTETomek Combined Training dataset:\")\n",
    "crossValidation(LogisticRegression(), X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier on SMOTETomek Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[97 28]\n",
      " [30 20]]\n",
      "\n",
      "Accuracy : 0.6685714285714286\n",
      "Sensitivity : 0.776\n",
      "Precision: 0.7637795275590551\n",
      "Specificity : 0.4\n",
      "F-Score : 0.7698412698412698\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.78      0.77       125\n",
      "         1.0       0.42      0.40      0.41        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.59      0.59      0.59       175\n",
      "weighted avg       0.66      0.67      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on SMOTETomek Combined Training dataset:\n",
      "[0.77348066 0.75       0.79444444 0.71666667] \n",
      "\n",
      "0.7586479435236342\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.1 KNN Classifier On SMOTETomek Combined Training dataset\n",
    "print(\"KNN Classifier on SMOTETomek Combined Training dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTETomek Combined Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTETomek Combined Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier on SMOTETomek Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6571428571428571\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.8651685393258427\n",
      "Specificity : 0.76\n",
      "F-Score : 0.719626168224299\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.62      0.72       125\n",
      "         1.0       0.44      0.76      0.56        50\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.65      0.69      0.64       175\n",
      "weighted avg       0.74      0.66      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on SMOTETomek Combined Training dataset:\n",
      "[0.73480663 0.73888889 0.68888889 0.68333333] \n",
      "\n",
      "0.7114794352363414\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5.1 Random Forest Classifier On SMOTETomek Combined Training dataset\n",
    "print(\"Random Forest Classifier on SMOTETomek Combined Training dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTETomek Combined Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier on SMOTETomek Combined Training dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[75 50]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.6\n",
      "Precision: 0.872093023255814\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7109004739336493\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.60      0.71       125\n",
      "         1.0       0.44      0.78      0.56        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.66      0.69      0.64       175\n",
      "weighted avg       0.75      0.65      0.67       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on SMOTETomek Combined Training dataset:\n",
      "[0.72928177 0.70555556 0.69444444 0.67777778] \n",
      "\n",
      "0.7017648864333947\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6 Voting Classifier for SMOTETomek Combined Training Dataset\n",
    "print(\"Voting Classifier on SMOTETomek Combined Training dataset:\")\n",
    "clfs = [('rf', RandomForestClassifier(max_depth=4,random_state=1)), ('lr',LogisticRegression()), ('svm',LinearSVC()), \n",
    "       ('nb',GaussianNB())]\n",
    "vclf = VotingClassifier(estimators=clfs, voting='hard')\n",
    "clfFitPredict(vclf, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTETomek Combined Training dataset:\")\n",
    "crossValidation(vclf, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on SMOTETomek Combined Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[77 48]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.616\n",
      "Precision: 0.8191489361702128\n",
      "Specificity : 0.66\n",
      "F-Score : 0.7031963470319635\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.62      0.70       125\n",
      "         1.0       0.41      0.66      0.50        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.61      0.64      0.60       175\n",
      "weighted avg       0.70      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on SMOTETomek Combined Training datset:\n",
      "[0.74033149 0.70555556 0.67777778 0.68333333] \n",
      "\n",
      "0.7017495395948434\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on SMOTETomek Combined Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[85 40]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.68\n",
      "Precision: 0.8415841584158416\n",
      "Specificity : 0.68\n",
      "F-Score : 0.752212389380531\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.68      0.75       125\n",
      "         1.0       0.46      0.68      0.55        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.65      0.68      0.65       175\n",
      "weighted avg       0.73      0.68      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on SMOTETomek Combined Training datset:\n",
      "[0.71823204 0.63888889 0.57222222 0.66666667] \n",
      "\n",
      "0.6490024554941682\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTEENN Combined Training datset\n",
    "\n",
    "dt_smoteTomek = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "adb_clf_smoteTomek = AdaBoostClassifier(base_estimator=dt_smoteTomek, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTETomek Combined Training datset:\")\n",
    "clfFitPredict(adb_clf_smoteTomek, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoost Classifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTETomek Combined Training datset:\")\n",
    "crossValidation(adb_clf_smoteTomek, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "\n",
    "svc_adb_smoteTomek = SVC(probability=True, kernel='linear')\n",
    "adb_clf_svc_smoteTomek = AdaBoostClassifier(base_estimator=svc_adb_smoteTomek, n_estimators=100, learning_rate=0.025)\n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on SMOTETomek Combined Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_smoteTomek, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTETomek Combined Training datset:\")\n",
    "crossValidation(adb_clf_svc_smoteTomek, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradientBoostingClassifier on the SMOTETomek Combined Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [20 30]]\n",
      "\n",
      "Accuracy : 0.6285714285714286\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.8\n",
      "Specificity : 0.6\n",
      "F-Score : 0.7111111111111111\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.64      0.71       125\n",
      "         1.0       0.40      0.60      0.48        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.60      0.62      0.60       175\n",
      "weighted avg       0.69      0.63      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on SMOTETomek Combined Training datset:\n",
      "[0.74585635 0.75555556 0.72777778 0.67222222] \n",
      "\n",
      "0.7253529772866789\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9 GradientBoostingClassifier On SMOTETomek Combined Training datset\n",
    "\n",
    "gbc_smoteTomek = GradientBoostingClassifier(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=0)\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTETomek Combined Training datset:\")\n",
    "clfFitPredict(gbc_smoteTomek, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTETomek Combined Training datset:\")\n",
    "crossValidation(gbc_smoteTomek, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier on the SMOTETomek dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [12 38]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8554216867469879\n",
      "Specificity : 0.76\n",
      "F-Score : 0.6826923076923076\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.57      0.68       125\n",
      "         1.0       0.41      0.76      0.54        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.63      0.66      0.61       175\n",
      "weighted avg       0.73      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on SMOTETomek Combined Training datset:\n",
      "[0.55248619 0.55       0.55       0.55555556] \n",
      "\n",
      "0.5520104358502149\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10 XGBClassifier on the SMOTETomek Combined Training datset\n",
    "\n",
    "xgb_clf_smoteTomek = XGBClassifier(objective='binary:logistic', booster='gblinear', n_estimators=10, seed=1)\n",
    "print(\"\\nXGBClassifier on the SMOTETomek dataset:\")\n",
    "clfFitPredict(xgb_clf_smoteTomek, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTETomek Combined Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTETomek Combined Training datset:\")\n",
    "crossValidation(xgb_clf_smoteTomek, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier on SMOTETomek Combined Training dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[95 30]\n",
      " [33 17]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.76\n",
      "Precision: 0.7421875\n",
      "Specificity : 0.34\n",
      "F-Score : 0.7509881422924901\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.76      0.75       125\n",
      "         1.0       0.36      0.34      0.35        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.55      0.55      0.55       175\n",
      "weighted avg       0.63      0.64      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on SMOTETomek dataset :\n",
      "[0.79005525 0.73888889 0.74444444 0.66111111] \n",
      "\n",
      "0.7336249232658072\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On SMOTETomek Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[95 30]\n",
      " [33 17]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.76\n",
      "Precision: 0.7421875\n",
      "Specificity : 0.34\n",
      "F-Score : 0.7509881422924901\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.76      0.75       125\n",
      "         1.0       0.36      0.34      0.35        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.55      0.55      0.55       175\n",
      "weighted avg       0.63      0.64      0.64       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On SMOTETomek Dataset\n",
      "[0.79005525 0.73888889 0.74444444 0.66111111] \n",
      "\n",
      "0.7336249232658072\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On SMOTETomek Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[58 67]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.5942857142857143\n",
      "Sensitivity : 0.464\n",
      "Precision: 0.9354838709677419\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6203208556149732\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62       125\n",
      "         1.0       0.41      0.92      0.56        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.67      0.69      0.59       175\n",
      "weighted avg       0.78      0.59      0.60       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On SMOTETomek Dataset\n",
      "[0.55248619 0.71666667 0.67777778 0.66666667] \n",
      "\n",
      "0.6533993247391038\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On SMOTETomek Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [20 30]]\n",
      "\n",
      "Accuracy : 0.56\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.7727272727272727\n",
      "Specificity : 0.6\n",
      "F-Score : 0.6384976525821596\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.54      0.64       125\n",
      "         1.0       0.34      0.60      0.44        50\n",
      "\n",
      "    accuracy                           0.56       175\n",
      "   macro avg       0.56      0.57      0.54       175\n",
      "weighted avg       0.65      0.56      0.58       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On SMOTETomek Dataset\n",
      "[0.67955801 0.72777778 0.69444444 0.63888889] \n",
      "\n",
      "0.6851672805402087\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On SMOTETomek Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[71 54]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.6342857142857142\n",
      "Sensitivity : 0.568\n",
      "Precision: 0.8765432098765432\n",
      "Specificity : 0.8\n",
      "F-Score : 0.6893203883495146\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.57      0.69       125\n",
      "         1.0       0.43      0.80      0.56        50\n",
      "\n",
      "    accuracy                           0.63       175\n",
      "   macro avg       0.65      0.68      0.62       175\n",
      "weighted avg       0.75      0.63      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On SMOTETomek Dataset\n",
      "[0.71270718 0.68333333 0.60555556 0.67222222] \n",
      "\n",
      "0.6684545733578884\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On SMOTETomek Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[88 37]\n",
      " [29 21]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.704\n",
      "Precision: 0.7521367521367521\n",
      "Specificity : 0.42\n",
      "F-Score : 0.7272727272727272\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.73       125\n",
      "         1.0       0.36      0.42      0.39        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.56      0.56      0.56       175\n",
      "weighted avg       0.64      0.62      0.63       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On SMOTETomek Dataset\n",
      "[0.79005525 0.81111111 0.77777778 0.66666667] \n",
      "\n",
      "0.761402701043585\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On SMOTETomek Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[82 43]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6914285714285714\n",
      "Sensitivity : 0.656\n",
      "Precision: 0.8817204301075269\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7522935779816514\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.66      0.75       125\n",
      "         1.0       0.48      0.78      0.59        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.68      0.72      0.67       175\n",
      "weighted avg       0.77      0.69      0.71       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On SMOTETomek Dataset\n",
      "[0.6961326  0.63333333 0.62777778 0.7       ] \n",
      "\n",
      "0.6643109269490485\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier On the SMOTETomek Combined Training Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTETomek Combined Training dataset :\")\n",
    "clfFitPredict(clf_bagging, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on SMOTETomek dataset\n",
    "print(\"\\nCross Validation of Bagging Classifier on SMOTETomek dataset :\")\n",
    "crossValidation(clf_bagging, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTETomek Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTETomek Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_smoteTomek, y_smoteTomek, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron on SMOTETomek dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[85 40]\n",
      " [17 33]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.68\n",
      "Precision: 0.8333333333333334\n",
      "Specificity : 0.66\n",
      "F-Score : 0.748898678414097\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.68      0.75       125\n",
      "         1.0       0.45      0.66      0.54        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.64      0.67      0.64       175\n",
      "weighted avg       0.72      0.67      0.69       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on SMOTETomek dataset :\n",
      "[0.64640884 0.55       0.64444444 0.68333333] \n",
      "\n",
      "0.6310466543891959\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perceptron On The SMOTETomek Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTETomek dataset :\")\n",
    "clfFitPredict(clf_percept, X_train_smoteTomek, X_test, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTETomek datset\n",
    "print(\"\\nCross Validation of Perceptron on SMOTETomek dataset :\")\n",
    "crossValidation(clf_percept, X_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55921241 0.73806294 0.8318547  0.91115399 0.94760695 0.97333456\n",
      " 0.99511738 0.99789825 0.99932507 1.        ]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification With PCA with SMOTEENN Dataset\n",
    "\n",
    "pca_smoteTomek_1 = PCA()\n",
    "X_pca_smoteTomek_1 = pca_smoteTomek_1.fit_transform(X_train_smoteTomek)\n",
    "#print(pca_smoteTomek_1.explained_variance_ratio_)\n",
    "print(pca_smoteTomek_1.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_smoteTomek1 = PCA(n_components=6)\n",
    "X_pca_train_smoteTomek1 = pd.DataFrame(pca_smoteTomek1.fit_transform(X_train_smoteTomek))\n",
    "X_pca_test_smoteTomek1 = pd.DataFrame(pca_smoteTomek1.transform(X_test))\n",
    "\n",
    "X_pca_smoteTomek = pd.concat([X_pca_train_smoteTomek1, X_pca_test_smoteTomek1], axis=0)\n",
    "#print(type(X_pca_train_smoteTomek1), type(X_pca_test_smoteTomek1), len(X_pca_smoteTomek))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes on SMOTETomek PCA Training  dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[61 64]\n",
      " [18 32]]\n",
      "\n",
      "Accuracy : 0.5314285714285715\n",
      "Sensitivity : 0.488\n",
      "Precision: 0.7721518987341772\n",
      "Specificity : 0.64\n",
      "F-Score : 0.5980392156862745\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.49      0.60       125\n",
      "         1.0       0.33      0.64      0.44        50\n",
      "\n",
      "    accuracy                           0.53       175\n",
      "   macro avg       0.55      0.56      0.52       175\n",
      "weighted avg       0.65      0.53      0.55       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Naive Bayes on SMOTETomek PCA Training dataset:\n",
      "[0.6961326  0.67222222 0.62777778 0.61111111] \n",
      "\n",
      "0.6518109269490485\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "SVM Classifier on SMOTETomek PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [ 9 41]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8831168831168831\n",
      "Specificity : 0.82\n",
      "F-Score : 0.6732673267326733\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.54      0.67       125\n",
      "         1.0       0.42      0.82      0.55        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.65      0.68      0.61       175\n",
      "weighted avg       0.75      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of SVM Classifier on SMOTETomek PCA Trained dataset:\n",
      "[0.70165746 0.65555556 0.65555556 0.68333333] \n",
      "\n",
      "0.674025475751995\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Logistic Regression Classifier on SMOTETomek PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [10 40]]\n",
      "\n",
      "Accuracy : 0.68\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.8876404494382022\n",
      "Specificity : 0.8\n",
      "F-Score : 0.7383177570093459\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.63      0.74       125\n",
      "         1.0       0.47      0.80      0.59        50\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.68      0.72      0.66       175\n",
      "weighted avg       0.77      0.68      0.70       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Logistic Regression Classifier on SMOTETomek PCA Trained dataset:\n",
      "[0.72928177 0.63888889 0.60555556 0.70555556] \n",
      "\n",
      "0.6698204419889503\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "KNN Classifier on SMOTETomek PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[101  24]\n",
      " [ 31  19]]\n",
      "\n",
      "Accuracy : 0.6857142857142857\n",
      "Sensitivity : 0.808\n",
      "Precision: 0.7651515151515151\n",
      "Specificity : 0.38\n",
      "F-Score : 0.7859922178988327\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.81      0.79       125\n",
      "         1.0       0.44      0.38      0.41        50\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.60      0.59      0.60       175\n",
      "weighted avg       0.67      0.69      0.68       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of KNN Classifier on SMOTETomek Training dataset:\n",
      "[0.77900552 0.75555556 0.77777778 0.72222222] \n",
      "\n",
      "0.7586402701043585\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest Classifier on SMOTETomek PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[80 45]\n",
      " [23 27]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.64\n",
      "Precision: 0.7766990291262136\n",
      "Specificity : 0.54\n",
      "F-Score : 0.7017543859649122\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.64      0.70       125\n",
      "         1.0       0.38      0.54      0.44        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.58      0.59      0.57       175\n",
      "weighted avg       0.66      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Random Forest Classifier on SMOTETomek Training dataset:\n",
      "[0.6961326  0.71666667 0.64444444 0.66666667] \n",
      "\n",
      "0.6809775936157151\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Voting Classifier on SMOTETomek PCA Trained dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[81 44]\n",
      " [22 28]]\n",
      "\n",
      "Accuracy : 0.6228571428571429\n",
      "Sensitivity : 0.648\n",
      "Precision: 0.7864077669902912\n",
      "Specificity : 0.56\n",
      "F-Score : 0.7105263157894738\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.65      0.71       125\n",
      "         1.0       0.39      0.56      0.46        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.59      0.60      0.58       175\n",
      "weighted avg       0.67      0.62      0.64       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Voting Classifier on SMOTETomek PCA Trained dataset:\n",
      "[0.71270718 0.67777778 0.65       0.66666667] \n",
      "\n",
      "0.6767879066912216\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with Decision Tree as base estimator on SMOTETomek PCATraining datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [22 28]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.7821782178217822\n",
      "Specificity : 0.56\n",
      "F-Score : 0.6991150442477877\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.63      0.70       125\n",
      "         1.0       0.38      0.56      0.45        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.58      0.60      0.58       175\n",
      "weighted avg       0.67      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoost Classifier on SMOTETomek PCA Training datset:\n",
      "[0.67403315 0.66666667 0.6        0.68333333] \n",
      "\n",
      "0.6560082872928177\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "AdaBoostClassifier with SVC as base estimator on Tomek PCA Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[62 63]\n",
      " [ 4 46]]\n",
      "\n",
      "Accuracy : 0.6171428571428571\n",
      "Sensitivity : 0.496\n",
      "Precision: 0.9393939393939394\n",
      "Specificity : 0.92\n",
      "F-Score : 0.6492146596858639\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.50      0.65       125\n",
      "         1.0       0.42      0.92      0.58        50\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.68      0.71      0.61       175\n",
      "weighted avg       0.79      0.62      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of AdaBoostClassifier with SVM as base estimator on SMOTETomek PCA Training datset:\n",
      "[0.70718232 0.61666667 0.59444444 0.66111111] \n",
      "\n",
      "0.6448511356660528\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "GradientBoostingClassifier on the SMOTETomek PCA Training datset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[78 47]\n",
      " [21 29]]\n",
      "\n",
      "Accuracy : 0.6114285714285714\n",
      "Sensitivity : 0.624\n",
      "Precision: 0.7878787878787878\n",
      "Specificity : 0.58\n",
      "F-Score : 0.6964285714285714\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.62      0.70       125\n",
      "         1.0       0.38      0.58      0.46        50\n",
      "\n",
      "    accuracy                           0.61       175\n",
      "   macro avg       0.58      0.60      0.58       175\n",
      "weighted avg       0.67      0.61      0.63       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of GradientBoostingClassifier on SMOTETomek PCA Training datset:\n",
      "[0.74585635 0.73888889 0.65555556 0.66111111] \n",
      "\n",
      "0.7003529772866789\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "XGBClassifier on the SMOTETomek PCA dataset:\n",
      "\n",
      "Confusion Matrix: \n",
      "[[90 35]\n",
      " [26 24]]\n",
      "\n",
      "Accuracy : 0.6514285714285715\n",
      "Sensitivity : 0.72\n",
      "Precision: 0.7758620689655172\n",
      "Specificity : 0.48\n",
      "F-Score : 0.7468879668049794\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.72      0.75       125\n",
      "         1.0       0.41      0.48      0.44        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.59      0.60      0.59       175\n",
      "weighted avg       0.67      0.65      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of XGBClassifier on SMOTETomek PCA Training datset:\n",
      "[0.55248619 0.55       0.55       0.55555556] \n",
      "\n",
      "0.5520104358502149\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier on SMOTETomek PCA Training dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[92 33]\n",
      " [29 21]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.736\n",
      "Precision: 0.7603305785123967\n",
      "Specificity : 0.42\n",
      "F-Score : 0.7479674796747968\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75       125\n",
      "         1.0       0.39      0.42      0.40        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.57      0.58      0.58       175\n",
      "weighted avg       0.65      0.65      0.65       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Bagging Classifier on smoteTomek PCA dataset :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79005525 0.77777778 0.72222222 0.65      ] \n",
      "\n",
      "0.7350138121546961\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Decision Tree as base estimator On SMOTETomek PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[92 33]\n",
      " [29 21]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.736\n",
      "Precision: 0.7603305785123967\n",
      "Specificity : 0.42\n",
      "F-Score : 0.7479674796747968\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.74      0.75       125\n",
      "         1.0       0.39      0.42      0.40        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.57      0.58      0.58       175\n",
      "weighted avg       0.65      0.65      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Decision Tree as base estimator On SMOTETomek PCA Dataset\n",
      "[0.79005525 0.77777778 0.72222222 0.65      ] \n",
      "\n",
      "0.7350138121546961\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with Perceptron as base estimator On SMOTETomek PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[78 47]\n",
      " [16 34]]\n",
      "\n",
      "Accuracy : 0.64\n",
      "Sensitivity : 0.624\n",
      "Precision: 0.8297872340425532\n",
      "Specificity : 0.68\n",
      "F-Score : 0.7123287671232877\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.62      0.71       125\n",
      "         1.0       0.42      0.68      0.52        50\n",
      "\n",
      "    accuracy                           0.64       175\n",
      "   macro avg       0.62      0.65      0.62       175\n",
      "weighted avg       0.71      0.64      0.66       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with Perceptron as base estimator On SMOTETomek PCA Dataset\n",
      "[0.57458564 0.65555556 0.67777778 0.67777778] \n",
      "\n",
      "0.6464241866175569\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with KNN as base estimator On SMOTETomek PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[72 53]\n",
      " [23 27]]\n",
      "\n",
      "Accuracy : 0.5657142857142857\n",
      "Sensitivity : 0.576\n",
      "Precision: 0.7578947368421053\n",
      "Specificity : 0.54\n",
      "F-Score : 0.6545454545454545\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.58      0.65       125\n",
      "         1.0       0.34      0.54      0.42        50\n",
      "\n",
      "    accuracy                           0.57       175\n",
      "   macro avg       0.55      0.56      0.53       175\n",
      "weighted avg       0.64      0.57      0.59       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with KNN as base estimator On SMOTETomek PCA Dataset\n",
      "[0.67403315 0.75       0.71666667 0.65      ] \n",
      "\n",
      "0.6976749539594843\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with SVC as base estimator On SMOTETomek PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[68 57]\n",
      " [15 35]]\n",
      "\n",
      "Accuracy : 0.5885714285714285\n",
      "Sensitivity : 0.544\n",
      "Precision: 0.8192771084337349\n",
      "Specificity : 0.7\n",
      "F-Score : 0.6538461538461539\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.54      0.65       125\n",
      "         1.0       0.38      0.70      0.49        50\n",
      "\n",
      "    accuracy                           0.59       175\n",
      "   macro avg       0.60      0.62      0.57       175\n",
      "weighted avg       0.69      0.59      0.61       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with SVC as base estimator On SMOTETomek PCA Dataset\n",
      "[0.66850829 0.69444444 0.61111111 0.65      ] \n",
      "\n",
      "0.6560159607120933\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with RF as base estimator On SMOTETomek PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[90 35]\n",
      " [27 23]]\n",
      "\n",
      "Accuracy : 0.6457142857142857\n",
      "Sensitivity : 0.72\n",
      "Precision: 0.7692307692307693\n",
      "Specificity : 0.46\n",
      "F-Score : 0.743801652892562\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.72      0.74       125\n",
      "         1.0       0.40      0.46      0.43        50\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.58      0.59      0.58       175\n",
      "weighted avg       0.66      0.65      0.65       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with RF as base estimator On SMOTETomek PCA Dataset\n",
      "[0.79005525 0.76666667 0.75       0.69444444] \n",
      "\n",
      "0.750291589932474\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Bagging Classifier with LR as base estimator On SMOTETomek PCA Dataset\n",
      "\n",
      "Confusion Matrix: \n",
      "[[79 46]\n",
      " [11 39]]\n",
      "\n",
      "Accuracy : 0.6742857142857143\n",
      "Sensitivity : 0.632\n",
      "Precision: 0.8777777777777778\n",
      "Specificity : 0.78\n",
      "F-Score : 0.7348837209302325\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.63      0.73       125\n",
      "         1.0       0.46      0.78      0.58        50\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.67      0.71      0.66       175\n",
      "weighted avg       0.76      0.67      0.69       175\n",
      " \n",
      "\n",
      "Cross Validation of Bagging Classifier with LR as base estimator On SMOTETomek PCA Dataset\n",
      "[0.69060773 0.62777778 0.62222222 0.69444444] \n",
      "\n",
      "0.6587630448127686\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Perceptron on SMOTETomek PCA dataset :\n",
      "\n",
      "Confusion Matrix: \n",
      "[[122   3]\n",
      " [ 44   6]]\n",
      "\n",
      "Accuracy : 0.7314285714285714\n",
      "Sensitivity : 0.976\n",
      "Precision: 0.7349397590361446\n",
      "Specificity : 0.12\n",
      "F-Score : 0.8384879725085911\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.98      0.84       125\n",
      "         1.0       0.67      0.12      0.20        50\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.70      0.55      0.52       175\n",
      "weighted avg       0.72      0.73      0.66       175\n",
      " \n",
      "\n",
      "\n",
      "Cross Validation of Perceptron on smoteTomek PCA dataset :\n",
      "[0.59116022 0.67222222 0.67222222 0.63888889] \n",
      "\n",
      "0.6436233885819522\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 Naive Bayes On SMOTETomek PCA Training dataset\n",
    "print(\"Naive Bayes on SMOTETomek PCA Training  dataset:\")\n",
    "clfFitPredict(GaussianNB(), X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Naive Bayes on SMOTETomek PCA Training datset\n",
    "print(\"\\nCross Validation of Naive Bayes on SMOTETomek PCA Training dataset:\")\n",
    "crossValidation(GaussianNB(), X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#2.1 SVM Classifier On SMOTETomek PCA Trained dataset\n",
    "print(\"SVM Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "clfFitPredict(LinearSVC(), X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on SVM Classifier on SMOTETomek PCA Trained datset\n",
    "print(\"\\nCross Validation of SVM Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "crossValidation(LinearSVC(), X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "# 3.1 Logistic Regression Classifier On SMOTETomek PCA Trained dataset\n",
    "print(\"Logistic Regression Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "clfFitPredict(LogisticRegression(), X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Logistic Regression Classifier on SMOTETomek PCA Trained dataset\n",
    "print(\"\\nCross Validation of Logistic Regression Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "crossValidation(LogisticRegression(), X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#4.1 KNN Classifier On SMOTETomek PCA Trained dataset\n",
    "print(\"KNN Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "clfFitPredict(KNeighborsClassifier(n_neighbors = 2), X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on KNN Classifier on SMOTETomek Training dataset\n",
    "print(\"\\nCross Validation of KNN Classifier on SMOTETomek Training dataset:\")\n",
    "crossValidation(KNeighborsClassifier(n_neighbors = 2), X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#5.1 Random Forest Classifier On SMOTETomek PCA Trained dataset\n",
    "print(\"Random Forest Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "clfFitPredict(RandomForestClassifier(max_depth=4, random_state=0), X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Random Forest Classifier on SMOTETomek PCA Training datset\n",
    "print(\"\\nCross Validation of Random Forest Classifier on SMOTETomek Training dataset:\")\n",
    "crossValidation(RandomForestClassifier(max_depth=4, random_state=0), X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#6 Voting Classifier for SMOTETomek PCA Trained Dataset\n",
    "print(\"Voting Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "clfFitPredict(vclf, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Voting Classifier on SMOTETomek PCA Trained datset\n",
    "print(\"\\nCross Validation of Voting Classifier on SMOTETomek PCA Trained dataset:\")\n",
    "crossValidation(vclf, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#7 AdaBoostClassifier With Decision Tree Classifier as base estimator on SMOTETomek PCA Training datset\n",
    "print(\"\\nAdaBoostClassifier with Decision Tree as base estimator on SMOTETomek PCATraining datset:\")\n",
    "clfFitPredict(adb_clf_smoteTomek, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "# Cross Validation on AdaBoost Classifier on SMOTETomek PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoost Classifier on SMOTETomek PCA Training datset:\")\n",
    "crossValidation(adb_clf_smoteTomek, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#8 AdaBoostClassifier With SVC as base estimator \n",
    "print(\"\\nAdaBoostClassifier with SVC as base estimator on Tomek PCA Training datset:\")\n",
    "clfFitPredict(adb_clf_svc_smoteTomek, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on AdaBoostClassifier on SMOTETomek PCA Training datset\n",
    "print(\"\\nCross Validation of AdaBoostClassifier with SVM as base estimator on SMOTETomek PCA Training datset:\")\n",
    "crossValidation(adb_clf_svc_smoteTomek, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#9 GradientBoostingClassifier On SMOTETomek PCA Training datset\n",
    "print(\"\\nGradientBoostingClassifier on the SMOTETomek PCA Training datset:\")\n",
    "clfFitPredict(gbc_smoteTomek, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on GradientBoostingClassifier on SMOTETomek PCA Training datset\n",
    "print(\"\\nCross Validation of GradientBoostingClassifier on SMOTETomek PCA Training datset:\")\n",
    "crossValidation(gbc_smoteTomek, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#10 XGBClassifier on the SMOTETomek PCA Training datset\n",
    "\n",
    "print(\"\\nXGBClassifier on the SMOTETomek PCA dataset:\")\n",
    "clfFitPredict(xgb_clf_smoteTomek, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on XGBClassifier on SMOTETomek PCA Training datset\n",
    "print(\"\\nCross Validation of XGBClassifier on SMOTETomek PCA Training datset:\")\n",
    "crossValidation(xgb_clf_smoteTomek, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "#X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "#X_pca_smoteTomek, y_smoteTomek\n",
    "\n",
    "#Bagging Classifier On the SMOTETomek PCA Training Dataset\n",
    "\n",
    "clf_bagging = BaggingClassifier(random_state=0)\n",
    "print(\"Bagging Classifier on SMOTETomek PCA Training dataset :\")\n",
    "clfFitPredict(clf_bagging, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Bagging Classifier on smoteTomek PCA datset\n",
    "print(\"\\nCross Validation of Bagging Classifier on smoteTomek PCA dataset :\")\n",
    "crossValidation(clf_bagging, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "\n",
    "base_estimators = [DecisionTreeClassifier(), \n",
    "                  Perceptron(), \n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(),\n",
    "                  RandomForestClassifier(),\n",
    "                  LogisticRegression()\n",
    "                 ]\n",
    "\n",
    "base_estimator_names = ['Decision Tree', 'Perceptron', 'KNN', 'SVC', 'RF', 'LR']\n",
    "index = 0\n",
    "for base_estimator in base_estimators:\n",
    "    print(\"Bagging Classifier with {} as base estimator On SMOTETomek PCA Dataset\".format(base_estimator_names[index]))\n",
    "    clf_bagging_temp = BaggingClassifier(base_estimator=base_estimator, random_state=0) \n",
    "    clfFitPredict(clf_bagging_temp, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "    print(\"Cross Validation of Bagging Classifier with {} as base estimator On SMOTETomek PCA Dataset\".format(base_estimator_names[index]))\n",
    "    crossValidation(clf_bagging_temp, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "    print(\"\\n----------------------------------------------------------------------\\n\")\n",
    "    index+=1\n",
    "\n",
    "#Perceptron On The SMOTETomek PCA Dataset\n",
    "\n",
    "clf_percept = Perceptron(tol=0.001, random_state=0)\n",
    "print(\"Perceptron on SMOTETomek PCA dataset :\")\n",
    "clfFitPredict(clf_percept, X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test)\n",
    "\n",
    "#Cross Validation on Perceptron on SMOTETomek PCA dataset\n",
    "print(\"\\nCross Validation of Perceptron on smoteTomek PCA dataset :\")\n",
    "crossValidation(clf_percept, X_pca_smoteTomek, y_smoteTomek, 4)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyper11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_smoteTomek.pkl']"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTETomek Combination Dataset\n",
    "random_svc_smoteTomek = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_svc_smoteTomek, \"RSCV_SVC_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTETomek Combination Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 'auto', 'C': 100}\n",
      "\n",
      "Best Score : 0.7106734006734007\n",
      "\n",
      "Accuracy Score : 0.6057142857142858\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTETomek Combination Dataset\")\n",
    "RSCV_SVC_smoteTomek_loaded  = joblib.load(\"RSCV_SVC_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_SVC_smoteTomek_pca.pkl']"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_svc_smoteTomek_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteTomek_pca.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_svc_smoteTomek_pca, \"RSCV_SVC_smoteTomek_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for SVC with SMOTETomek Combination PCA Dataset\n",
      "\n",
      "Best Parameters : {'kernel': 'sigmoid', 'gamma': 0.05, 'C': 1000}\n",
      "\n",
      "Best Score : 0.7214814814814815\n",
      "\n",
      "Accuracy Score : 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for SVC with SMOTETomek Combination PCA Dataset\")\n",
    "RSCV_SVC_smoteTomek_pca_loaded  = joblib.load(\"RSCV_SVC_smoteTomek_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteTomek_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteTomek_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteTomek_pca_loaded.predict(X_pca_test_smoteTomek1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_smoteTomek.pkl']"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On SMOTETomek Combination\n",
    "\n",
    "random_logreg_smoteTomek = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_smoteTomek, \"RSCV_LR_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTETomek Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 1000}\n",
      "\n",
      "Best Score : 0.7416161616161616\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek Dataset\")\n",
    "RSCV_LR_smoteTomek_loaded  = joblib.load(\"RSCV_LR_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_smoteTomek.pkl']"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logreg_pca_smoteTomek = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_pca_smoteTomek, \"RSCV_LR_pca_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTETomek PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.7160269360269361\n",
      "\n",
      "Accuracy Score : 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek PCA Dataset\")\n",
    "RSCV_LR_pca_smoteTomek_loaded  = joblib.load(\"RSCV_LR_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srix/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 96 is smaller than n_iter=100. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_smoteTomek.pkl']"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Logistic Regression On SMOTETomek Combination\n",
    "\n",
    "random_logreg_smoteTomek = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_smoteTomek, \"RSCV_LR_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTETomek Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'liblinear', 'penalty': 'l2', 'C': 1000}\n",
      "\n",
      "Best Score : 0.7416161616161616\n",
      "\n",
      "Accuracy Score : 0.5885714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek Dataset\")\n",
    "RSCV_LR_smoteTomek_loaded  = joblib.load(\"RSCV_LR_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_LR_pca_smoteTomek.pkl']"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logreg_pca_smoteTomek = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_pca_smoteTomek, \"RSCV_LR_pca_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for LR with SMOTETomek PCA Dataset\n",
      "\n",
      "Best Parameters : {'solver': 'saga', 'penalty': 'l1', 'C': 10}\n",
      "\n",
      "Best Score : 0.7160269360269361\n",
      "\n",
      "Accuracy Score : 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek PCA Dataset\")\n",
    "RSCV_LR_pca_smoteTomek_loaded  = joblib.load(\"RSCV_LR_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_smoteTomek.pkl']"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for RandomForest On SMOTETomek Dataset\n",
    "\n",
    "random_rf_smoteTomek = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_rf_smoteTomek, \"RSCV_RF_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF with SMOTETomek Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.5, 'min_samples_leaf': 0.1, 'max_features': 'auto', 'max_depth': 26.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7252525252525253\n",
      "\n",
      "Accuracy Score : 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF with SMOTETomek Dataset\")\n",
    "RSCV_RF_smoteTomek_loaded  = joblib.load(\"RSCV_RF_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RSCV_RF_pca_smoteTomek.pkl']"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rf_pca_smoteTomek = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_rf_pca_smoteTomek, \"RSCV_RF_pca_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for RF on SMOTETomek PCA Dataset\n",
      "\n",
      "Best Parameter : {'n_estimators': 100, 'min_samples_split': 0.2, 'min_samples_leaf': 0.2, 'max_features': 'sqrt', 'max_depth': 11.0, 'bootstrap': False}\n",
      "\n",
      "Best Score : 0.7050168350168351\n",
      "\n",
      "Accuracy Score : 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for RF on SMOTETomek PCA Dataset\")\n",
    "RSCV_RF_pca_smoteTomek_loaded  = joblib.load(\"RSCV_RF_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_smoteTomek.pkl']"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTETomek Dataset\n",
    "\n",
    "clf_gbc_smoteTomek = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(clf_gbc_smoteTomek,'RSCV_GBC_smoteTomek.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with SMOTETomek Dataset\n",
      "\n",
      "Best Score : 0.7875084175084175\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with SMOTETomek Dataset\")\n",
    "RSCV_GBC_smoteTomek_loaded  = joblib.load(\"RSCV_GBC_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_GBC_pca_smoteTomek.pkl']"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gbc_pca_smoteTomek = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_smoteTomek,'RSCV_GBC_pca_smoteTomek.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for GBC with SMOTETomek PCA Dataset\n",
      "\n",
      "Best Score : 0.7563299663299663\n",
      "\n",
      "Best Parameters : {'n_estimators': 300, 'min_samples_split': 0.1, 'min_samples_leaf': 0.2, 'max_depth': 16.0, 'learning_rate': 0.5}\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for GBC with SMOTETomek PCA Dataset\")\n",
    "RSCV_GBC_pca_smoteTomek_loaded  = joblib.load(\"RSCV_GBC_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_smoteTomek.pkl']"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter for AdaBoost Classifier On SMOTETomek Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteTomek = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteTomek, \"RSCV_ADC_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SMOTETomek PCA Dataset\n",
      "\n",
      "Best Score - 0.5575084175084175\n",
      "\n",
      "Best Parameters - {'n_estimators': 800, 'learning_rate': 0.005, 'algorithm': 'SAMME'}\n",
      "\n",
      " Accuracy Score - 0.6171428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SMOTETomek PCA Dataset\")\n",
    "RSCV_ADC_smoteTomek_loaded  = joblib.load(\"RSCV_ADC_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_smoteTomek_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_smoteTomek_pca.pkl']"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier on SMOTETomek PCA Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteTomek_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteTomek_pca.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteTomek_pca, \"RSCV_ADC_smoteTomek_pca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SMOTETomek PCA Dataset\n",
      "\n",
      "Best Score - 0.5538047138047137\n",
      "\n",
      "Best Parameters - {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      " Accuracy Score - 0.6228571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SMOTETomek PCA Dataset\")\n",
    "RSCV_ADC_smoteTomek_pca_loaded  = joblib.load(\"RSCV_ADC_smoteTomek_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteTomek_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_smoteTomek_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteTomek_pca_loaded.predict(X_pca_test_smoteTomek1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSCV_ADC_svc_smoteTomek.pkl']"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_smoteTomek = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_smoteTomek, \"RSCV_ADC_svc_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomizedSearchCV for ADC with SVC on SMOTETomek Dataset\n",
      "\n",
      "Best Score : {'n_estimators': 1000, 'learning_rate': 1, 'algorithm': 'SAMME'}\n",
      "\n",
      "Best Parameter : 0.5463973063973064\n",
      "\n",
      "Accuracy Score : 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandomizedSearchCV for ADC with SVC on SMOTETomek Dataset\")\n",
    "RSCV_ADC_svc_smoteTomek_loaded  = joblib.load(\"RSCV_ADC_svc_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_smoteTomek_loaded.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_smoteTomek = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_smoteTomek, \"RSCV_ADC_svc_pca_smoteTomek.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTETomek PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_smoteTomek_loaded  = joblib.load(\"RSCV_ADC_svc_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hyperparameter Tuning for SVC on SMOTETomek Combination Dataset\n",
    "random_svc_smoteTomek = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_svc_smoteTomek, \"RSCV_SVC_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTETomek Combination Dataset\")\n",
    "RSCV_SVC_smoteTomek_loaded  = joblib.load(\"RSCV_SVC_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "random_svc_smoteTomek_pca = RandomizedSearchCV(estimator = SVC(random_state=0), \n",
    "                            param_distributions = param_grid_svc, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_svc_smoteTomek_pca.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_svc_smoteTomek_pca, \"RSCV_SVC_smoteTomek_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTETomek Combination PCA Dataset\")\n",
    "RSCV_SVC_smoteTomek_pca_loaded  = joblib.load(\"RSCV_SVC_smoteTomek_pca.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_SVC_smoteTomek_pca_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_SVC_smoteTomek_pca_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_SVC_smoteTomek_pca_loaded.predict(X_pca_test_smoteTomek1)))\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On SMOTETomek Combination\n",
    "\n",
    "random_logreg_smoteTomek = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_smoteTomek, \"RSCV_LR_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek Dataset\")\n",
    "RSCV_LR_smoteTomek_loaded  = joblib.load(\"RSCV_LR_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "random_logreg_pca_smoteTomek = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_pca_smoteTomek, \"RSCV_LR_pca_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek PCA Dataset\")\n",
    "RSCV_LR_pca_smoteTomek_loaded  = joblib.load(\"RSCV_LR_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n",
    "\n",
    "#Hyperparameter Tuning for Logistic Regression On SMOTETomek Combination\n",
    "\n",
    "random_logreg_smoteTomek = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            cv=10,scoring='accuracy',refit=True,verbose=1,\n",
    "                            n_jobs=-1,n_iter=100,random_state=0\n",
    "                           )\n",
    "\n",
    "random_logreg_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_smoteTomek, \"RSCV_LR_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek Dataset\")\n",
    "RSCV_LR_smoteTomek_loaded  = joblib.load(\"RSCV_LR_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\",RSCV_LR_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "random_logreg_pca_smoteTomek = RandomizedSearchCV(estimator = LogisticRegression(), \n",
    "                            param_distributions = param_grid_logreg, \n",
    "                            refit=True,verbose=True,scoring='accuracy',\n",
    "                            cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "\n",
    "random_logreg_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_logreg_pca_smoteTomek, \"RSCV_LR_pca_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for LR with SMOTETomek PCA Dataset\")\n",
    "RSCV_LR_pca_smoteTomek_loaded  = joblib.load(\"RSCV_LR_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameters :\", RSCV_LR_pca_smoteTomek_loaded.best_params_) \n",
    "print(\"\\nBest Score :\", RSCV_LR_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_LR_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n",
    "\n",
    "\n",
    "#Hyperparameter Tuning for RandomForest On SMOTETomek Dataset\n",
    "\n",
    "random_rf_smoteTomek = RandomizedSearchCV(estimator=RandomForestClassifier(random_state = 1),\n",
    "                               param_distributions=param_grid_rf, \n",
    "                               verbose=False,cv=10,scoring='accuracy', \n",
    "                               refit=True,n_jobs=-1,random_state=0\n",
    "                              )\n",
    "random_rf_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_rf_smoteTomek, \"RSCV_RF_smoteEnn.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF with SMOTETomek Dataset\")\n",
    "RSCV_RF_smoteTomek_loaded  = joblib.load(\"RSCV_RF_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "random_rf_pca_smoteTomek = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 1), \n",
    "                            param_distributions = param_grid_rf,refit=True,verbose=True,\n",
    "                            scoring='accuracy',cv=10,n_jobs=-1,random_state = 0\n",
    "                           )\n",
    "random_rf_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_rf_pca_smoteTomek, \"RSCV_RF_pca_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for RF on SMOTETomek PCA Dataset\")\n",
    "RSCV_RF_pca_smoteTomek_loaded  = joblib.load(\"RSCV_RF_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Parameter :\", RSCV_RF_pca_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Score :\", RSCV_RF_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_RF_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n",
    "\n",
    "#Hyperparameter Tuning for GradientBoostingClassifier On SMOTETomek Dataset\n",
    "\n",
    "clf_gbc_smoteTomek = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(clf_gbc_smoteTomek,'RSCV_GBC_smoteTomek.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with SMOTETomek Dataset\")\n",
    "RSCV_GBC_smoteTomek_loaded  = joblib.load(\"RSCV_GBC_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_GBC_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "clf_gbc_pca_smoteTomek = RandomizedSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                             param_distributions=param_grid_gbc,cv=10,scoring='accuracy',\n",
    "                             refit=True, n_jobs=-1,verbose=False,random_state=0\n",
    "                            )\n",
    "clf_gbc_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(clf_gbc_pca_smoteTomek,'RSCV_GBC_pca_smoteTomek.pkl')\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for GBC with SMOTETomek PCA Dataset\")\n",
    "RSCV_GBC_pca_smoteTomek_loaded  = joblib.load(\"RSCV_GBC_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\",RSCV_GBC_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nBest Parameters :\", RSCV_GBC_pca_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_GBC_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))\n",
    "\n",
    "\n",
    "#Hyperparameter for AdaBoost Classifier On SMOTETomek Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteTomek = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteTomek, \"RSCV_ADC_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SMOTETomek PCA Dataset\")\n",
    "RSCV_ADC_smoteTomek_loaded  = joblib.load(\"RSCV_ADC_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\",RSCV_ADC_smoteTomek_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier on SMOTETomek PCA Dataset\n",
    "                \n",
    "dTC = DecisionTreeClassifier(max_depth=4,max_features='sqrt',min_samples_leaf=0.5,min_samples_split=0.1)\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=dTC, random_state=0)\n",
    "\n",
    "random_adaboost_smoteTomek_pca = RandomizedSearchCV(estimator=ada_classifier, param_distributions=param_grid_adc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_smoteTomek_pca.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_smoteTomek_pca, \"RSCV_ADC_smoteTomek_pca.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SMOTETomek PCA Dataset\")\n",
    "RSCV_ADC_smoteTomek_pca_loaded  = joblib.load(\"RSCV_ADC_smoteTomek_pca.pkl\")\n",
    "print(\"\\nBest Score -\", RSCV_ADC_smoteTomek_pca_loaded.best_score_)\n",
    "print(\"\\nBest Parameters -\", RSCV_ADC_smoteTomek_pca_loaded.best_params_)\n",
    "print(\"\\n Accuracy Score -\", accuracy_score(y_test, RSCV_ADC_smoteTomek_pca_loaded.predict(X_pca_test_smoteTomek1)))\n",
    "\n",
    "#Hyperparameter Tuning For AdaBoostClassifier with SVC as base estimator \n",
    "\n",
    "svc = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "\n",
    "random_adaboost_svc_smoteTomek = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                     random_state=0, cv=10, scoring='accuracy',\n",
    "                                     refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_smoteTomek.fit(X_train_smoteTomek, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_smoteTomek, \"RSCV_ADC_svc_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for ADC with SVC on SMOTETomek Dataset\")\n",
    "RSCV_ADC_svc_smoteTomek_loaded  = joblib.load(\"RSCV_ADC_svc_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\",RSCV_ADC_svc_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\",accuracy_score(y_test, RSCV_ADC_svc_smoteTomek_loaded.predict(X_test)))\n",
    "\n",
    "#X_pca_train_smoteTomek1, X_pca_test_smoteTomek1, y_train_smoteTomek, y_test\n",
    "#X_train_smoteTomek, X_test, y_train_smoteTomek, y_test\n",
    "\n",
    "svc  = SVC(kernel='sigmoid', gamma=0.001, C=1)\n",
    "ada_classifier_svc = AdaBoostClassifier(base_estimator=svc, random_state=0)\n",
    "random_adaboost_svc_pca_smoteTomek = RandomizedSearchCV(estimator=ada_classifier_svc, param_distributions=param_grid_adc_svc,\n",
    "                                            random_state=0, cv=10, scoring='accuracy',\n",
    "                                            refit=True, n_jobs=-1, verbose=False)\n",
    "random_adaboost_svc_pca_smoteTomek.fit(X_pca_train_smoteTomek1, y_train_smoteTomek.values.ravel())\n",
    "joblib.dump(random_adaboost_svc_pca_smoteTomek, \"RSCV_ADC_svc_pca_smoteTomek.pkl\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV for SVC with SMOTETomek PCA Dataset\")\n",
    "RSCV_ADC_svc_pca_smoteTomek_loaded  = joblib.load(\"RSCV_ADC_svc_pca_smoteTomek.pkl\")\n",
    "print(\"\\nBest Score :\", RSCV_ADC_svc_pca_smoteTomek_loaded.best_params_)\n",
    "print(\"\\nBest Parameter :\", RSCV_ADC_svc_pca_smoteTomek_loaded.best_score_)\n",
    "print(\"\\nAccuracy Score :\", accuracy_score(y_test, RSCV_ADC_svc_pca_smoteTomek_loaded.predict(X_pca_test_smoteTomek1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
